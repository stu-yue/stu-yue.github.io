<!DOCTYPE html>
<html lang=en>
<head>
    <meta charset="utf-8">
    
    <title>Memo | Optimization Algorithm in Machine Learning | Yue&#39;s Jotter</title>
    
    
        <meta name="keywords" content="optimization,ml" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Reproduced in The Summary of Optimization Algorithm in ML  For machine learning algorithms with diverse forms and characteristics, we have various optimization algorithms suitable for optimizing thei">
<meta property="og:type" content="article">
<meta property="og:title" content="Memo | Optimization Algorithm in Machine Learning">
<meta property="og:url" content="https://stu-yue.github.io/jottings/mathematics/memo_optimization_alg/">
<meta property="og:site_name" content="Yue&#39;s Jotter">
<meta property="og:description" content="Reproduced in The Summary of Optimization Algorithm in ML  For machine learning algorithms with diverse forms and characteristics, we have various optimization algorithms suitable for optimizing thei">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://stu-yue.github.io/jottings/mathematics/memo_optimization_alg/memo_optimization_alg/overview.png">
<meta property="og:image" content="https://stu-yue.github.io/jottings/mathematics/memo_optimization_alg/overview.png">
<meta property="article:published_time" content="2023-08-05T14:56:53.000Z">
<meta property="article:modified_time" content="2023-11-13T10:46:27.185Z">
<meta property="article:author" content="stu-yue">
<meta property="article:tag" content="optimization">
<meta property="article:tag" content="ml">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://stu-yue.github.io/jottings/mathematics/memo_optimization_alg/memo_optimization_alg/overview.png">
    

    

    
        <link rel="icon" href="/css/images/logo.png" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">

    
<script src="/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Yue's Jotter" type="application/atom+xml">
</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Yue&#39;s Jotter</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">HOME</a>
                
                    <a class="main-nav-link" href="/archives">ARCHIVES</a>
                
                    <a class="main-nav-link" href="/categories">CATEGORIES</a>
                
                    <a class="main-nav-link" href="/tags">TAGS</a>
                
                    <a class="main-nav-link" href="/about">ABOUT</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">HOME</a></td>
                
                    <td><a class="main-nav-link" href="/archives">ARCHIVES</a></td>
                
                    <td><a class="main-nav-link" href="/categories">CATEGORIES</a></td>
                
                    <td><a class="main-nav-link" href="/tags">TAGS</a></td>
                
                    <td><a class="main-nav-link" href="/about">ABOUT</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>categories</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            architecture
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/jottings/architecture/summa_firmware_and_drivers/">Summa | Firmware and Drivers</a></li>  <li class="file"><a href="/jottings/architecture/summa_memory_categories/">Summa | The Majority of Memory Categories</a></li>  <li class="file"><a href="/jottings/architecture/memo_isa_and_micro_architecture/">Memo | ISA and Micro-architecture</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            languages
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            python
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/jottings/languages/python/memo_GIL_and_coroutine/">Memo | GIL and Coroutine</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            shell
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/jottings/languages/shell/memo_exploring_os/">Memo | Exploring Linux Files and Directories</a></li>  <li class="file"><a href="/jottings/languages/shell/memo_redirection/">Memo | Redirection</a></li>  <li class="file"><a href="/jottings/languages/shell/memo_see_the_world_through_shell/">Memo | See the World through Shell</a></li>  <li class="file"><a href="/jottings/languages/shell/memo_permission_progress_env/">Memo | Permission, Progress and Shell Environment</a></li>  <li class="file"><a href="/jottings/languages/shell/memo_others/">Memo | Olds and Ends</a></li>  <li class="file"><a href="/jottings/languages/shell/memo_package_device/">Memo | Package and Device</a></li>  <li class="file"><a href="/jottings/languages/shell/memo_tmux/">Memo | Tmux</a></li>  <li class="file"><a href="/jottings/languages/shell/shell/"></a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            mathematics
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file active"><a href="/jottings/mathematics/memo_optimization_alg/">Memo | Optimization Algorithm in Machine Learning</a></li>  <li class="file"><a href="/jottings/mathematics/memo_algebra_basis/">Memo | Algebra Basis</a></li>  <li class="file"><a href="/jottings/mathematics/memo_mle_mae_bayes/">Memo | Parameter Estimation</a></li>  <li class="file"><a href="/jottings/mathematics/memo_law_of_probability/">Memo | Law of Large Number</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            networks
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/jottings/networks/memo_network_tidbits/">Summa |Networks Tidbits</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            statistics_ml
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/jottings/statistics_ml/summa_intro/">Summa | Intro of Statistical ML</a></li>  <li class="file"><a href="/jottings/statistics_ml/memo_ctc/">Memo | CTC Introduction</a></li>  <li class="file"><a href="/jottings/statistics_ml/memo_lm_and_word_vector/">Memo | LM and Word Representation</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            tidbits
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/jottings/tidbits/hot_points/">Hot Points</a></li>  <li class="file"><a href="/jottings/tidbits/tbr_compiler/">TBR_compiler</a></li>  <li class="file"><a href="/jottings/tidbits/tbr_net_info/">TBR_Net_Info</a></li>  <li class="file"><a href="/jottings/tidbits/quantization/"></a></li>  </ul> 
                    </li> 
                     <li class="file"><a href="/jottings/intro/">Welcome to Yue's Jotter</a></li>  </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-mathematics/memo_optimization_alg" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/mathematics/">mathematics</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/ml/" rel="tag">ml</a>, <a class="tag-link-link" href="/tags/optimization/" rel="tag">optimization</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/jottings/mathematics/memo_optimization_alg/">
            <time datetime="2023-08-05T14:56:53.000Z" itemprop="datePublished">2023-08-05</time>
        </a>
    </div>


                        
                        
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/stu-yue/stu-yue.github.io/raw/main/source/_posts/mathematics/memo_optimization_alg.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/stu-yue/stu-yue.github.io/edit/main/source/_posts/mathematics/memo_optimization_alg.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/stu-yue/stu-yue.github.io/commits/main/source/_posts/mathematics/memo_optimization_alg.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            Memo | Optimization Algorithm in Machine Learning
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
        
        
            <blockquote>
<p>Reproduced in <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/42689565">The Summary of Optimization Algorithm in ML</a></p>
</blockquote>
<p>For machine learning algorithms with diverse forms and characteristics, we have various optimization algorithms suitable for optimizing their objective functions. Apart from a few problems that can be solved using <strong>Brute Force Search</strong> to obtain the optimal solution, we can categorize the optimization algorithms used in machine learning into two types: </p>
<ul>
<li><p><strong>Analytical Solutions</strong>: <em><strong>These algorithms aim to find the optimal solution to the objective function by solving mathematical equations or performing algebraic manipulations. They often involve setting derivatives or gradients to zero and solving the resulting equations</strong>.</em> Analytical solutions are typically used for linear regression, logistic regression, and certain types of optimization problems with closed-form solutions.</p>
</li>
<li><p><strong>Numerical Optimization</strong>: <em><strong>These algorithms iteratively search for the optimal solution by evaluating the objective function at different points in the search space. They do not rely on explicit mathematical equations or derivatives</strong></em>. Numerical optimization methods include gradient-based algorithms like gradient descent and its variants, Newton’s method, stochastic gradient descent, and quasi-Newton methods. </p>
<ul>
<li><p><strong>Global Optimization Methods:</strong> </p>
<ul>
<li><strong>Heuristic Algorithm, Simulated Annealing, Particle Swarm Optimization</strong>, etc.</li>
</ul>
</li>
<li><p><strong>Local Optimization Methods:</strong> </p>
<ul>
<li><p><strong>Gradient Based:</strong> </p>
<ul>
<li><p><strong>First Order Derivative:</strong> (Jacobian)</p>
<ul>
<li><p><strong>Gradient Descent:</strong> $\theta &#x3D; \theta - \eta \cdot\nabla J(\theta)$</p>
<ul>
<li>whereas Standard Gradient Descent will only converge to the minimum of the basin as mentioned above.</li>
</ul>
</li>
<li><p><strong>SGD</strong>: $\theta &#x3D; \theta - \eta \cdot \nabla J(\theta;x_i;y_i)$;</p>
<ul>
<li>frequent updates, parameters updates have high variance and causes the Loss function to fluctuate to different intensities;</li>
<li>helps us <strong>discover new and possibly better local minima</strong>;</li>
<li>it ultimately <strong>complicates the convergence to the exact minimum</strong> and will <strong>keep overshooting</strong> due to the frequent fluctuations;</li>
</ul>
</li>
<li><p><strong>Mini-Batch GD</strong>: ultimately lead us to a much better and stable convergence;</p>
<ul>
<li>make use of highly optimized matrix optimizations common to state-of-the-art deep learning libraries that make computing the gradient w.r.t. a mini-batch very efficient.</li>
</ul>
</li>
<li><p><strong>Challenges in GD</strong>: </p>
<ol>
<li>Choosing a proper learning rate can be difficult;</li>
<li>Additionally, the same learning rate applies to all parameter updates. If our data is sparse and our features have very different frequencies, we might not want to update all of them to the same extent, but perform a larger update for rarely occurring features.</li>
<li>avoiding getting trapped in their numerous <strong>sub-optimal local minima</strong>; Actually, Difficulty arises in fact not from local minima but from *<strong>saddle points*</strong>, i.e. <em>points where one dimension slopes up and another slopes down</em>. These saddle points are usually surrounded by a plateau of the same error, which makes it notoriously hard for SGD to escape, as the gradient is close to zero in all dimensions.</li>
</ol>
</li>
<li><p><strong>Momentum</strong>: $V(t) &#x3D; \gamma\cdot V(t-1)+\eta \cdot\nabla J(\theta)$, then $\theta &#x3D; \theta - V(t)$;</p>
<ul>
<li>leads to faster and stable convergence; reduced oscillations</li>
<li>Problem: What actually happens is that as we reach the minima i.e the lowest point on the curve ,the <strong>momentum</strong> is pretty high and it doesn’t knows to *<strong>slow*</strong> <em>down</em> at that point due to the high momentum <em>which could cause it to miss the minima entirely and continue movie up.</em></li>
</ul>
</li>
<li><p><strong>Nesterov accelerated gradient (NAG)</strong>: $V(t) &#x3D; \gamma\cdot V(t-1)+\eta\cdot\nabla J(\theta - \gamma\cdot V(t-1))$, then $\theta &#x3D; \theta - V(t)$；</p>
<ul>
<li>In the method he suggested we first make <strong>a big jump based on out previous momentum</strong> then calculate the Gradient and <strong>then make an correction which results in an parameter update</strong>. Now this anticipatory update prevents us to go too fast and not miss the minima and makes it more responsive to changes.</li>
<li>We know that we will use our momentum term <strong>γV(t−1)</strong> to move the parameters <strong>θ</strong>. Computing <strong>θ−γV(t−1)</strong> thus gives us an <em>approximation of the next position of the parameters</em> <em>which gives us a</em> <em>rough idea where our parameters are going to be</em>. <strong>We can now effectively look ahead by calculating the gradient not w.r.t. to our current parameters θ but w.r.t. the approximate future position of our parameters</strong></li>
</ul>
</li>
<li><p><strong>AdaGrad</strong>: </p>
<ul>
<li>$\theta_{t+1,i} &#x3D; \theta_{t,i}-\frac{\eta}{\sqrt{G_{t,i}+\epsilon}}\cdot g_{t,i}$,  $G_{t,i} &#x3D; G_{t,i}+\nabla_{\theta_{t,i}}J(\theta)$;</li>
<li>allows the learning Rate <strong>$-\eta$</strong> to <strong>adapt</strong> based on the parameters. So it makes big updates for infrequent parameters and small updates for frequent parameters. For this reason, it is well-suited for dealing with sparse data.</li>
<li>At the beginning, <strong>AdaGrad</strong> has an incentive effect on convergence, and then slowly becomes penalty convergence, and the updating speed is getting slower and slower</li>
<li>Problem:  its learning rate $-\eta$ is always Decreasing and decaying.<ul>
<li>Due to: the accumulation of each squared Gradients in the denominator , since every added term is positive. This in turn causes the <em>learning rate to shrink and eventually become so small,</em> <strong>that the model just stops learning entirely and stops acquiring new additional knowledge.</strong></li>
<li>This problem of <strong>Decaying learning Rate</strong> is Rectified in another algorithm called <strong>AdaDelta.</strong></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>AdaDelta</strong>: </p>
<ul>
<li>$g(t)$ is gradient of mini-batch;</li>
<li><strong>RMSprop</strong>: <ul>
<li>$E[g^2]<em>t &#x3D; \gamma E[g^2]</em>{t-1}+(1-\gamma)g^2_t$, </li>
<li>$\Delta\theta_t &#x3D; -\frac{\eta}{\sqrt{E[g^2]_t+\epsilon}}\odot g_t &#x3D; -\frac{\eta}{RMS[g]_t}g_t$,</li>
<li>$\theta_{t+1} &#x3D; \theta_t + \Delta\theta_t$</li>
</ul>
</li>
<li>The authors note that the <strong>units in this update (as well as in SGD, Momentum, or Adagrad) do not match</strong>, i.e. the update should have the same hypothetical units as the parameter. To realize this, they first define another exponentially decaying average, this time not of squared gradients but of squared parameter updates;</li>
<li>Thus, they use $RMS[\Delta\theta]_{t-1}$ instead of hyperparameter $\eta$ ;<ul>
<li>$RMS[\Delta\theta]<em>t &#x3D; \sqrt{E[\Delta\theta^2]</em>{t-1}+\epsilon}$</li>
<li>$E[\Delta\theta^2]<em>t &#x3D; \gamma E[\Delta\theta^2]</em>{t-1}+(1-\gamma)\Delta\theta^2_t$</li>
</ul>
</li>
<li>Instead of accumulating all previous squared gradients, *<strong>AdaDelta*</strong> limits the window of accumulated past gradients to some fixed size <strong>w</strong>.</li>
<li>Another thing with AdaDelta is that we don’t even need to set a default learning rate.</li>
</ul>
<blockquote>
<p><strong>What improvements we have done so far——</strong></p>
<ol>
<li>We are calculating <em>different learning Rates</em> for each parameter.</li>
<li>We are also calculating <em>momentum</em>.</li>
<li>Preventing <strong>Vanishing(decaying) learning Rates</strong>.</li>
</ol>
<p><em>Since we are calculating individual</em> <strong>learning rates</strong> <em>for each parameter , why not calculate individual</em> *<strong>momentum*</strong> <em>changes for each parameter and store them separately. This is where a new modified technique and improvement comes into play called as</em> *<strong>Adam.*</strong></p>
</blockquote>
</li>
<li><p><strong>Adam</strong>: Adaptive Moment Estimation (Adam) is another method that computes adaptive learning rates for each parameter. In addition to storing an exponentially decaying average of past squared gradients like <strong>AdaDelta</strong> ,<strong>Adam</strong> *also keeps an exponentially decaying average of past gradients <strong>M(t)</strong>, similar to momentum*:</p>
<ul>
<li>$m_t &#x3D; \beta_1m_{t-1}+(1-\beta_1)g_t, \quad v_t &#x3D; \beta_2v_{t-1}+(1-\beta_2)g^2_t$<ul>
<li>$m_t &#x3D; (1-\beta_1)\sum_{i&#x3D;1}^{t}\beta^{t-i}_{1}g_i$, </li>
<li>sum all weights of $g_i$ is $(1-\beta_1)\sum_{i&#x3D;1}^{t}\beta_1^{t-i} &#x3D; 1-\beta^t_1$</li>
</ul>
</li>
<li>To rectify the bias to 1, divide $(1-\beta_1^t)$ respectively,   $\hat m_t &#x3D; \frac{m_t}{1-\beta_1^t}, \quad \hat v_t &#x3D; \frac{v_t}{1-\beta_2^t}$,</li>
<li>$\theta_{t+1} &#x3D; \theta_t - \frac{\eta}{\sqrt{\hat v_t}+\epsilon}\hat m_t$</li>
<li>指数加权移动平均$m_t$，按元素平方的指数加权移动平均$v_t$</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Second Order Derivative:</strong> (Hessian)</p>
<ul>
<li><strong>Newton Method:</strong></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Divide and Conquer:</strong> </p>
<ul>
<li><strong>Coordinate Descent:</strong> </li>
<li><strong>SMO Algorithm:</strong> </li>
<li><strong>Staged Optimization:</strong></li>
</ul>
</li>
<li><p><strong>Dynamic Programming:</strong></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The following picture illustrates the organization of this memorandum: </p>
<img src="./memo_optimization_alg/overview.png" style="zoom:100%">

<img src="./overview.png" style="zoom:100%">







<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><ol>
<li><a target="_blank" rel="noopener" href="https://medium.com/@anishsingh20/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f">Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient Descent</a></li>
</ol>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/jottings/languages/python/memo_GIL_and_coroutine/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    Memo | GIL and Coroutine
                
            </div>
        </a>
    
    
        <a href="/jottings/languages/shell/memo_exploring_os/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">Memo | Exploring Linux Files and Directories</div>
        </a>
    
</nav>





    
    




<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            stu-yue &copy; 2024 
            <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a target="_blank" rel="noopener" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
        </div>
    </div>
</footer>

        

    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


    </div>
</body>
</html>