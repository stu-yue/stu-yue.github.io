{"pages":[{"title":"ABOUT","date":"2023-10-04T06:07:04.840Z","path":"about/index.html","text":"ğŸ‘©â€ğŸ’»: A CODER WITH GREEN HANDS ğŸ’¡: THINK TWICE, CODE ONCE! ğŸ¯: GOTO NIPS, MSRA AND BE REASSURED ğŸ’Œ: BEST WISHES TO LEE XIAOMAO 12345// life mottoif (sad() == true) &#123; sad().stop(); beAwesome();&#125;"},{"title":"TAGS","date":"2023-07-13T06:48:03.646Z","path":"tags/index.html","text":""},{"title":"CATEGORIES","date":"2023-07-13T06:47:46.496Z","path":"categories/index.html","text":""}],"posts":[{"title":"Memo | Law of Large Number","date":"2023-10-21T05:56:53.000Z","path":"jottings/mathematics/memo_law_of_probability/","text":"1 Law of Large Number1.1 Folk UnderstandingIn simple terms, the large numbers theorem refers to that a random event may or may not occur in a single experiment, but in a large number of repeated experiments, it often shows obvious regularity, that is, the frequency of the random event will converge to a constant value, which is the probability of the event. Another way to express it is that when the sample data is infinite, the sample mean tends to population mean. Because in real life, we can not run an infinite number of experiments, and it is difficult to estimate the parameters of the population. The law of large numbers connects mean values, which belong to mathematical statistics, with expectations, which belong to probability theory. 1.2 Convergence in Probability Weak Law: convergence in probability Strong Law: almost sure convergence (outlier can be negligible in measure) 1.3 Bernoulliâ€™s LawFrom the perspective of defining probability, reveals the relationship between probability and frequency.$$\\lim\\limits_{n\\rightarrow \\infin} P{ |\\frac{f_A}{n} - p| &lt; \\epsilon } &#x3D; 1$$ 1.4 Khinchinâ€™s LawPriori Condition: Independent Identically Distributed, $\\lim\\limits_{n\\rightarrow \\infin} P{ |\\frac{1}{n}\\sum\\limits_{i&#x3D;1}^nX_i - \\frac{1}{n}\\sum\\limits_{i&#x3D;1}^{n}E(X_i)| &lt; \\epsilon } &#x3D; 1$ 1.5 Chebyshevâ€™s LawPriori Condition: Independent Distributed, $\\lim\\limits_{n\\rightarrow \\infin} P{ |\\frac{1}{n}\\sum\\limits_{i&#x3D;1}^nX_i - \\frac{1}{n}\\sum\\limits_{i&#x3D;1}^{n}\\mu_i| &lt; \\epsilon } &#x3D; 1$ 2 Heavy-tailed Distribution Ref: 1, 2 Pareto Distribution:$$P(X&gt;x) &#x3D; \\left{\\begin{align}(\\frac{x_{min}}{x})^\\alpha,&amp;\\quad x\\ge x_{min} \\1, &amp;\\quad x&lt;x_{min}\\end{align}\\right.$$ $$f(x) &#x3D; \\left{\\begin{align}\\frac{1}{x^\\alpha}\\cdot\\frac{\\alpha x_{min}^\\alpha}{x},&amp;\\quad x\\ge x_{min} \\0, &amp;\\quad x&lt;x_{min}\\end{align}\\right.$$ Pareto Principle: states that for many outcomes, roughly 80% of consequences com from 20% of causes (the â€œvital fewâ€). Other names â€”â€” 80&#x2F;20 rule, the law of the vital few (states the imbalance phenomenon); Mathematically, the 80&#x2F;20 rule is roughly described by a power law distribution (also known as a Pareto distribution) for a particular set of parameters. Zipf Distribution:$$f(x) &#x3D; \\frac{1}{x^\\alpha\\sum_{i&#x3D;1}^{n}(1&#x2F;i)^\\alpha}, \\ x &#x3D; 1,2,\\cdots,n$$Zipfâ€™s law states that the value of the nth entry is inversely proportional to n, when a list of measured values is sorted in decreasing order. Zeta Distribution: when $n\\rightarrow \\infty$, $\\text{Zipf}(\\alpha, n)\\rightarrow\\text{Zeta}(\\alpha)$ ; Zeta is regraded as a type of pareto distribution in the discrete distribution.$$f(x) &#x3D; \\frac{1}{x^\\alpha\\sum_{i&#x3D;1}^{\\infty}(1&#x2F;i)^\\alpha}, \\ x &#x3D; 1,2,\\cdots,n,\\text{and}\\ \\alpha &gt; 1$$","tags":[{"name":"math","slug":"math","permalink":"https://stu-yue.github.io/tags/math/"}],"categories":[{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"}]},{"title":"Memo | CTC Introduction","date":"2023-10-17T07:56:53.000Z","path":"jottings/statistics_ml/memo_ctc/","text":"1 Problem DescriptionIn seq2seq structure, given input sequence $X&#x3D;[x_1,\\cdots,x_T]$ with corresponding label $Y &#x3D; [y_1,\\cdots,y_N]$, such as speech recognition. Our job is to find a map, and this algorithm for classifying time series data is called Temporal Classification. Compared with traditional classification, temporal classification has the following difficulties: The lengths of $X$ and $Y$ are variable. The lengths of $X$ and $Y$ are not equal. For an end-to-end model, we donâ€™t want manual design the alignment between $X$ and $Y$. The CTC provides the solution, that for a given input sequence $X$, CTC gives the output distribution of all possible $Y$. Based on this distribution, we can output the most likely outcome or give the probability of a certain output. Loss Function: Given the input sequence $X$, we want to maximize the posterior probability $P(Y|X)$ of $Y$, and $P(Y|X)$ should be derivable so that we can perform the gradient-descent algorithm; Test: Given a trained model and input sequence $X$, we want to output $Y$ with the highest probability:$$Y^* &#x3D; \\arg\\max_YP(Y|X)$$Of course, when testing, we want Y to be searched as soon as possible (greedy, beam, prefix-beam, LM). CTC Procedure REF: https://zhuanlan.zhihu.com/p/42719047 CTC Traits Conditional independence: A very unreasonable assumption of the CTC is its assumption that each time slice is independent of each other, which is a very bad assumption. In OCR or speech recognition, there is some semantic information between each time slice, so the effect should be improved if the language model can be added to the CTC. Monotonic alignment: Another constraint of CTC is the monotonic alignment between input $X$ and output $Y$, which holds true in OCR and speech recognition. However, in some scenarios, such as machine translation, this constraint is not valid. Many-to-one mapping: Another constraint of CTC is that the length of the input sequence $X$ is greater than the length of the label data $Y$, but for scenarios where the length of $Y$ is greater than the length of $X$, CTC is invalid.","tags":[{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"}],"categories":[{"name":"statistics_ml","slug":"statistics-ml","permalink":"https://stu-yue.github.io/categories/statistics-ml/"}]},{"title":"Memo | LM and Word Representation","date":"2023-10-17T07:56:53.000Z","path":"jottings/statistics_ml/memo_lm_and_word_vector/","text":"Language Model è¯­è¨€æ¨¡å‹æ˜¯è¡¡é‡ä¸€å¥è¯å‡ºç°åœ¨è‡ªç„¶è¯­è¨€ä¸­çš„æ¦‚ç‡çš„æ¨¡å‹ï¼› æ•°å­¦å½¢å¼ä¸Šï¼Œç»™å®šä¸€å¥è¯ $s &#x3D; { w_1,\\cdots,w_n }$ï¼Œå®ƒå¯¹åº”çš„æ¦‚ç‡ä¸ºï¼š$$\\begin{align*}P(s) &amp;&#x3D; P(w_1,\\cdots,w_n) \\&amp;&#x3D; P(w_1)\\times P(w_2|w_1) \\times \\cdots \\times P(w_n|w_1,\\cdots,w_{n-1})\\&amp;&#x3D; \\prod\\limits_{i&#x3D;1}^{n}P(w_i|w_1,\\cdots,w_{i-1})\\end{align*}$$ è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒåœ¨äºæ ¹æ®å‰æ–‡é¢„æµ‹ä¸‹ä¸€ä¸ªè¯å‡ºç°çš„æ¦‚ç‡ï¼› $P(w_i|w_1,\\cdots,w_{i-1}),\\ w_i \\in V,\\ V&#x3D;{ w_1,\\cdots,w_{|V|} }$ é©¬å°”å¯å¤«å‡è®¾ (Markov Assumption)ï¼šå½“å‰è¯å‡ºç°çš„æ¦‚ç‡åªå’Œå®ƒå‰é¢çš„kä¸ªè¯ç›¸å…³ï¼›$$\\begin{align*}P(w_i | w_1,\\cdots,w_{i-1}) &amp;&#x3D; P(w_i | w_{i-k},\\cdots,w_{i-1}) \\&amp; &#x3D; P(w_i) \\qquad\\qquad\\qquad \\rightarrow\\quad\\text{k&#x3D;0, Unigram Model} \\&amp; &#x3D; P(w_i | w_{i-1}) \\qquad\\qquad \\rightarrow\\quad\\text{k&#x3D;1, Bigram Model} \\&amp; &#x3D; P(w_i | w_{i-2}, w_{i-1})\\qquad\\rightarrow\\quad\\text{k&#x3D;2, Trigram Model}\\\\end{align*}$$ ç”¨é¢‘ç‡ä¼°è®¡æ¦‚ç‡ï¼ˆå¤§æ•°å®šç†â€”â€”ä¼¯åŠªåˆ©ï¼‰$$\\begin{align*}P(w_i | w_1,\\cdots,w_{i-1}) &amp;&#x3D; P(w_i | w_{i-k},\\cdots,w_{i-1}) \\&amp; &#x3D; \\frac{P(w_{i-k},\\cdots,w_{i-1},w_i)}{P(w_{i-k},\\cdots,w_{i-1})} \\&amp; \\approx \\frac{\\text{count}(w_{i-k},\\cdots,w_{i-1},w_i)}{\\text{count}(w_{i-k},\\cdots,w_{i-1})} \\\\end{align*}$$ Zipf Law, also known as the rank-size rule or Zipf distribution, is an empirical observation about the frequency distribution of words or other items in a given corpus of natural language. It states that the frequency of any word is inversely proportional to its rank in the frequency table. éšè—ä¿¡æ¯ï¼Œæ’ä½é åçš„è¯çš„é¢‘ç‡éå¸¸ä½ï¼Œç”šè‡³æœªå‡ºç°åœ¨è¯­æ–™ä¸­ï¼› æ•°æ®ç¨€ç–ï¼Œå¯¹äºæœªå‡ºç°åœ¨è¯­æ–™ä¸­çš„è¯æˆ–n-gramï¼Œæ— æ³•ä¼°è®¡å…¶æ¦‚ç‡ï¼› å¹³æ»‘æŠ€æœ¯ ï¼ˆæ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ã€å¤å¾·-å›¾çµå¹³æ»‘ã€æ’å€¼å¹³æ»‘ã€Katzå¹³æ»‘ï¼‰ $$\\begin{align*}P(w_i | w_1,\\cdots,w_{i-1}) &amp;&#x3D; P(w_i | w_{i-k},\\cdots,w_{i-1}) \\&amp; &#x3D; \\frac{P(w_{i-k},\\cdots,w_{i-1},w_i)}{P(w_{i-k},\\cdots,w_{i-1})} \\&amp; \\approx \\frac{\\text{count}(w_{i-k},\\cdots,w_{i-1},w_i)+1}{\\text{count}(w_{i-k},\\cdots,w_{i-1})+|V|} \\\\end{align*}$$ å›é€€ç­–ç•¥$$\\begin{align*}P(w_i | w_1,\\cdots,w_{i-1}) &amp;&#x3D; P(w_i | w_{i-k},\\cdots,w_{i-1}) \\&amp; &#x3D; \\frac{P(w_{i-k},\\cdots,w_{i-1},w_i)}{P(w_{i-k},\\cdots,w_{i-1})} \\&amp; \\approx \\frac{\\text{count}(w_{i-k},\\cdots,w_{i-1},w_i)}{\\text{count}(w_{i-k},\\cdots,w_{i-1})}\\qquad \\rightarrow\\quad\\text{students opened their} \\&amp; \\approx \\frac{\\text{count}(w_{i-k+j},\\cdots,w_{i-1},w_i)}{\\text{count}(w_{i-k+j},\\cdots,w_{i-1})}\\quad \\rightarrow\\quad\\text{opened their} \\\\end{align*}$$ å‚æ•°è§„æ¨¡é—®é¢˜ï¼šéšç€kçš„å¢å¤§ï¼Œå‚æ•°æ•°ç›®å‘ˆæŒ‡æ•°å¢é•¿ï¼Œæ— æ³•å­˜å‚¨ï¼› k&#x3D;1ï¼Œå‚æ•°é‡&#x3D;$|V|^2$ï¼›k&#x3D;2ï¼Œå‚æ•°é‡&#x3D;$|V|^3$ï¼›k&#x3D;n-1ï¼Œå‚æ•°é‡&#x3D;$|V|^n$ï¼› å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ ç”¨æ¥è¡¡é‡ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒæˆ–æ¦‚ç‡æ¨¡å‹é¢„æµ‹æ ·æœ¬çš„å¥½åç¨‹åº¦ï¼› å¯ä»¥ç”¨æ¥æ¯”è¾ƒä¸¤ä¸ªæ¦‚ç‡æ¨¡å‹ï¼Œä½å›°æƒ‘åº¦çš„æ¦‚ç‡æ¨¡å‹èƒ½æ›´å¥½åœ°é¢„æµ‹æ ·æœ¬ï¼›$$\\text{Perplexity}(s) &#x3D; 2^{H(s)} &#x3D; \\sqrt[n]{1&#x2F;P(w_1,\\cdots,w_n)}$$ Word Representation è¯åº“ï¼š WordNetï¼šä¸€ä¸ªåŒ…å«åŒä¹‰è¯ï¼ˆ synonym ï¼‰å’Œä¸Šä½è¯ï¼ˆ hypernyms ï¼‰çš„çŸ¥è¯†åº“ï¼› è¯åº“çš„é—®é¢˜ï¼š ç¼ºå°‘å·®å¼‚æ€§ (proficientä¹Ÿè¢«è§†ä¸ºgoodçš„åŒä¹‰è¯)ï¼Œä¸å¤Ÿç²¾ç¡®ï¼› ç¼ºå°‘æ–°è¯ï¼Œæ— æ³•åŠæ—¶æ›´æ–° ä¸»è§‚æ€§ï¼Œäººå·¥æ ‡æ³¨ï¼› ç¦»æ•£è¯è¡¨ç¤ºï¼š One-hotè¡¨ç¤ºï¼š 123456å•è¯è¡¨ç¤º motel = [0 0 0 0 0 1 0] hotel = [0 0 0 1 0 0 0]æ–‡æœ¬è¡¨ç¤º The students opened their books [0 0 1 1 0 0 1 0] â¬† æ¬¡æ•°ã€é¢‘ç‡ã€é€†æ–‡æ¡£é¢‘ç‡ã€TF-IDFã€... è¯è¢‹æ¨¡å‹ï¼ˆBag of Wordï¼‰ï¼šè¯è¢‹æ¨¡å‹ç”¨äºæ–‡æœ¬è¡¨ç¤ºï¼Œå¦‚æœæ¯ä¸ªè¯ä¸ºOne-hotè¡¨ç¤ºï¼Œé‚£ä¹ˆæŠŠæ¯ä¸ªè¯çš„One-hotå‘é‡ç›¸åŠ ï¼Œå¾—åˆ°çš„å‘é‡å°±æ˜¯è¯¥æ–‡æœ¬åŸºäºBOWå¾—åˆ°çš„è¡¨ç¤ºï¼› è¯é¢‘ï¼ˆTerm Frequencyï¼ŒTFï¼‰ï¼šåœ¨æ–‡æ¡£ä¸­å‡ºç°é¢‘ç‡è¶Šé«˜çš„è¯å¯¹å½“å‰æ–‡æ¡£å¯èƒ½è¶Šé‡è¦ï¼›$$f_{ij} &#x3D; \\frac{\\text{count}(\\text{term}\\ i)\\text{in doc} \\ j}{\\text{count}(\\text{all term})\\text{in doc} \\ j}, \\tf_{ij} &#x3D; \\frac{f_{ij}}{\\max_k(f_{kj})}$$ é€†æ–‡æ¡£é¢‘ç‡ï¼ˆInverse Document Frequencyï¼ŒIDFï¼‰ï¼šåœ¨å¾ˆå¤šæ–‡æ¡£ä¸­éƒ½å‡ºç°çš„è¯å¯èƒ½ä¸é‡è¦ï¼ˆå¦‚è™šè¯ï¼‰ï¼›$$df_i &#x3D; \\text{doc frequency of term}\\ i &#x3D; \\text{numbers of doc containing term} \\ i, \\idf_i &#x3D; \\log_2\\frac{N}{df_i} \\ \\text{ï¼ˆNä¸ºæ–‡æ¡£æ€»æ•°ï¼‰}$$ TF-IDFï¼šç»¼åˆä¸€ä¸ªè¯åœ¨å½“å‰æ–‡æ¡£ä¸­çš„é¢‘ç‡å’Œæ‰€æœ‰æ–‡æ¡£ä¸­å‡ºç°çš„æ¬¡æ•°æ¥åº¦é‡è¿™ä¸ªè¯å¯¹å½“å‰æ–‡æ¡£é‡è¦æ€§ï¼›$$tf_{ij}-idf_i &#x3D; tf_{ij}*idf_i &#x3D; tf_{ij}*\\log_2\\frac{N}{df_i}$$ N-gramï¼šNå…ƒç»„æå–å±€éƒ¨çš„ä¸Šä¸‹æ–‡ä½ ä¿¡æ¯ï¼› ç¦»æ•£è¯è¡¨ç¤ºé—®é¢˜ï¼šè¯­ä¹‰é¸¿æ²Ÿã€ç»´åº¦çˆ†ç‚¸ï¼› åˆ†å¸ƒå¼è¯è¡¨ç¤ºï¼ˆè¯åµŒå…¥ï¼‰ ç”¨ä¸€ä¸ªä½ç»´ç¨ å¯†çš„å‘é‡è¡¨ç¤ºå•è¯çš„æ•´ä½“å«ä¹‰ï¼› æ ¸å¿ƒæ€æƒ³ï¼šä¸€ä¸ªè¯çš„å«ä¹‰èƒ½è¢«è¯¥è¯æ‰€åœ¨çš„ä¸Šä¸‹æ–‡åæ˜ ï¼› Co-occurrenceï¼š åŸºäºçª—å£çš„å…±ç°çŸ©é˜µï¼š ç»Ÿè®¡çª—å£å†…å•è¯ä¹‹é—´çš„å…±ç°ä¿¡æ¯ï¼› ç±»ä¼¼äºword2vecï¼› èƒ½å¤Ÿæ•è·ä¸€äº›å¥æ³•å’Œè¯­ä¹‰ä¿¡æ¯ï¼ˆå±€éƒ¨ä¿¡æ¯ï¼‰ï¼› åŸºäºæ–‡æ¡£çš„å…±ç°çŸ©é˜µï¼š ç»Ÿè®¡æ–‡æ¡£å’Œå•è¯ä¹‹é—´çš„å…±ç°ä¿¡æ¯ï¼› Latent Semantics Analysis (LSA)ï¼› èƒ½å¤Ÿæ•è·è¯é¢˜ä¿¡æ¯ï¼ˆå…¨å±€ä¿¡æ¯ï¼‰ï¼› Word2vec[Mikolov et al. 2013] æ˜¯ä¸€å¥—å­¦ä¹ è¯å‘é‡çš„ç®—æ³•æ¡†æ¶ ç®—æ³•æ€æƒ³ï¼šå¤§é‡çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼ˆè®­ç»ƒè¯­æ–™ï¼‰ ä¸ºè¯è¡¨ä¸­çš„æ¯ä¸ªè¯éšæœºåˆå§‹åŒ–ä¸€ä¸ªå‘é‡è¡¨ç¤º éå†æ–‡æœ¬ä¸­çš„æ¯ä¸ªå•è¯ $c$ï¼Œå…¶ä¸Šä¸‹æ–‡å•è¯ä¸º $o$ ä½¿ç”¨å•è¯ $c$ çš„ä¸Šä¸‹æ–‡ $o$ é¢„æµ‹å•è¯ $c$ çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆæ ¸å¿ƒæ€æƒ³ï¼‰ æ›´æ–°è¯å‘é‡çš„è¡¨ç¤ºä½¿å¾—å•è¯ $c$ çš„é¢„æµ‹æ¦‚ç‡æœ€å¤§åŒ– è¿ç»­è¯è¢‹æ¨¡å‹ï¼ˆCBOWï¼ŒContinuous Bag of Wordsï¼‰ ç›®æ ‡ï¼šé€šè¿‡å±€éƒ¨è¯­è¨€æ¨¡å‹çš„ä¼˜åŒ–ï¼Œè·å¾—è¯å‘é‡ ä¼˜åŒ–ç›®æ ‡ï¼šå›ºå®šä¸Šä¸‹æ–‡è¯å‘é‡è¡¨ç¤ºï¼Œè®¡ç®—ä¸­å¿ƒè¯çš„ä¼¼ç„¶å‡½æ•°ï¼Œæœ€å¤§åŒ–å…¶ä¼¼ç„¶ï¼ˆè´Ÿå¯¹æ•°ï¼‰ è®¡ç®—ä¼˜åŒ–ï¼šè´Ÿé‡‡æ ·ï¼ˆNegative Samplingï¼‰ ä¸ºé¿å…softmaxè®¡ç®—æ•´ä¸ªåºå¤§çš„è¯è¡¨ï¼Œé€šå¸¸é‡‡ç”¨è´Ÿé‡‡æ ·çš„æ–¹æ³•ï¼Œå°†å¤šåˆ†ç±»é—®é¢˜è½¬æ¢ä¸ºäºŒåˆ†ç±»é—®é¢˜ï¼›å¤§å¤§å‡å°‘äº†è®­ç»ƒæ—¶é—´å’Œè®¡ç®—æˆæœ¬ï¼› Skip-gramï¼šä¸­å¿ƒè¯ $c$ é¢„æµ‹ä¸Šä¸‹æ–‡ $o$ï¼› ä¼˜ç‚¹ ç¼ºç‚¹ ä»£è¡¨æ–¹æ³• å…±ç°çŸ©é˜µæ³• é€Ÿåº¦å¿«ï¼Œæœ‰æ•ˆåˆ©ç”¨ç»Ÿè®¡æ•°æ® è¿‡åˆ†ä¾èµ–å•è¯å…±ç°æ€§å’Œæ•°æ®é‡ LSA, HAL ç›´æ¥å­¦ä¹ æ³• èƒ½å¤Ÿæ•è·è¯­æ³•å’Œè¯­ä¹‰ä¿¡æ¯ é€Ÿåº¦å’Œæ•°æ®è§„æ¨¡ç›¸å…³ï¼Œæœªæœ‰æ•ˆåˆ©ç”¨ç»Ÿè®¡æ•°æ® Skip-gram, CBOW åŸºäºè®¡æ•°çš„å’ŒåŸºäºé¢„æµ‹çš„éƒ½æ¢ç©¶äº†è¯­æ–™åº“çš„æ½œåœ¨å…±ç°ç»Ÿè®¡ GloVeï¼šé›†ä¸¤å®¶ä¹‹é•¿ å…±ç°æ¦‚ç‡çŸ©é˜µ$X_{ij}$ï¼› å•è¯ $w_i$ï¼Œ$w_j$ çš„è¯å‘é‡ $v_i$ï¼Œ$v_j$ï¼› ä»¥å­¦ä¹ çš„æ–¹å¼ï¼Œç”¨è¯å‘é‡ä¹‹é—´çš„è¯­ä¹‰å…³ç³»æ¥æ‹Ÿåˆå…±ç°æ¦‚ç‡çŸ©é˜µï¼›$$J &#x3D; \\sum\\limits_{i,j&#x3D;1}^{|V|}f(X_{ij})(v_i^Tv_j+b_i+b_j-\\log X_{ij})^2 \\v_i^Tv_j \\quad\\rightarrow\\quad\\text{å±€éƒ¨ä¿¡æ¯} \\\\log X_{ij}\\quad\\rightarrow\\quad\\text{å…¨å±€ç»Ÿè®¡ä¿¡æ¯} \\$$ è®­ç»ƒå¿«ï¼Œé€‚åº”äºå¤§è§„æ¨¡æ•°æ®ï¼Œåœ¨å°è§„æ¨¡æ•°æ®ä¸Šæ€§èƒ½ä¼˜ç§€ï¼›","tags":[{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"}],"categories":[{"name":"statistics_ml","slug":"statistics-ml","permalink":"https://stu-yue.github.io/categories/statistics-ml/"}]},{"title":"Memo | ISA and Micro-architecture","date":"2023-10-14T10:21:53.000Z","path":"jottings/architecture/memo_isa_and_micro_architecture/","text":"What is CPU? CPUs are a general purpose, flexible architecture that take in a stream of instructions from all types of workloads, and compute or process information based on those instructions. Simply put, CPUs do what we tell them or program them to do. This ability to continue shrinking transistors is based on a famous law&#x2F;observation that we in the industry refer to as Mooreâ€™s Law, that is, we can double the number of transistors per unit area about every two year. Bug Aside: Operators traced an error on the computers to a moth trapped in a relay, recoining the term â€œbugâ€. CPU Architecture: **ENIAC: ** In early period, computer programs are hardware-based. Computers with data in memory and programs embedded in the hardware are computationally inefficient and less flexible. Von Neumann Machine: Programs are encoded as data and stored in memory (Principle of Stored Program Control). Harvard Machine: A memory structure that separates program instruction storage from data storage. CPU can access instructions and read&#x2F;write data at the same time. Use two independent memory modules to store instructions and data respectively, and each storage module does not allow instructions and data to coexist; Use two independent buses as a dedicated communication path between the CPU and each memory, and these two buses are unrelated. In fact, the vast majority of modern computers use â€œModified Harvard Architecture,â€ where instructions and data share the same address space, but the cache is separate. As it stands, von Neumann for large-scale processing, and Harvard for small-scale processing. CPU workflow architecture: Instruction Set ArchitectureThe ISA is the dictionary of instructions, data types, and the formats that the CPU adhering to that ISA must execute. The ISA is used as a design spec (specification) that tells the engineer what operations it needs to execute. Because of this layer of abstraction, the instructions in the ISA are implementation independent. Micro-architecture is the concrete implementation of ISA in the hardware. CISC (Complex Instruction Set Computers): Early CPUs all used CISC, which was designed to perform the required computational tasks with minimal machine language instructions. In order to achieve complex operations, microprocessors provide programmers with functions similar to various registers and machine instructions, but also through microprograms stored in read-only memory (ROM) to achieve its extremely powerful functions. RISC (Reduced Instruction Set Computers): In CISC, many complex instructions require extremely complex operations, and most of these instructions are direct copies of some high-level language, so the universality is poor. Because of the secondary microcode execution, it also slows down the operation of simple instruction systems that are frequently invoked. Summary: The complex instructions are converted into a microprogram, which is stored in the microservice memory when the CPU is manufactured. A microprogram contains several microinstructions (also known as microcode), and when executing complex instructions, it is actually executing a microprogram. This also brings a difference between the two instruction sets, the execution of microprograms cannot be interrupted, while RISC instructions can be interrupted between each other, so in theory RISC can respond faster to interrupts. Command Capability: The instruction capability of CISC is strong, but the usage rate of most instructions is low, which increases the complexity of CPU. Instructions are variable length format, which must be divided into different length instructions, so more processing work is needed when executing a single instruction. Most RISC instructions are single-cycle instructions, the length of instructions is fixed, and the CPU is fast and stable when executing instructions. Addressing Mode: CISC supports a variety of addressing methods. RISC supports few addressing methods. Implementation Mode: CISC is implemented through microprogrammed control technology (microcode). RISC adds a general register, hard-wired logic control is the main, suitable for pipelined execution. RISC can optimize compilation and effectively support high-level languages. R&amp;D Cycle: CISC has a long development cycle. RISC hardware is simple, so its manufacturing process is simple and low cost.","tags":[{"name":"instruction set arch","slug":"instruction-set-arch","permalink":"https://stu-yue.github.io/tags/instruction-set-arch/"}],"categories":[{"name":"architecture","slug":"architecture","permalink":"https://stu-yue.github.io/categories/architecture/"}]},{"title":"Memo | Tmux","date":"2023-10-04T07:56:53.000Z","path":"jottings/languages/shell/memo_tmux/","text":"What is tmux? A typical use of the command line is to open a terminal window (session), whose important feature is that window is connected to the process started in it (window closed, session ends, vice versa). Tmux, Terminal multiplexer, is the session and window â€œunbindâ€ tool. It allows: simultaneous access to multiple sessions in a single window. (useful for running multiple terminal simultaneously) a new window to access an existing session; each session having multiple connection window (multiple people sharing sessions in real time) arbitrary vertical and horizontal splitting of windows; Basic conception: session: Basic Usage Start â€”tmux, Quitâ€”exit/Ctrl-d, Prefix Keyâ€”Ctrl+b; A status bar is located at the bottom: 12[name/id] [list of ][0] 0:bash 1:test3* 2:test4- &quot;VM-16-17-ubuntu&quot; 15:28 04-Oct-23 Session Management New a session: tmux new -s &lt;session-name&gt;; Split sessions: tmux detach/Ctrl+b d, after the command is executed, the current Tmux window exits, but the session and the processes inside it still run in the background; View all current tmux sessions: tmux ls 1230: 1 windows (created Tue Sep 19 20:42:24 2023)1: 1 windows (created Tue Oct 3 19:57:48 2023)test2: 1 windows (created Wed Oct 4 14:49:04 2023) (attached) Attach a session: tmux attach -t id/&lt;session-name&gt;; Kill a session: tmux kill-session -t id/&lt;session-name&gt;; Switch a session: tmux switch -t id/&lt;session-name&gt;; Rename a session: tmux rename-session -t id/&lt;session-name&gt; &lt;new-name&gt;; Shortcuts: Ctrl+bd: Split current session; Ctrl+b s list all session; Ctrl+b $: rename current session; Simple workflow of tmux: new a session: tmux new -s my_session; run program in tmux window; Ctrl+b d splits the session; Attach the last session tmux attach-session -t my_session; Pane OperationTmux can split the window into panes, which can execute different commands. tmux splilt-window splits into vertical layout; tmux split-window -h splits into horizontal layout; tmux select-pane moves the cursor in different panes: 1234567891011# å…‰æ ‡åˆ‡æ¢åˆ°ä¸Šæ–¹çª—æ ¼$ tmux select-pane -U# å…‰æ ‡åˆ‡æ¢åˆ°ä¸‹æ–¹çª—æ ¼$ tmux select-pane -D# å…‰æ ‡åˆ‡æ¢åˆ°å·¦è¾¹çª—æ ¼$ tmux select-pane -L# å…‰æ ‡åˆ‡æ¢åˆ°å³è¾¹çª—æ ¼$ tmux select-pane -R tmux swap-pane exchanges the positions of panes: 12345# å½“å‰çª—æ ¼ä¸Šç§»$ tmux swap-pane -U# å½“å‰çª—æ ¼ä¸‹ç§»$ tmux swap-pane -D Shortcuts in pane operations: 1234567891011121314Ctrl+b % ï¼šåˆ’åˆ†å·¦å³ä¸¤ä¸ªçª—æ ¼ã€‚Ctrl+b &quot; ï¼šåˆ’åˆ†ä¸Šä¸‹ä¸¤ä¸ªçª—æ ¼ã€‚Ctrl+b &lt;arrow key&gt; ï¼šå…‰æ ‡åˆ‡æ¢åˆ°å…¶ä»–çª—æ ¼ã€‚&lt;arrow key&gt;æ˜¯æŒ‡å‘è¦åˆ‡æ¢åˆ°çš„çª—æ ¼çš„æ–¹å‘é”®ï¼Œæ¯”å¦‚åˆ‡æ¢åˆ°ä¸‹æ–¹çª—æ ¼ï¼Œå°±æŒ‰æ–¹å‘é”®â†“ã€‚Ctrl+b ; ï¼šå…‰æ ‡åˆ‡æ¢åˆ°ä¸Šä¸€ä¸ªçª—æ ¼ã€‚Ctrl+b o ï¼šå…‰æ ‡åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªçª—æ ¼ã€‚Ctrl+b &#123; ï¼šå½“å‰çª—æ ¼ä¸ä¸Šä¸€ä¸ªçª—æ ¼äº¤æ¢ä½ç½®ã€‚Ctrl+b &#125; ï¼šå½“å‰çª—æ ¼ä¸ä¸‹ä¸€ä¸ªçª—æ ¼äº¤æ¢ä½ç½®ã€‚Ctrl+b Ctrl+o ï¼šæ‰€æœ‰çª—æ ¼å‘å‰ç§»åŠ¨ä¸€ä¸ªä½ç½®ï¼Œç¬¬ä¸€ä¸ªçª—æ ¼å˜æˆæœ€åä¸€ä¸ªçª—æ ¼ã€‚Ctrl+b Alt+o ï¼šæ‰€æœ‰çª—æ ¼å‘åç§»åŠ¨ä¸€ä¸ªä½ç½®ï¼Œæœ€åä¸€ä¸ªçª—æ ¼å˜æˆç¬¬ä¸€ä¸ªçª—æ ¼ã€‚Ctrl+b x ï¼šå…³é—­å½“å‰çª—æ ¼ã€‚Ctrl+b ! ï¼šå°†å½“å‰çª—æ ¼æ‹†åˆ†ä¸ºä¸€ä¸ªç‹¬ç«‹çª—å£ã€‚Ctrl+b z ï¼šå½“å‰çª—æ ¼å…¨å±æ˜¾ç¤ºï¼Œå†ä½¿ç”¨ä¸€æ¬¡ä¼šå˜å›åŸæ¥å¤§å°ã€‚Ctrl+b Ctrl+&lt;arrow key&gt; ï¼šæŒ‰ç®­å¤´æ–¹å‘è°ƒæ•´çª—æ ¼å¤§å°ã€‚Ctrl+b q ï¼šæ˜¾ç¤ºçª—æ ¼ç¼–å·ã€‚ Window Operation tmux new-window -n &lt;window-name&gt;: new a window; tmux select-window -t &lt;window-number/name&gt;: switch window tmux rename-window Shortcuts in window operation: 123456Ctrl+b cï¼šåˆ›å»ºä¸€ä¸ªæ–°çª—å£ï¼ŒçŠ¶æ€æ ä¼šæ˜¾ç¤ºå¤šä¸ªçª—å£çš„ä¿¡æ¯ã€‚Ctrl+b pï¼šåˆ‡æ¢åˆ°ä¸Šä¸€ä¸ªçª—å£ï¼ˆæŒ‰ç…§çŠ¶æ€æ ä¸Šçš„é¡ºåºï¼‰ã€‚Ctrl+b nï¼šåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªçª—å£ã€‚Ctrl+b &lt;number&gt;ï¼šåˆ‡æ¢åˆ°æŒ‡å®šç¼–å·çš„çª—å£ï¼Œå…¶ä¸­çš„&lt;number&gt;æ˜¯çŠ¶æ€æ ä¸Šçš„çª—å£ç¼–å·ã€‚Ctrl+b wï¼šä»åˆ—è¡¨ä¸­é€‰æ‹©çª—å£ã€‚Ctrl+b ,ï¼šçª—å£é‡å‘½åã€‚ Other Commands123456789101112131415# åˆ—å‡ºæ‰€æœ‰å¿«æ·é”®ï¼ŒåŠå…¶å¯¹åº”çš„ Tmux å‘½ä»¤$ tmux list-keys# åˆ—å‡ºæ‰€æœ‰ Tmux å‘½ä»¤åŠå…¶å‚æ•°$ tmux list-commands# åˆ—å‡ºå½“å‰æ‰€æœ‰ Tmux ä¼šè¯çš„ä¿¡æ¯$ tmux info# é‡æ–°åŠ è½½å½“å‰çš„ Tmux é…ç½®$ tmux source-file ~/.tmux.confctrl+b, : //æŒ‰å®Œå‰ç¼€ctrl+Båï¼Œå†æŒ‰åˆ†å·ï¼šè¿›å…¥å‘½ä»¤è¡Œæ¨¡å¼set -g mouse on //å‘½ä»¤è¡Œä¸­è¾“å…¥è¿™å¥å‘½ä»¤ï¼Œå›è½¦å°±è¡Œäº†","tags":[{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"","date":"2023-09-26T06:40:27.727Z","path":"jottings/tidbits/quantization/","text":"åœ¨çº¿é‡åŒ–ï¼šæŒ‡é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(Quantization-Aware Training)ï¼Œåœ¨ç½‘ç»œæ¨¡å‹è®­ç»ƒé˜¶æ®µé‡‡ç”¨é‡åŒ–æ–¹æ¡ˆè¿›è¡Œé‡åŒ–ï¼› é‡åŒ–æ„ŸçŸ¥è®­ç»ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ç§ä¼ªé‡åŒ–çš„è¿‡ç¨‹ï¼Œå®ƒæ˜¯åœ¨å¯è¯†åˆ«çš„æŸäº›æ“ä½œå†…åµŒå…¥ä¼ªé‡åŒ–èŠ‚ç‚¹ï¼ˆfake quantization opï¼‰ï¼Œå¹¶å‚ä¸æ¨¡å‹è®­ç»ƒçš„å‰å‘æ¨ç†è¿‡ç¨‹æ¨¡æ‹Ÿå¼•å…¥ï¼Œä½†æ¨¡å‹çš„åå‘ä¼ æ’­è¿‡ç¨‹ä¾æ—§ä½¿ç”¨å…¨ç²¾åº¦æµ®ç‚¹æ•°è¿›è¡Œï¼› ä¼ªé‡åŒ–èŠ‚ç‚¹ï¼Œæ˜¯æŒ‡é‡åŒ–æ„ŸçŸ¥è®­ç»ƒä¸­æ’å…¥çš„èŠ‚ç‚¹ï¼Œç”¨ä»¥å¯»æ‰¾ç½‘ç»œæ•°æ®åˆ†å¸ƒï¼Œå¹¶åé¦ˆæŸå¤±ç²¾åº¦ï¼š æ‰¾åˆ°è¾“å…¥ã€æƒé‡ç­‰å¾…é‡åŒ–æ•°æ®çš„åˆ†å¸ƒï¼Œæ‰¾åˆ°å¾…é‡åŒ–æ•°æ®çš„æœ€å¤§å’Œæœ€å°å€¼ï¼› æ¨¡æ‹Ÿä½æ¯”ç‰¹é‡åŒ–å¸¦æ¥çš„ç²¾åº¦æŸå¤±ï¼ŒæŠŠè¯¥æŸå¤±ä½œç”¨åˆ°ç½‘ç»œæ¨¡å‹ä¸­ï¼Œä¼ é€’ç»™æŸå¤±å‡½æ•°ï¼Œè®©ä¼˜åŒ–å™¨åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹è¯¥æŸå¤±å€¼è¿›è¡Œä¼˜åŒ–ï¼Œ å°½å¯èƒ½å‡å°‘ç”±äºä¼ªé‡åŒ–æ“ä½œè€Œå¼•èµ·çš„ç²¾åº¦ä¸‹é™ï¼› å…ˆé¥±å’Œæˆªæ–­å¤„ç†ï¼š$clamp(x,x_{min}, x_{max}) &#x3D; \\min(\\max(x,x_{min}), x_{max})$ï¼› å†Float-&gt;Int-&gt;Floatï¼š ç¦»çº¿é‡åŒ–ï¼šæŒ‡è®­ç»ƒåé‡åŒ–(Post-Training Quantization)ï¼š åŠ¨æ€ç¦»çº¿é‡åŒ–(PTQ, Dynamic)ï¼š åŠ¨æ€ç¦»çº¿é‡åŒ–ä»…å°†æ¨¡å‹ä¸­ç‰¹å®šç®—å­çš„æƒé‡ä»FP32ç±»å‹æ˜ å°„æˆ INT8&#x2F;16 ç±»å‹ï¼Œbiaså’Œæ¿€æ´»å‡½æ•° åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€é‡åŒ–ã€‚ä½†æ˜¯å¯¹äºä¸åŒçš„è¾“å…¥å€¼æ¥è¯´ï¼Œå…¶ç¼©æ”¾å› å­æ˜¯åŠ¨æ€è®¡ç®—çš„ï¼ˆâ€œåŠ¨æ€â€çš„ç”±æ¥ï¼‰ã€‚åŠ¨æ€é‡åŒ–æ˜¯å‡ ç§é‡åŒ–æ–¹æ³•ä¸­æ€§èƒ½æœ€å·®çš„ã€‚åŠ¨æ€é‡åŒ–å¸¸ç”¨äºéå¸¸å¤§çš„æ¨¡å‹ã€‚ é™æ€ç¦»çº¿é‡åŒ–(PTQ, Static)ï¼š é™æ€ç¦»çº¿é‡åŒ–ä½¿ç”¨å°‘é‡æ— æ ‡ç­¾æ ¡å‡†æ•°æ®ï¼Œé‡‡ç”¨ KL æ•£åº¦ç­‰æ–¹æ³•è®¡ç®—é‡åŒ–æ¯”ä¾‹å› å­ã€‚é™æ€é‡åŒ–ï¼ˆStatic quantizationï¼‰ä¸åŠ¨æ€é‡åŒ–çš„åŒºåˆ«åœ¨äºå…¶è¾“å…¥çš„ç¼©æ”¾å› å­è®¡ç®—æ–¹æ³•ä¸åŒï¼Œé™æ€é‡åŒ–çš„æ¨¡å‹åœ¨ä½¿ç”¨å‰æœ‰â€œcalibrateâ€çš„è¿‡ç¨‹ï¼ˆæ ¡å‡†ç¼©æ”¾å› å­ï¼‰ï¼šå‡†å¤‡éƒ¨åˆ†è¾“å…¥ï¼ˆå¯¹äºå›¾åƒåˆ†ç±»æ¨¡å‹å°±æ˜¯å‡†å¤‡ä¸€äº›å›¾ç‰‡ï¼Œå…¶ä»–ä»»åŠ¡ç±»ä¼¼ï¼‰ï¼Œä½¿ç”¨é™æ€é‡åŒ–åçš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­é‡åŒ–æ¨¡å‹çš„ç¼©æ”¾å› å­ä¼šæ ¹æ®è¾“å…¥æ•°æ®çš„åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ã€‚ä¸€æ—¦æ ¡å‡†å®Œæˆåï¼Œæƒé‡å’Œè¾“å…¥çš„ç¼©æ”¾å› å­éƒ½å›ºå®šï¼ˆâ€œé™æ€â€çš„ç”±æ¥ï¼‰ã€‚é™æ€é‡åŒ–çš„æ€§èƒ½ä¸€èˆ¬æ¯”åŠ¨æ€é‡åŒ–å¥½ï¼Œå¸¸ç”¨äºä¸­ç­‰æ¨¡å‹å’Œå¤§æ¨¡å‹ã€‚å› æ­¤å®é™…ä¸­åŸºæœ¬éƒ½æ˜¯åœ¨ç”¨é™æ€é‡åŒ–ã€‚ é™æ€ç¦»çº¿é‡åŒ–çš„ç›®æ ‡æ˜¯æ±‚å–é‡åŒ–æ¯”ä¾‹å› å­ï¼Œä¸»è¦é€šè¿‡å¯¹ç§°é‡åŒ–ã€éå¯¹ç§°é‡åŒ–æ–¹å¼æ¥æ±‚ï¼Œè€Œæ‰¾æœ€å¤§å€¼æˆ–è€…é˜ˆå€¼çš„æ–¹æ³•åˆæœ‰MinMaxã€KLDã€ADMMã€EQç­‰æ–¹æ³•ã€‚ å¯¹ç§°é‡åŒ–ä¸éå¯¹ç§°é‡åŒ–ï¼šå¯¹äºweightæƒé‡çš„é‡åŒ–ä½¿ç”¨å¯¹ç§°é‡åŒ–[-INT_MAX, INT_MAX]ï¼Œå¯¹äºactivateæ¿€æ´»çš„é‡åŒ–ä½¿ç”¨éå¯¹ç§°é‡åŒ–[0, INT_MAX]ï¼›","tags":[],"categories":[{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"}]},{"title":"Memo | Package and Device","date":"2023-09-19T14:56:53.000Z","path":"jottings/languages/shell/memo_package_device/","text":"Package Package System Package Management System Linux Release Version Debian Style (.deb) Debian, Ubuntu Red Hat Style (.rpm) Fedora, CentOS A package file is a compressed collection of files that make up a software package and may contain a large number of programs and the data files that support those programs. Metadata for the packet is included, such as a text description of the package and its contents. Other included are pre-installation and post-installation scripts (which perform configuration tasks before and after installation) Upper Tools and Underlying Tools: Linux Release Version Underlying Tool (install and delete packages) Upper Tool (search for metadata and resolve dependencies) Debian-Style dpkg apt, aptitude Fedora, CentOS rpm yum Search for metadata in the resource repository Style Command Debian apt update; apt search search_string Red Hat yum search search_string (e.g. yum search emacs) Install a package via resource repository Style Command Debian apt update; apt install package_name Red Hat yum install package_name Install a package via raw package files Style Command Debian dpkg â€“install &#x2F; -i package_file Red Hat rpm -i package_file (rpm -i emacs-22.1-7.fc7-i386.rpm) NOTE: Due to this command is executed by rpm, not analyzing dependencies for package_file, so if a dependency is missing, rpm will report error and exit. Uninstall a package Style Command Debian apt remove package_name &#x2F; dpkg -r package_name Red Hat yum erase package_name Upgrade package via resource repository Style Command Debian apt update; apt upgrade Red Hat yum update Upgrade package via package_file Style Command Debian dpkg â€“install package_file Red Hat rpm -U package_file List all package installed Style Command Debian dpkg â€“list &#x2F; -l Red Hat rpm -qa Determine whether a package is installed Style Command Debian dpkg â€“status package_name Red Hat rpm -q package_name Show the info for the installed package Style Command Debian apt show package_name Red Hat yum info package_name apt useful arguments: -y : default set yes in interactive shell; -f: solve the package dependencies; Device","tags":[{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Summa |Networks Tidbits","date":"2023-09-07T10:35:53.000Z","path":"jottings/networks/memo_network_tidbits/","text":"Tunneling: The basic principle is to create a virtual channel between the source and the target, through which the original packets is encapsulated in the packet of another protocol, and then transmitted between the source and the target. At the target end, the receiver unwarps the encapsulated packet, reverts it to the original packet, and gives it to the target application for processing. For example, VPN (Virtual Private Network), SSH Tunneling, GRE (Generic Routing Encapsulation, like IPv6 over IPv4).","tags":[{"name":"networks","slug":"networks","permalink":"https://stu-yue.github.io/tags/networks/"}],"categories":[{"name":"networks","slug":"networks","permalink":"https://stu-yue.github.io/categories/networks/"}]},{"title":"Memo | Olds and Ends","date":"2023-09-06T07:56:53.000Z","path":"jottings/languages/shell/memo_others/","text":"Difference between sh and bash: sh is usually symbolic link for dash; dash is a more lightweight shell, POSIX, designed to replace sh and provide faster startup and executions speeds; bash is an extended version of sh, and most scripts that conform to sh syntax should work fine in bash; In a nutshell, sh is bash, which enables the POSIX standard. POSIX, Portable Operating System Interface of UNIX In accordance with the POSIX specification, â€œWhen a line of code encounters an error, it does not continue to interpret subsequent lines.â€ However, in bash, even if an error occurs, it will continue to execute subsequent lines. To view cpu information: lscpu, or cat /proc/cpuinfo;","tags":[{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | Permission, Progress and Shell Environment","date":"2023-08-31T14:56:53.000Z","path":"jottings/languages/shell/memo_permission_progress_env/","text":"PermissionFirst of all, letâ€™s take a quick look at the permissions-related commands. id: To show the id number of the user. id username: chmod: To change the mode of files. symbolic examples: 123u (user), g (group), o (other), a (all)+, -, =u+x u-x +x[=a+x] o-rw, go=rw u+x,go=rw umask: To set default file permissions (before creating). an example: 1234# umask is 0002Original file mode | --- rw- rw- rw-Mask | 000 000 000 010Result | --- rw- rw- r-- su: To run the shell as another user. su - username, - can enter the home directory. sudo: To execute the command as another user. chown: To change the file owner. chown [owner[:group]] file..., here are some examples: Example Explanation bob change the file owner to bob bob:users change the file owner to bob, group to users :admins change the group to admins, file owner remains the same bob: change the file owner to bob, group to bobâ€™s login group chgrp: To change the group ownership of files. chgrp groupname file... passwd: To change the userâ€™s password. passwd username: set userâ€™s password. User information is stored in /etc/passwd, group information is stored in /etc/group; use the command cat /etc/passwd to have a quick look. 123456789101112131415161718192021cat /etc/passwd | grep ubuntu # username:passwd:uid:gid:comment:home_dir:shell# passwd (x) denotes that password is protected in /etc/passwd# comment store some useful comments (like username)ubuntu:x:1000:1000:ubuntu:/home/ubuntu:/bin/bash sudo cat /etc/shadow | grep ubuntu #username:passwd(encrypted):last_modify_time:min_interval:max_intervalubuntu:$1$oQIzlBrL$MErhwMGkTzqaeWkJNzpUh1:19132:0:99999:7::: cat /etc/group | grep cdrom # groupname:passwd:gid:group_membercdrom:x:24:ubuntu,yue sudo cat /etc/gshadow | grep test # groupname:passwd:group_manager:group_membertest:*:yue:ubuntu Permission Overview: r w x File readable writable executable Directory readable writable to files in the directory enterable to the directory Home directory default permission: user &#x3D;rwx, go&#x3D;r-x ; setuid (s/S &lt;-&gt; x/-, 4000/u+s) : It set valid user ID from the running userâ€™s ID to the file ownerâ€™s ID; setgid (g/G &lt;-&gt; x/-, 2000/g+s): Run not with the permissions of the group to which the user who started it belongs, but with the group that owns the file. In other words, the process gid is the same as the file gid. sticky (t/T &lt;-&gt; x/-, 1000/o+t): It has no effect on files, but when it is used on a directory, all files in the directory can only be deleted or moved by their owner. File Type: Tag Type - a normal file d a directory l a symbolic link (real file property is the file property that the symbolic link points to) c a character device file (process bytes stream, like terminal) b a block device file (process blocks, like hard-disk or CD-ROM) User and GroupBecause the permission is too large, you can even delete system files and crash the system. Therefore, you are not recommended to directly use root account. On Linux systems, sudo is used as the default root identity for standard users. Next, we have some commands for managing users and groups. groupadd: create a new work group, whose info is added to /etc/group, /etc/gshadow and so on. [-g gid] (specify the id of new group), -r (create system working groups) groupdel: delete a group gpasswd [options] groupname: management tool the /etc/group and /etc/gshadow -a/d username (add&#x2F;delete user to group) -A (specify the manager) -r/R (cancel the password for the group, then only group member can newgrp to access the group) -M user1,user2... add users to group groupmod: change the group information -g gid (change group id) -n new_name old_name (change group name) newgrp groupname: Itâ€™s using the same account another group name, to log into the system again. useradd: create a new user. -m/M (automatically &#x2F; not create a user home directory), -g (specify the login group), -G grp1,grp2... (specify the supplementary groups) -d (specify the starting directory for the user to log in to), -r (create a system account) -s (specify the login shell) -n (cancel creating a group with the user name) -p (specify the password, or later run the command passwd to set) useradd -m -g root username, useradd -d /home/test username userdel: -r (recursively delete) Initial Login Group, is a group that a user owns immediately upon login. Itâ€™s usually specified with -g when creating a user. The GID in the user info (/etc/passwd) is login group. A userâ€™s additional group is to assign additional permission to the specified user. (There can be only one login group and multiple supplementary group) usermod: modify the settings of the user account. -d: set login directory of the user account -e: set validity period â€¦ -g: set the login group â€¦ -G: set the supplementary group â€¦ -s: set the shell used after login â€¦ -l new_name old_name: set the new username â€¦ -L/U: lock&#x2F;unlock the account â€¦ -p: set the new password â€¦ ProgressWhen the system starts, the kernel initializes some of its own activities as Init Process (PID 1). In turn, a series of shell scripts called Init Scripts (located in /etc) are run, which can start all system services. Many of these system services are implemented in the form of daemons, which run only in the background without any user interface (inaccessible). Here are some of the command-line tools available: ps: To view the snapshot of process status; common parameter aux (show all processes) 1234567ubuntu@VM-16-17-ubuntu:/etc$ ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND# TTY: ? denotes terminal running locally, Pts/n denotes terminal running remotely# VSZ: virtual memory size# RSS: physical memory size occupied by process# STAT: R(running), S(sleeping), D(uninterruptible sleeping), T(terminal), Z(zombie) &lt;(high priority) N(low priority) Ctrl-C: send a SIGIN Ctrl-D: send a EOF Ctrl-Z: send a SIGSTP, pause ongoing process on the terminal so as to be resumed when necessary. top: To displays a continuously updated list of system process in order of process activity (default, refresh per 3s); jobs: bg: fg: kill: To send signals to programs (kill [-signal] PID...); NO. NAME EXPLANATION 1 HUP Hang up, this signal is used to tell the program that the control terminal has â€œhung up.â€ You can show what this signal does by closing a terminal session. Foreground programs running on the current terminal will receive this signal and terminate. Many daemons also use this signal to re-initialize. 2 INT like Ctrl-c 9 KILL The KILL signal is never sent to the target program. Instead, the kernel immediately terminates the process. When a process is terminated in this way, it has no opportunity to do any â€œcleaningâ€ or saving work. 15 TERM Terminal, this is default signal sent by KILL 18 CONT Continue, after getting a stop signal, program will be resumed by CONT 19 STOP like KILL, STOP is not sent to the target process, so it cannot be ignored å…¶ä»–å¸¸ç”¨ä¿¡å·ï¼š NO. NAME EXPLANATION 3 QUIT 11 SEGV If a program uses memory illegally, this signal will be sent 20 TSTP Ctrl-z will trigger this signal to cause terminal stop, unlike STOP, it can be ignored killall: To send signals to multiple processes that match a particular program or username (killall [-u user] [-signal] name...); shutdown: To shutdown the machine or reboot; Shell Environment printenv: set: To display existing shell variables in the system and set new variable values for shell variables. When user log in to the system, the bash program starts and reads a series of configuration scripts (startup files that define a default environment for all users), then it reads the startup files in the home directory that define the userâ€™s personal shell environment. The exact startup order depends on the type of shell session you want to run. There are two types, one is login shell session (need username and password), the other is non-login shell session (start under the GUI). Login shell startup order: File Usage &#x2F;etc&#x2F;profile global conf script applying to all users ~&#x2F;.bash_profile userâ€™s personal startup file, used to extend or override settings in global conf script ~&#x2F;.bash_login if ~&#x2F;.bash_profile is not found, bash will try to read this script Non-login shell startup order: File Usage &#x2F;etc&#x2F;bash.bashrc global conf script applying to all users ~&#x2F;.bashrc userâ€™s personal startup file, used to extend or override settings in global conf script In addition to reading the startup files above, non-login shell also inherit the environment settings of their parent process, usually a login shell. In general usersâ€™ points, the file ~&#x2F;.bashrc is probably the most important startup file because itâ€™s almost always read. Non-login shells read it by default, and most startup files for login shells are written in such a way that they can read ~&#x2F;.bashrc . The below is a typical .bash_profile file (From CentOS 4): 12345678# .bash_profile# Get the aliaes and functionsif [ -f ~/.bashrc ]; then. ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/binexport PATH export: export environment variables; alias: create alias for command; Refref1","tags":[{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | Parameter Estimation","date":"2023-08-30T05:56:53.000Z","path":"jottings/mathematics/memo_mle_mae_bayes/","text":"Through this note, I hope to deepen my understanding of probability distribution and inference. Preface Probability: to predict results obtained in the next observation when parameters are known; Statistic&#x2F;Likelihood: to estimate parameters about properties when the result of observations are known; Parametric Method: assume that the learned distribution has a specific functional form (like Gaussian distribution or exponential p.d.f), we only estimate the parameters in these functions. Nonparametric Method: use the training samples to estimate the density of any point in the domain. Nonparametric methods also have parameters, we just donâ€™t assume any specific functional form for distribution; Actually, nonparametric methods treat all training samples as parameters; example: kernel density estimation; Under the joint distribution $p_{X,Y}(X,Y)$: When the effect of $Y$ is removed from the joint distribution $p_{X,Y}(X,Y)$, marginal distribution $p_X(X)$ is called marginal likelihood; When $X$ has not yet been observed, marginal distribution $p_Y(Y)$ is called prior distribution; Posterior Distribution: $p(\\theta|\\mathcal{D}) &#x3D; \\frac{p(\\mathcal{D},\\theta)}{p(\\mathcal{D})}$, concentrating Population Info, Sample Info and Prior Info; $p(\\mathcal{D})$ is marginal likelihood; $\\text{Posterior} &#x3D; \\frac{\\text{Likelihood}\\times \\text{Prior}}{\\text{Marginal Likelihood}}$, in terms of $p(Y|X) &#x3D; \\frac{1}{Z}p(X|Y)p(Y)$, $Z&#x3D;p(X)&gt;0$ is a normalized constant such that $p(Y|X)$ is a valid probability distribution. The Views Frequentist: Data are repeatable random sample - there is a frequency; Underlying parameters remain constant during this repeatable process; Parameters are fixed value; statistical inference: Population Info + Sample Info MLE, MAP; Bayesian: Data are observed from the realized sample; Parameters are unknown (random variable) and described probabilistically (prior distribution); statistical inference: Population Info + Sample Info + Prior Info (Main Diff); Bayesian Estimation; Notations Training Data: $\\mathcal{D} &#x3D; { (\\mathbf{x_1}, y_1),\\cdots,(\\mathbf{x}_n, y_n) }$; Model Parameter: $\\theta$; New Data: $x^*$; Maximum Likelihood Estimation Objective is$$\\theta_{MLE}^* &#x3D; \\arg\\max_\\theta p(\\mathcal{D}|\\theta)$$ $p(\\mathcal{D}|\\theta)$ is likelihood, not conditional probability; Usually, we define$$\\mathscr{l}(\\theta) &#x3D; p(\\mathcal{D}|\\theta) \\\\mathscr{ll}(\\theta) &#x3D; \\ln \\mathscr{l}(\\theta)$$So, objective is equivalent to$$\\theta_{MLE}^* &#x3D; \\arg\\max_\\theta \\mathscr{ll}(\\theta)$$That is, we seek those values for the parameters in $\\theta$ which maximize $p(\\mathcal{D}|\\theta)$. The MLE solution is usually obtained by setting$$\\frac{\\partial \\mathscr{ll}(\\theta)}{\\partial\\theta} &#x3D; 0$$ However, the modelâ€¦ Does not incorporate prior belief; Easy to overfit the data; Maximum A Posteri Estimation Objective is$$\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta p(\\theta|\\mathcal{D})$$Since we have Bayes rule:$$p(\\theta | \\mathcal{D}) &#x3D; \\frac{p(\\mathcal{D})p(\\theta)}{p(\\mathcal{D})}$$Our objective is equivalent to$$\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta p(\\mathcal{D}|\\theta)p(\\theta)$$Further, by taking the log$$\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta {\\ln p(\\mathcal{D}|\\theta) + lnp(\\theta) } \\\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta { \\mathscr{ll}(\\theta) + \\ln p(\\theta) }$$Thus, our final goal is to find$$\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta { \\mathscr{ll}(\\theta) + \\ln p(\\theta) }$$The difference between MAP and MLE is the â€œextraâ€ term - $p(\\theta)$. The term is: our prior (belief) also can be seen as penalty (regularization) - to reduce the overfitting. For $p(\\theta|\\mathcal{D})$, in terms of point estimation for $\\theta$, using the maximum value is called Maximum A Posterior Estimation; using the median value is called Posteriror Median Estimation; using the expectation value is called Posterior Expectation Estimation; Bayesian Estimation $p(\\theta|\\mathcal{D})$ (itâ€™s the result of adjustments to prior $p(\\theta)$ by population and sample); Equal Ignorance: If thereâ€™s no information about the prior distribution, assume $\\theta \\sim U(0,1)$ ; Learning: Computing the posterior $p(\\theta|\\mathcal{D})$ ; Prediction: $p(\\hat y | x^*,\\mathcal{D}) &#x3D; \\int_\\theta p(\\hat y | x^*,\\theta)p(\\theta|\\mathcal{D})d\\theta$ ; Both MLE and MAP return only single and specific values for the paramter $\\theta$; Bayesian estimation, by contrast, calculates fully the posterior distribution $p(\\theta|\\mathcal{D})$, and making prediction by considering all possible $\\theta$. Thus, for Bayesian methods: The prediction is optimal Avoid the overfitting Bayesian is powerful, butâ€¦ We need to compute posterior distribution $p(\\theta|\\mathcal{D})$, and$$p(\\theta|\\mathcal{D}) &#x3D; \\frac{p(\\mathcal{D}|\\theta)p(\\theta)}{\\int p(\\mathcal{D},\\theta)d\\theta}$$In practice, evaluating this posterior is usually intractable due to the complex integralsâ€¦ ReferenceMainly Ref Ref2 Ref3","tags":[{"name":"math","slug":"math","permalink":"https://stu-yue.github.io/tags/math/"}],"categories":[{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"}]},{"title":"Memo | Algebra Basis","date":"2023-08-27T07:56:53.000Z","path":"jottings/mathematics/memo_algebra_basis/","text":"**Positive Definiteness of the Norm: ** According to the usual definition, a norm should satisfy the property of positive definiteness which means that a norm must have a non-negative value for non-zero vectors and only attain zero when the vector is the zero. **Norm and Distance Evaluation: ** Norm Distance $L_0\\ \\text{norm}$ : $ $L_1\\ \\text{norm}$ : $ $L_2\\ \\text{norm}$ : $ $L_p\\ \\text{norm}$ : $ $\\text{Infinite norm}$ : $ Normed Space: Normed space introduces a norm (or length, modulus) concept on the basis of linear space.","tags":[{"name":"algebra","slug":"algebra","permalink":"https://stu-yue.github.io/tags/algebra/"}],"categories":[{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"}]},{"title":"Summa | Intro of Statistical ML","date":"2023-08-27T07:56:53.000Z","path":"jottings/statistics_ml/summa_intro/","text":"If a system is able to improve its performance by executing a certain process, it is called learning. 1 Basis Hypothesis Space: The set of functions that includes all possible models to be learned. Common Steps: Attain a finite training data set. Determine the set of learning models. Determine the criteria for model selection (learning strategies). Develop algorithms for solving the optimal model (learning algorithm). Select optimal model according to criteria. Use the learned optimal model to predict or analyze new data. Problem Types: Classification&#x2F;Tagging (outputs take a finite number of discrete values), Regression (function fitting, real values) Model Types: Discriminative Model: directly model $p(Y|X)$; Cons: easy to learn, high classification accuracy; Generative Model: model $p(X, Y)$, usually translating to modeling the prior distribution $p(Y)$ and class conditional distribution $p(X|Y)$, due to ($p(X, Y)&#x3D; P(X|Y)p(Y)$); Cons: add the prior distribution [main diff], model the data generation process;","tags":[{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"},{"name":"statistic","slug":"statistic","permalink":"https://stu-yue.github.io/tags/statistic/"}],"categories":[{"name":"statistics_ml","slug":"statistics-ml","permalink":"https://stu-yue.github.io/categories/statistics-ml/"}]},{"title":"Memo | See the World through Shell","date":"2023-08-27T07:56:53.000Z","path":"jottings/languages/shell/memo_see_the_world_through_shell/","text":"In this post, thereâ€™re other commands we should be familiar with: echo: To display a line text. -e (explain the escape sequences) clear: history: To display the history list content. list history commands: sequence conduct !! repeat the last command executed !number repeat the number line command in the history !string repeat the command starting with this string !?string repeat the command containing this string Expansions in Shell Mathematical Expression: Format: $((expression)), for example, echo $((2 + 2)); Operators: +, -, *, / (integer division), %, ** (exponentiation); Curly Brackets (or Braces): Curly braces can create multiple text characters. Generally speaking, a pattern in curly braces may contain a header and a postscript. The curly brace expression itself may contain a list of strings separated by commas, an integer interval, or a single character interval. Whitespace characters cannot be embedded in this mode. echo Number_&#123;1..5&#125;, echo &#123;Z..A&#125;, echo Front-&#123;A,B,C&#125;; mkdir &#123;2007..2009&#125;-0&#123;1..9&#125; &#123;2007..2009&#125;-&#123;10..12&#125; Furthermore, curly braces can be nested: 12echo a&#123;A&#123;1,2&#125;,B&#123;3,4&#125;&#125;baA1b aA2b aB3b aB4b Parameter Expansion: Command Substitution: Use the output of a command as expansion mode: ls -l $(which cp), echo$(ls), file $(ls /usr/bin* | grep zip); In the old shell, [&#96;&#96;] can replace [$()]: 1ls -l `which cp` Double Quotation: In double quotes, the special characters used by the shell lose their special meaning and are treated as ordinary characters. Mathematical expansion, parameter expansion and command substitution are still performed. (Double quotation can retain whitespace) ls -l &quot;two words.txt&quot;, echo &quot;$USER $((2+2)) $(cal)&quot;; echo &quot;$(cal)&quot; is different with echo $(cal), try it. Single Quotation: Single quotation disables all mode expansions. 123456ubuntu@VM-16-17-ubuntu:~$ echo text ~/*.txt &#123;a,b&#125; $(echo foo) $((2+2)) $USERubuntu@VM-16-17-ubuntu:~$ echo &quot;text ~/*.txt &#123;a,b&#125; $(echo foo) $((2+2)) $USER&quot;ubuntu@VM-16-17-ubuntu:~$ echo &#x27;text ~/*.txt &#123;a,b&#125; $(echo foo) $((2+2)) $USER&#x27;text /home/ubuntu/lazy_dog.txt /home/ubuntu/ls.txt a b foo 4 ubuntutext ~/*.txt &#123;a,b&#125; foo 4 ubuntutext ~/*.txt &#123;a,b&#125; $(echo foo) $((2+2)) $USER **Backslash: ** \\ can escape special characters in shell, but not in single quotes. 12echo &quot;The balance for user $USER is: \\$5.00&quot;mv bad\\&amp;filename good_filename NOTE: 1$&quot;abc&quot;, $&quot;\\n&quot; The above is a special string conversion syntax used to localize strings (with Settings such as the environment variable LANG or LC_MESSAGES). 1$&#x27;abc&#x27;, $&#x27;\\n&#x27;, $&#x27;ab\\tc&#x27; When you use the form $â€™abcâ€™ in the Shell, the Shell extends the string and replaces the special characters with the corresponding escape sequence.","tags":[{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | Redirection","date":"2023-08-25T06:56:53.000Z","path":"jottings/languages/shell/memo_redirection/","text":"Input&#x2F;output redirection is achieved by modifying file pointers. When redirection occurs, file descriptors themselves are not changed, instead, itâ€™s the file pointers associated with the file descriptors that are altered. Manipulation of File Descriptors in Shell In redirection, &amp; is used to indicates the following numbers is file descriptor rather than a filename. Output Redirection: stdiout redirection: command &gt;file: [overwrite], stdout overwrites the file. &gt; file: clear the content. command &gt;&gt;file: [append], stdout appends to the file. stderr redirection: command 2&gt;file: [overwrite], stderr overwrites the file. command 2&gt;&gt;file: [append], stderr appends to the file. Both stdout and stderr: command &gt;file 2&gt;&amp;1: [overwrite], both stdout and stderr overwrite the file. command &gt;&gt;file 2&gt;&amp;1: [append], both stdout and stderr append to the file. command &gt;file1 2&gt;file2: stdout overwrites the file1, stderr overwrites the file2. command &gt;&gt;file1 2&gt;&gt;file2: stdout appends to file1, stderr appends to file2. command &gt;file 2&gt;file: [not recommend] file is opened twice, leading to resource competition. command &gt;&gt;file 2&gt;&gt;file: [not recommend] file is opened twice, leading to resource competition. Input Redirection: command &lt;file: take the contents of the file as the input to command. 1234#!/bin/bashwhile read str; do echo $strdone &lt;readme.txt command &lt;&lt;END: read data from standard input (keyboard) until meeting the delimiter END (defined by the user). command &lt;file1 &gt;file2: input by file1, and output to file2 &amp;&gt;: redirect both stdout and stderr to the same location (usually a file). &gt;&amp;: redirect the output of one file descriptor to another &gt;&amp;-: equal to redirection to /dev/null PipelinePipeline is used to link the stdout of the previous instruction as the stdin of the next instruction. Pipeline is often used to perform complex operations on data. Itâ€™s possible to put several commands together to form a pipeline (usually called filter). For example: 1ls /bin /usr/bin | sort | uniq | less CommandThereâ€™s some useful command in this memo: cat: To link file. cat can accept not one parameter, so it can concatenate the file: cat movie.mpeg.0* &gt; movie.mpeg; sort: To sort the text lines. uniq: To report&#x2F;omit the repetitive lines. grep: To print the matching rows. -i (ignore upper&#x2F;lower), -v (reverse find, print mismatching lines), -n (show the matching lines), -r (recursively find), -l (only print matching filename), -c (only print the number of matching line) wc: To print the LF, word, bytes of the text. -c (bytes), -l (lines), -w (words) head&#x2F;tail: To print first&#x2F;last part of text. -n (lines), -c (bytes) tail -f filename: continue to monitor this file, when the new is added to the file, they appear immediately on the screen. tee: read from stdin, and write to stdout and file. -a (append mode), -i (ignore-interrupts) ls -l | tee -a ls.log : print the content both in the stdout and file. ls /usr/bin | tee ls.log | grep zip","tags":[{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | GIL and Coroutine","date":"2023-08-10T08:01:53.000Z","path":"jottings/languages/python/memo_GIL_and_coroutine/","text":"GIL (Global Interpreter Lock) GIL is not a characteristic of Python itself, but rather a characteristic to CPython, the reference implementation of Python. In CPython, GIL is a mutex lock used to ensure that only on thread is executing at a time within a process. In the absence of the GIL, itâ€™s possible for multiple threads executing the same code simultaneously to cause incorrect reference counting of variables, leading to the garbage collector directly reclaiming the variables involved in the executed code. This can result in errors when other threads attempt to use those reclaimed variables. How to work: Each thread acquires the GIL at the beginning of its execution to prevent other threads from preempting. Similarly, after each thread completes a segment of code (or before system calls that may cause blocking, such as IO operations), it releases the GIL to allow other threads to utilize resources. In CPython, thereâ€™s another mechanism called check_interval, where the interpreter periodically checks the status of the GIL lock for threads. After a certain interval, the interpreter forces the current thread to release the GIL, allowing other threads to have opportunity to execute. Overall, each Python thread is encapsulated in a similar loop structure. Letâ€™s take a look at the following code: 12345678910111213for (;;) &#123; if (--ticker &lt; 0) &#123; ticker = check_interval; /* Give another thread a chance */ PyThread_release_lock(interpreter_lock); /* Other thread may run now */ PyThread_acquire_lock(interpreter_lock); &#125; bytecode = *next_instr++; switch(bytecode) &#123; /* execute the next instruction ... */ &#125;&#125; The above example represents instruction counting, while the current approach is mostly based on time slicing. Hereâ€™s another example that demonstrates GILâ€™s working principle: 123456789101112131415161718# coding=utf-8from threading import Threadfrom multiprocessing import Processdef test(): # endless loop for full CPU utilization while True: pass# multi-thread version:# t1 = Thread(target=test)# multi-process version:t1 = Process(target=test)t1.start()# main thread executionwhile True: pass When the multi-thread code running, we can observe the CPU utilization from htop as shown below: 121 [50%]2 [50%] According to the above, we can know that each thread spends their a half time waiting for GIL. Additionally, the multi-process version as shown below: 121 [100%]2 [100%] The other way to utilize multi-core CPU is Multi-Process or Coroutine GeneratorGenerator contains the yield keyword to produce values. It has the following characteristics: Laziness: Generators are lazy in nature, meaning they produce values on-demand as requested by the caller, rather than generating all the values at once. This lazy evaluation allows for efficient memory usage, especially when dealing with large or infinite sequences. Memory efficiency: Due to their lazy evaluation, generators are memory-efficient. Iterability: Generators are iterable objects, which means they can be looped over using a for loop or consumed by other iterable functions like list() or sum(). They provide a convenient way to iterate over a sequence of values without the need to store the entire sequence in memory. State persistence: Generators maintain their internal state between successive calls. When a generator function is paused at a yield statement, the local variablesâ€™ values are preserved. This allows the generator to resume execution from where it left off, retaining the necessary information to generate the next value. Infinite sequences: Generators can be used to represent infinite sequences since they generate values on-the-fly. Function-like behavior: Generators are defined using the def keyword like regular functions, and they can have parameters, return values, and other function features. However, they differ in their execution behavior, as they can be paused and resumed. When the generator function finishes executing (no more yield statements or returns), the generator object raises a StopIteration exception. yield from is a syntactic sugar that allows delegation of generator execution within a generator function. It provides a concise way to call a sub-generator from a parent generator and directly pass the values yielded by the sub-generator to the parent generator. 123456789101112def sub_generator(): yield &#x27;A&#x27; yield &#x27;B&#x27; yield &#x27;C&#x27; def parent_generator(): yield &#x27;START&#x27; yield from sub_generator() yield &#x27;END&#x27; for item in parent_generator(): print(item) yield and send are used together to allow the generator function to receive values during each iteration and send values back into the generator function for processing. Here is an example of how yield and send are used: 1234567891011121314151617def generator_function(): result = yield # First call, receives a value sent by send() while True: print(&#x27;gen&#x27;, result) result = yield resultgen = generator_function()# Start the generatornext(gen) # or gen.send(None)output = gen.send(&quot;Hello&quot;)print(&#x27;out&#x27;, output)output = gen.send(&quot;World&quot;)print(&#x27;out&#x27;, output)# print result:# gen Hello# out Hello# gen World# out World generator.throw(AnyException) allows generator to throw an Exception, and generator.close() can stop the generator. CoroutineCoroutines are implemented using generator functions and the yield statement. The principle of coroutines is as follows: Coroutine Function Definition: Define a generator function as a coroutine function. This function can use the yield statement to specify suspension points, where it pauses execution and returns a value to the caller. Coroutine Initialization: Create a coroutine object by calling the coroutine function. Coroutine Iteration: Use the next() function or the .send() method of the coroutine object to iterate and execute the coroutine. When the coroutine encounters a yield statement, it pauses execution and returns the result to the caller. Coroutine Resumption: When the caller sends a value to the coroutine (using the .send() method), the coroutine resumes execution from the last paused position and uses the sent value as the result of the yield expression. Coroutine Termination: When the coroutine reaches the end of the function or encounters a StopIteration exception, the coroutine terminates. Further calls to the .send() method on the coroutine object will raise a StopIteration exception. Coroutines allow achieving concurrent execution without the need for multiple threads or processes. Coroutines can switch between different execution paths, enabling efficient asynchronous programming. Coroutines can also delegate to other coroutines using the yield from statement, enabling more complex cooperation and task decomposition. Python provides the asyncio module to support coroutine programming, where the async and await keywords offer a more concise syntax for defining and managing coroutines. With asyncio, it becomes easy to write asynchronous programs and handle tasks like I&#x2F;O operations, network communication, and more. Itâ€™s important to note that coroutines run in a single thread, so their performance may not be as good as multi-threading or multiprocessing when it comes to CPU-bound tasks. However, in I&#x2F;O-bound tasks, coroutines shine because they can effectively utilize the waiting time for I&#x2F;O to execute other tasks. Async&#x2F;Await async def is a keyword combination used in Python to define asynchronous functions. An asynchronous function is a special type of function that can contain await expressions, which suspend the execution of the function and wait for the completion of asynchronous operations. Here is a example: 12345678910111213141516import asyncio# Define an asynchronous functionasync def async_func(): print(&quot;Start&quot;) await asyncio.sleep(1) # Suspend function execution using await, waiting for the completion of an asynchronous operation print(&quot;End&quot;)# Run the asynchronous function in an event loopasync def main(): await async_func()# Create an event loop and run the main functionloop = asyncio.get_event_loop()loop.run_until_complete(main())loop.close() await is a keyword used to suspend the execution of an asynchronous function and wait for the completion of an asynchronous operation. await can only be used within an asynchronous context and is typically used in conjunction with async def. The general usage of await is as follows: Use await within an asynchronous function or coroutine to suspend its execution and wait for the completion of an asynchronous operation. For example: 123async def async_func(): result = await async_operation() # ç­‰å¾… async_operation() å¼‚æ­¥æ“ä½œçš„å®Œæˆ # ç»§ç»­å¼‚æ­¥æ“ä½œï¼Œä½¿ç”¨å¼‚æ­¥æ“ä½œçš„ç»“æœ result Note that await can only be used within asynchronous functions or coroutines. It is not valid to use await in synchronous code. Typically, await is followed by an awaitable object, such as an asynchronous function, coroutine, asynchronous iterator, etc. These awaitable objects must implement specific protocols, which include methods like __await__() or __aiter__(). The await expression invokes these methods to obtain an iterator or a context manager from the awaitable object and waits for its completion. Here are some common awaitable objects: Asynchronous functions or coroutines: Use await to wait for the execution of an asynchronous function or coroutine to complete. Asynchronous generators: Use await to iterate over asynchronous generators and wait for each generated value. Asynchronous iterators: Use await to iterate over asynchronous iterators and wait for each iteration value. Asynchronous context managers: Use await to enter and exit the context of an asynchronous context manager. For example: 123456async def async_func(): async with async_context_manager() as cm: await cm.do_something() # Wait for the completion of the asynchronous context manager async for item in async_iterator(): await process_item(item) # Wait for the completion of each item generated by the asynchronous iterator","tags":[{"name":"python","slug":"python","permalink":"https://stu-yue.github.io/tags/python/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"python","slug":"languages/python","permalink":"https://stu-yue.github.io/categories/languages/python/"}]},{"title":"Memo | Optimization Algorithm in Machine Learning","date":"2023-08-05T14:56:53.000Z","path":"jottings/mathematics/memo_optimization_alg/","text":"Reproduced in The Summary of Optimization Algorithm in ML For machine learning algorithms with diverse forms and characteristics, we have various optimization algorithms suitable for optimizing their objective functions. Apart from a few problems that can be solved using Brute Force Search to obtain the optimal solution, we can categorize the optimization algorithms used in machine learning into two types: Analytical Solutions: These algorithms aim to find the optimal solution to the objective function by solving mathematical equations or performing algebraic manipulations. They often involve setting derivatives or gradients to zero and solving the resulting equations. Analytical solutions are typically used for linear regression, logistic regression, and certain types of optimization problems with closed-form solutions. Numerical Optimization: These algorithms iteratively search for the optimal solution by evaluating the objective function at different points in the search space. They do not rely on explicit mathematical equations or derivatives. Numerical optimization methods include gradient-based algorithms like gradient descent and its variants, Newtonâ€™s method, stochastic gradient descent, and quasi-Newton methods. Global Optimization Methods: Heuristic Algorithm, Simulated Annealing, Particle Swarm Optimization, etc. Local Optimization Methods: Gradient Based: First Order Derivative: Gradient Descent: Second Order Derivative: Newton Method: Divide and Conquer: Coordinate Descent: SMO Algorithm: Staged Optimization: Dynamic Programming: The following picture illustrates the organization of this memorandum:","tags":[{"name":"optimization","slug":"optimization","permalink":"https://stu-yue.github.io/tags/optimization/"},{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"}],"categories":[{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"}]},{"title":"Memo | Exploring Linux Files and Directories","date":"2023-08-05T02:56:53.000Z","path":"jottings/languages/shell/memo_exploring_os/","text":"Letâ€™s start by learning some commands that are helpful for researching Linux systems. type: To explain how to interpret a command name. which: To show which executable program will be executed. man: To show command manual. apropos: To display a list of appropriate commands. info: To display the command info. alias: To create an alias for the command unalias: To cancel a alias for the command. ls: To list the files and directories in the current directory. -a, -d, -h, -r/--reverse, -l, -S[sort by size], -t[sort by modification time] file: To determine the file type. file filename is OK. less: To browse the content of a file, specifically, less is an improved version of more. less filename is OK. Commands Behavior Page UP or b Backward one window Page Down or space Forward one window UP Arrow Backward one line Down Arrow Forward one line [N]G Go to last line in file (or N lines) [N]g Go to first line in file (or N lines) &#x2F;characters Search forward for matching line n Repeat previous search h Display help. cpï¼š Options Implication -a, â€“archive Copy files and directories, along with their attributes, including ownership and permissions -i, â€“interactive Prompt the user for confirmation before overwriting an existing file (default disable) -r, â€“recursive -u, â€“update Update the content not already present in the original -v, â€“verbose Display detailed command operation information mv: Options Implication -i, â€“interactive Prompt the user for confirmation before overwriting an existing file (default disable) -u, â€“update Update the content not already present in the original -v, â€“verbose Display detailed command operation information rm: Options Implication -f, â€“force Directly delete the file even if its attributes are read-only, without requiring individual confirmation -i, â€“interactive Prompt the user for confirmation before overwriting an existing file (default disable) -r, â€“recursive -v, â€“verbose Display detailed command operation information ln: ln file hard_link creates a hard link, and ln -s item soft_link creates a soft link. Hard Links: A hard link is a direct reference to the same physical location of a file on the storage device. It creates an additional entry in the file system that points to the same inode (data structure representing a file) as the original file. Changes made to either the original file or the hard link are reflected in both, as they refer to the same underlying data. Hard links cannot reference directories or files on different file systems or partitions. Soft Links: A symbolic link is a special file that contains a path pointing to another file or directory. It acts as a pointer or shortcut to the target file or directory. Symbolic links are independent files and have their own inodes. Modifying the original file or symbolic link does not affect each other, as they are separate entities. Symbolic links can reference directories or files on different file systems or partitions. Soft links can be created to a non-existent filename (of course, if you use vi on this soft link file, Linux will automatically create a new file named â€œfilenameâ€). Hard links cannot be created in such cases since the file must already exist, and the inode must exist as well. Using ls -li can view the inodes of the files. drwxrwxr-x 2 â€˜s 2 is the number of hard links to a file. Besides, the usual number of inodes for a directory is 2 (include parent directory and itself .) tar: To create archive files (usually with the .tar extension) and archive files. create archive file: tar -cvf archive.tar file1 file2 directory/ -c (create archive file), -v (view details), -f (specify archive file) extract archive file: tar -xvf archive.tar -x (extract the content of archive files) compress archive file: tar -czvf archive.tar.gz directory/ -z (use gzip to compress) decompress archive file: tar -xzvf archive.tar.gz, tar -xjvf archive.tar.bz2 list the content of archive files: tar -tvf archive.tar tar -tf test.tar: view package structure tar -C dest_dir/ -x[z]vf test.tar[.gz] specified_dir_or_file...[path in -tf shows]: unzip the specified file&#x2F;directory in the package; unzip archive.zip -d dest_dir split and cat: split the tar.gz into small files, split: split -6/-b 3M -d -a 2 cud_test.tar.gz[dst_filename] cud_test.tar.gz_[out_filename] 12345cud_test.tar.gz_00cud_test.tar.gz_01cud_test.tar.gz_02cud_test.tar.gz_03cud_test.tar.gz_04 -&lt;line_N&gt; : split into a file every N lines -b &lt;bytes&gt; : split into a file every N bytes -d : specify the generated split file suffix in numeric form -a x : set the length of the sequence (suffix digits) cat cud_test.tar.gz_* &gt; cud_test.tar.gz : to concatenate split files; Before starting using commands, letâ€™s introduce wildcards that provide special characters to help you quickly specify a group of filenames. Wildcard Implication * match any sequence of characters, including zero characters. ? match any single character (excluding zero character) [character] match any single character within the specified character set [!character] match any single character without the specified character set [[:class:]] match any single character within the specified character class The following table lists the most commonly used character classes. Character Class Implication [:alnum:] match any single letter or digit [:alpha:] match any single letter [:digit:] match any single digit [:lower:] match any single lower letter [:upper:] match any single upper letter There are some examples constructed with wildcard: *, g*, b*.txt, Data???, [abc]*, BACKUP.[0-9][0-9][0-9], [[:upper:]], [![:digit:]]*, *[[:lower:]123] Service and Systemctl systemctl is a system service manager that actually combines the service and chkconfig commands together. 123456789systemctl is-enabled httpd.servicesystemctl status httpd.servicesystemctl list-unit-files --type=servicesystemctl restart httpd.servicesystemctl stop httpd.servicesystemctl reload httpd.servicesystemctl restart httpd.servicesystemctl enable httpd # bootstrapsystemctl disable httpd # not bootstrap service 12345service ssh startservice ssh stopservice ssh restartservice ssh statusservice --status-all","tags":[{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Hot Points","date":"2023-07-22T12:00:53.000Z","path":"jottings/tidbits/hot_points/","text":"Generate random numbers by reading thermal noise on CPU pins. Hot Plug, refers to the operation of inserting&#x2F;removing a device while it is running. In contrast, Cold Plug means do above operation while the device is powered off. Software versionâ€™s explanation: Version Description Snapshot Development version Alpha Internal beta Beta Public beta Pre (M) Similar to Alpha, sometimes subdivided into M_(Milestone) version RC(Release Candidate) During Beta stage, new features will continue to be added, but once the RC version is reached, there will mainly be on debugging and issue resolution. GA(General Availability) Some software may be labeled as â€œstableâ€ or â€œproductionâ€. Release&#x2F;Stable Current The latest version, but no necessarily a stable one. Eval There may be a monthly or fixed time limit for usage. Declarative Programming expresses the logic of a computation without describing its control flow. Many languages that apply this style attempt to minimize or eliminate side effects by describing what the program must accomplish in terms of the problem domain (what to do), rather than specifying all the details of how the program should achieve the result (how to do). Imperative Programming uses statements that change a programâ€™s state. Imperative Programming focuses on describing how a program operates step by step, rather than on high-level descriptions of its expected results. KVM: Kernel-based Virtual Machine, is a virtualization infrastructure used in the Linux kernel to turn the Linux kernel into a hypervisor; Hypervisor: creates and runs virtual machines, sometimes called a virtual machine monitor (VMM), like a meta-OS; IT resource pooled, OS and hardware decoupled, allocated according to needs; A computer on which a hypervisor runs one or more virtual machines is called a host machine, and each virtual machine is called a guest machine; (Type 1) Native or bare mental hypervisor: runs directly on the hostâ€™s hardware to manage guest operating systems. It takes the place of a host operating system and VM resources are scheduled directly to the hardware by the hypervisor. This type of hypervisor is most common in an enterprise data center or other server-based environments. KVM, Microsoft Hyper-V, and VMware vSphere are examples of a type 1 hypervisor. KVM was merged into the Linux kernel in 2007, so if youâ€™re using a modern version of Linux, you already have access to KVM. (Type 2) Hosted hypervisor: run on a conventional operating system as a software layer or application. It works by abstracting guest operating systems from the host operating system. VM resources are scheduled against a host operating system, which is then executed against the hardware. A type 2 hypervisor is better for individual users who want to run multiple operating systems on a personal computer. VMware Workstation and Oracle VirtualBox are examples of a type 2 hypervisor. (Emulator) The difference with the Hypervisor is that the Hypervisor runs the same VM and host CPU architecture, while the Emulator can be used to run systems or programs on other hardware platforms (arm, mips, x86). When used as a machine emulator, QEMU can run OSes and programs made for one machine (e.g. an ARM board) on a different machine (e.g. your x86 PC). By using dynamic translation, it achieves very good performance; QEMU can use other hypervisors like Xen or KVM to use CPU extensions (HVM) for virtualization. When used as a virtualizer, QEMU achieves near native performances by executing the guest code directly on the host CPU. When QEMU is used in conjunction with KVM, KVM provides hardware virtualization support, while QEMU is responsible for virtual machine simulation and management. In this configuration, KVM functions as a Hypervisor to directly interact with hardware and provide high-performance virtualization support, while QEMU runs on the upper layer of KVM and is responsible for VM simulation and management, including device simulation, VM creation, start, and stop. So while QEMU is not a traditional Hypervisor on its own, when used in conjunction with KVM, QEMU can work with KVM to provide a complete virtualization solution and act as part of a Hypervisor","tags":[{"name":"points","slug":"points","permalink":"https://stu-yue.github.io/tags/points/"}],"categories":[{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"}]},{"title":"TBR_compiler","date":"2023-07-22T12:00:53.000Z","path":"jottings/tidbits/tbr_compiler/","text":"ã€Šç¼–è¯‘åŸç†ã€‹è¯¾ä»¶æ¬è¿ â€”â€”&gt; æºåœ°å€ 1.1 ç¼–è¯‘å™¨ä½œç”¨ ç¼–è¯‘å™¨ï¼ˆCompilerï¼‰ è¯»å…¥ä»¥æŸç§è¯­è¨€ï¼ˆæºè¯­è¨€ï¼‰ç¼–å†™çš„ç¨‹åºï¼› è¾“å‡ºç­‰ä»·çš„ç”¨å¦ä¸€ç§è¯­è¨€ï¼ˆç›®æ ‡è¯­è¨€ï¼‰ç¼–å†™çš„ç¨‹åºï¼› é€šå¸¸ç›®æ ‡ç¨‹åºæ˜¯å¯æ‰§è¡Œçš„ï¼› è§£é‡Šå™¨ï¼ˆInterpreterï¼‰ ä¸ç”Ÿæˆç›®æ ‡ç¨‹åºï¼Œç›´æ¥æ ¹æ®æºç¨‹åºçš„è¯­ä¹‰æ‰§è¡Œæºç¨‹åºä¸­æŒ‡å®šçš„æ“ä½œï¼› Javaè¯­è¨€çš„å¤„ç†ç»“åˆäº†ç¼–è¯‘(.classå­—èŠ‚ç )å’Œè§£é‡Šï¼ŒPythonä¼šå°†ç¼–è¯‘çš„å­—èŠ‚ç (pyc)å­˜æ”¾äº_pycache_(å¯è·¨å¹³å°éƒ¨ç½²ï¼Œä¸€å®šç¨‹åº¦é˜²æºç æ³„éœ²ï¼Œimportçš„pyä¸å˜pycå°±ä¸å˜[æ£€æŸ¥pyå’Œpycçš„ä¿®æ”¹æ—¶é—´æ˜¯å¦ä¸€è‡´]) 1.2 ç¼–è¯‘å™¨çš„ç»“æ„ ç¼–è¯‘å™¨å¯ä»¥åˆ†ä¸ºåˆ†æéƒ¨åˆ†å’Œç»¼åˆéƒ¨åˆ† åˆ†æï¼ˆanalysisï¼‰éƒ¨åˆ† &#x2F; å‰ç«¯ï¼ˆfront endï¼‰ æŠŠæºç¨‹åºåˆ†è§£æˆç»„æˆè¦ç´ ï¼Œä»¥åŠç›¸åº”çš„è¯­æ³•ç»“æ„ï¼› ä½¿ç”¨è¿™ä¸ªç»“æ„åˆ›å»ºæºç¨‹åºçš„ä¸­é—´è¡¨ç¤ºï¼› åŒæ—¶æ”¶é›†å’Œæºç¨‹åºç›¸å…³çš„ä¿¡æ¯ï¼Œå­˜æ”¾åˆ°ç¬¦å·è¡¨ï¼› ç»¼åˆï¼ˆsynthesisï¼‰éƒ¨åˆ† &#x2F; åç«¯ï¼ˆback endï¼‰ æ ¹æ®ä¸­é—´è¡¨ç¤ºå’Œç¬¦å·è¡¨ä¿¡æ¯æ„é€ ç›®æ ‡ç¨‹åºï¼› å‰ç«¯éƒ¨åˆ†æ˜¯æœºå™¨æ— å…³çš„ï¼Œåç«¯éƒ¨åˆ†æ˜¯æœºå™¨ç›¸å…³çš„ï¼› ç¼–è¯‘å™¨åˆ†æˆæ‰§è¡Œé¡ºåºçš„ä¸€ç»„æ­¥éª¤ï¼š 1.3 è¯æ³•åˆ†æ è¯æ³•åˆ†æ&#x2F;æ‰«æï¼ˆlexical analysis&#x2F;scanningï¼‰ è¯»å…¥æºç¨‹åºçš„å­—ç¬¦æµï¼Œè¾“å‡ºä¸ºæœ‰æ„ä¹‰çš„è¯ç´ ï¼ˆlexemeï¼‰ &lt;token-name, attribute-value&gt; token-nameï¼šç”±è¯­æ³•åˆ†ææ­¥éª¤ä½¿ç”¨ï¼› attribute-valueï¼šæŒ‡å‘ç›¸åº”çš„ç¬¦å·è¡¨æ¡ç›®ï¼Œç”±è¯­ä¹‰åˆ†æ&#x2F;ä»£ç ç”Ÿæˆæ­¥éª¤ä½¿ç”¨ï¼› ä¾‹å­ position &#x3D; initial + rate * 60 &lt;id, 1&gt; &lt;&#x3D;, &gt; &lt;id, 2&gt;, &lt;+, &gt; &lt;id, 3&gt; &lt;*, &gt; &lt;number, 4&gt; 1.4 è¯­æ³•åˆ†æ è¯­æ³•åˆ†æ&#x2F;è§£æï¼ˆsyntax analysis&#x2F;parsingï¼‰ æ ¹æ®å„ä¸ªè¯æ³•å•å…ƒçš„ç¬¬ä¸€ä¸ªåˆ†é‡æ¥åˆ›å»ºæ ‘å‹çš„ä¸­é—´è¡¨ç¤ºå½¢å¼ï¼Œé€šå¸¸æ˜¯è¯­æ³•æ ‘ï¼ˆsyntax treeï¼‰ ä¸­é—´è¡¨ç¤ºå½¢å¼æŒ‡å‡ºäº†è¯æ³•å•å…ƒæµçš„è¯­æ³•ç»“æ„ï¼› 1.5 è¯­ä¹‰åˆ†æ è¯­ä¹‰åˆ†æï¼ˆsemantic analysisï¼‰ ä½¿ç”¨è¯­æ³•æ ‘å’Œç¬¦å·è¡¨ä¸­çš„ä¿¡æ¯ï¼Œæ£€æŸ¥æºç¨‹åºæ˜¯å¦æ»¡è¶³è¯­è¨€å®šä¹‰çš„è¯­ä¹‰çº¦æŸï¼› åŒæ—¶æ”¶é›†ç±»å‹ä¿¡æ¯ï¼Œç”¨äºä»£ç ç”Ÿæˆã€ç±»å‹æ£€æŸ¥ã€ç±»å‹è½¬æ¢ï¼› 1.6 ä¸­é—´ä»£ç ç”Ÿæˆ æ ¹æ®è¯­ä¹‰åˆ†æè¾“å‡ºï¼Œç”Ÿæˆç±»æœºå™¨è¯­è¨€çš„ä¸­é—´è¡¨ç¤ºï¼› ä¸‰åœ°å€ä»£ç ï¼ˆthree-address codeï¼‰ æ¯ä¸ªæŒ‡ä»¤æœ€å¤šåŒ…å«ä¸‰ä¸ªè¿ç®—åˆ†é‡ï¼›å¾ˆå®¹æ˜“ç”Ÿæˆæœºå™¨è¯­è¨€æŒ‡ä»¤ï¼› 1.7 ä¸­é—´ä»£ç ä¼˜åŒ– é€šè¿‡å¯¹ä¸­é—´ä»£ç åˆ†æï¼Œæ”¹è¿›ä¸­é—´ä»£ç çš„è´¨é‡ï¼›ï¼ˆæ›´å¿«ã€æ›´çŸ­ã€èƒ½è€—æ›´ä½ï¼‰ 1.8 ä»£ç ç”Ÿæˆ æŠŠä¸­é—´è¡¨ç¤ºå½¢å¼æ˜ å°„æˆç›®æ ‡è¯­è¨€ï¼›ï¼ˆå¯„å­˜å™¨åˆ†é…ã€æŒ‡ä»¤é€‰æ‹©ï¼‰ 1.9 å…¶ä»– ç¬¦å·è¡¨ç®¡ç†ï¼šè®°å½•æºç¨‹åºä¸­ä½¿ç”¨çš„å˜é‡çš„åå­—ï¼Œæ”¶é›†å„ç§å±æ€§ï¼› ç¼–è¯‘å™¨æ„é€ å·¥å…·ï¼šæ‰«æå™¨ï¼ˆLexï¼‰ã€è¯­æ³•åˆ†æå™¨ï¼ˆYaccï¼‰ã€è¯­æ³•åˆ¶å¯¼çš„ç¿»è¯‘å¼•æ“ï¼› ç¨‹åºè®¾è®¡è¯­è¨€çš„æ–°å‘å±•å‘ç¼–è¯‘å™¨è®¾è®¡è€…æå‡ºæ–°çš„è¦æ±‚ è®¾è®¡ç›¸åº”çš„ç®—æ³•å’Œè¡¨ç¤ºæ–¹æ³•æ¥ç¿»è¯‘å’Œæ”¯æŒæ–°çš„è¯­è¨€ç‰¹å¾ï¼Œå¦‚å¤šæ€ã€åŠ¨æ€ç»‘å®šã€ç±»ã€ç±»å± (æ¨¡æ¿) ã€â€¦ ç¼–è¯‘å™¨è®¾è®¡è€…è¿˜éœ€è¦æ›´å¥½åœ°åˆ©ç”¨æ–°ç¡¬ä»¶çš„èƒ½åŠ› RISCæŠ€æœ¯ã€å¤šæ ¸æŠ€æœ¯ã€å¤§è§„æ¨¡å¹¶è¡ŒæŠ€æœ¯ 1.10 ç¨‹åºè®¾è®¡è¯­è¨€çš„åŸºç¡€æ¦‚å¿µ é™æ€&#x2F;åŠ¨æ€ï¼š é™æ€ï¼šæ”¯æŒç¼–è¯‘å™¨é™æ€å†³å®šæŸä¸ªé—®é¢˜ï¼› åŠ¨æ€ï¼šåªå…è®¸åœ¨ç¨‹åºè¿è¡Œæ—¶åˆ»ä½œå‡ºå†³å®šï¼› ä½œç”¨åŸŸï¼š xçš„ä½œç”¨åŸŸæŒ‡ç¨‹åºæ–‡æœ¬çš„ä¸€ä¸ªåŒºåŸŸï¼Œå…¶ä¸­å¯¹xçš„ä½¿ç”¨éƒ½æŒ‡å‘è¿™ä¸ªå£°æ˜ï¼› é™æ€ä½œç”¨åŸŸï¼ˆstatic scopeï¼‰: é€šè¿‡é™æ€é˜…è¯»ç¨‹åºå¯å†³å®šï¼› åŠ¨æ€ä½œç”¨åŸŸï¼ˆdynamic scopeï¼‰: è¿è¡Œæ—¶ç¡®å®šxçš„æŒ‡å‘ï¼› ç¯å¢ƒä¸çŠ¶æ€ï¼š ç¯å¢ƒï¼ˆenvironmentï¼‰: æ˜¯ä»åå­—åˆ°å­˜å‚¨ä½ç½®çš„æ˜ å°„ï¼› çŠ¶æ€ï¼ˆstateï¼‰: ä»å­˜å‚¨ä½ç½®åˆ°å®ƒä»¬å€¼çš„æ˜ å°„ï¼›","tags":[{"name":"points","slug":"points","permalink":"https://stu-yue.github.io/tags/points/"}],"categories":[{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"}]},{"title":"TBR_Net_Info","date":"2023-07-22T12:00:53.000Z","path":"jottings/tidbits/tbr_net_info/","text":"1 IPTV å’Œ OTTIPTVï¼ˆInternet Protocol Televisionï¼‰æ˜¯ä¸€ç§é€šè¿‡Internet Protocolï¼ˆIPï¼‰åœ¨ä¸“ç”¨ç½‘ç»œä¸Šä¼ è¾“è§†é¢‘å’ŒéŸ³é¢‘å†…å®¹çš„æŠ€æœ¯ã€‚å®ƒä½¿ç”¨LANï¼ˆå±€åŸŸç½‘ï¼‰æˆ–WANï¼ˆå¹¿åŸŸç½‘ï¼‰ç­‰å°é—­ç½‘ç»œç”Ÿæ€ç³»ç»Ÿè¿›è¡Œæ“ä½œã€‚IPTVéœ€è¦ä¸“é—¨çš„è®¾å¤‡ï¼ˆå¦‚æœºé¡¶ç›’ï¼‰å’Œå®½å¸¦è¿æ¥ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è¿™äº›è®¾å¤‡è®¿é—®ä¼ ç»Ÿçš„ç”µè§†é¢‘é“ï¼Œå¦‚CBSã€CNNã€FOXã€HBOç­‰ã€‚IPTVçš„ä¼˜åŠ¿åœ¨äºæä¾›é«˜è´¨é‡çš„å›¾åƒå’Œå£°éŸ³ï¼Œå› ä¸ºå®ƒä½¿ç”¨ä¸“ç”¨ç½‘ç»œè¿›è¡Œä¼ è¾“ï¼Œä¸ä¼šå ç”¨ç”¨æˆ·çš„äº’è”ç½‘å¸¦å®½[2]ã€‚ OTTï¼ˆOver-The-Topï¼‰æ˜¯ä¸€ç§é€šè¿‡å…¬å…±äº’è”ç½‘ä¼ è¾“è§†é¢‘å†…å®¹çš„æŠ€æœ¯ã€‚OTTæœåŠ¡åŸºäºè§†é¢‘ç‚¹æ’­ï¼ˆVODï¼‰çš„åˆ†å‘ï¼Œç”¨æˆ·åªéœ€è®¢é˜…æœåŠ¡ï¼Œå°±å¯ä»¥é€šè¿‡è¿æ¥åˆ°äº’è”ç½‘çš„è®¾å¤‡æ’­æ”¾å†…å®¹ã€‚OTTæœåŠ¡çš„ä¼˜åŠ¿åœ¨äºæˆæœ¬è¾ƒä½ã€å®‰è£…ç®€ä¾¿ï¼Œå¹¶ä¸”æä¾›å„ç§å„æ ·çš„èŠ‚ç›®é€‰æ‹©ã€‚ç„¶è€Œï¼ŒOTTçš„è§†é¢‘è´¨é‡å–å†³äºç”¨æˆ·çš„äº’è”ç½‘è¿æ¥é€Ÿåº¦ï¼Œå¯èƒ½ä¼šå‡ºç°ç¼“å†²å¯¼è‡´å†…å®¹ä¸­æ–­çš„æƒ…å†µ[2]ã€‚ ä»¥ä¸‹æ˜¯IPTVå’ŒOTTä¹‹é—´çš„ä¸»è¦åŒºåˆ«ï¼š å†…å®¹ä¼ é€’å’Œç½‘ç»œç»“æ„ï¼š IPTVä½¿ç”¨å°é—­ç½‘ç»œï¼ˆLANã€WANï¼‰ï¼Œæä¾›å¹³ç¨³çš„å†…å®¹ä¼ é€’ï¼Œä¸ä¾èµ–äºäº’è”ç½‘å¸¦å®½ã€‚ OTTä½¿ç”¨å…¬å…±äº’è”ç½‘è¿æ¥ï¼Œä»»ä½•äººéƒ½å¯ä»¥è®¿é—®ï¼Œä½†æœåŠ¡è´¨é‡å–å†³äºç”¨æˆ·çš„äº’è”ç½‘é€Ÿåº¦ã€‚ è®¾å¤‡éœ€æ±‚ï¼š OTTä¸éœ€è¦é¢å¤–çš„ç¡¬ä»¶è®¾å¤‡ï¼Œåªéœ€ä½¿ç”¨ä¸“ç”¨åº”ç”¨ç¨‹åºå³å¯ã€‚ IPTVéœ€è¦ä¸“é—¨çš„æœºé¡¶ç›’å’Œè·¯ç”±å™¨ã€‚ è§†é¢‘è´¨é‡ï¼š OTTçš„è§†é¢‘è´¨é‡å–å†³äºäº’è”ç½‘é€Ÿåº¦ã€‚ IPTVæä¾›æ›´æµç•…ã€æ›´å¥½çš„ç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰æ›´é«˜çš„è§†é¢‘è´¨é‡å’ŒéŸ³é¢‘æ•ˆæœã€‚ ä»·æ ¼ï¼š OTTæœåŠ¡é€šå¸¸æ˜¯å…è´¹çš„ï¼Œä½†å¯èƒ½éœ€è¦ä»˜è´¹è®¢é˜…ä»¥å»é™¤å¹¿å‘Šã€‚ IPTVçš„ä»·æ ¼è¾ƒé«˜ï¼Œå¹³å‡æ¯æœˆè´¹ç”¨åœ¨15ç¾å…ƒè‡³30ç¾å…ƒä¹‹é—´ã€‚ å†…å®¹ç±»å‹ï¼š OTTæä¾›å…è´¹æˆ–ä»˜è´¹çš„å†…å®¹ï¼Œä¹Ÿå¯ä»¥æ˜¯æ··åˆå†…å®¹ã€‚ IPTVæä¾›ç‹¬å®¶çš„ä»˜è´¹å†…å®¹ï¼Œå¦‚è®¢é˜…è§†é¢‘ç‚¹æ’­ï¼ˆSVODï¼‰ã€‚ OTT+ç›´æ’­ï¼Ÿ 2 è¿è¥å•†ã€ISPã€ICPã€éª¨å¹²ç½‘ ç”µä¿¡è¿è¥å•†ï¼šæŒ‡æä¾›åŸºç¡€çš„ç”µä¿¡ä¸šåŠ¡ï¼ŒåŒ…æ‹¬å›ºç½‘ï¼ˆæœ‰çº¿ï¼‰ï¼Œç§»åŠ¨ç½‘ç»œï¼ˆæ— çº¿ï¼‰çš„è¿è¥å•†ï¼ˆç”µä¿¡&#x2F;è”é€š&#x2F;ç§»åŠ¨æ˜¯ä¸€çº§&#x2F;åŸºç¡€è¿è¥å•†ï¼‰ã€‚ ISPï¼šå¤šæŒ‡äº’è”ç½‘æ¥å…¥æœåŠ¡æä¾›å•†ï¼Œé•¿åŸå®½å¸¦ç­‰äºŒçº§è¿è¥å•†ï¼ˆé€šè¿‡è´­ä¹°ç”µä¿¡è¿è¥å•†çš„å¸¦å®½æ¥æä¾›äº’è”ç½‘æ¥å…¥æœåŠ¡ï¼‰ ICPï¼šå†…å®¹æä¾›å•†æŒ‡æä¾›äº’è”ç½‘ä¸Šå„ç§å†…å®¹çš„æœåŠ¡æä¾›å•†ï¼Œä¾‹å¦‚è§†é¢‘ã€éŸ³ä¹ã€æ–°é—»ã€ç¤¾äº¤åª’ä½“ç­‰ã€‚åœ¨ä¸­å›½ï¼Œä¸€äº›çŸ¥åçš„å†…å®¹æä¾›å•†åŒ…æ‹¬çˆ±å¥‡å¼‚ã€ä¼˜é…·ç­‰ã€‚ å†…å®¹æä¾›å•†é€šå¸¸å°†å…¶å†…å®¹æ‰˜ç®¡åœ¨ç”µä¿¡è¿è¥å•†çš„æœºæˆ¿å†…ï¼Œç”¨æˆ·é€šè¿‡è´­ä¹°ISPçš„æœåŠ¡æ¥è®¿é—®è¿™äº›å†…å®¹ã€‚ å±€åŸŸç½‘ï¼šå‡ å°è®¡ç®—æœºäº’è”ï¼ˆè®¡ç®—æœºç»„ï¼‰ï¼ˆå…‰çº¤ã€å¾ˆç»†çš„å…‰ç¼†ã€‘&#x2F;wifiï¼‰ï¼› å››ç§æŠ€æœ¯ç±»å‹&#x2F;æ ‡å‡†ï¼šä»¥å¤ªç½‘ã€ä»¤ç‰Œç¯ã€ä»¤ç‰Œæ€»çº¿ã€å…‰çº¤åˆ†å¸ƒå¼æ•°æ®æ¥å£(FDDI)ï¼› åŸåŸŸç½‘ï¼šåŸå¸‚èŒƒå›´å†…çš„è®¡ç®—æœºé€šä¿¡ç½‘ï¼ˆå¤§å‹LANï¼‰ï¼ˆå…‰ç¼†ï¼‰ï¼› å•ç‹¬åˆ—å‡ºï¼Œç”±äºæœ‰ä¸€ä¸ªç‹¬æœ‰æ ‡å‡†ï¼šåˆ†å¸ƒå¼é˜Ÿåˆ—åŒæ€»çº¿DQDBï¼ˆDistributed Queue Dual Busï¼‰ éª¨å¹²ç½‘ï¼šé€šå¸¸æ˜¯ä¸€ä¸ªå›½å®¶æˆ–åœ°åŒºèŒƒå›´å†…çš„ç½‘ç»œï¼Œç”¨äºè¿æ¥ä¸åŒåŸå¸‚æˆ–åœ°åŒºçš„ç½‘ç»œï¼› å¹¿åŸŸç½‘ï¼šè·¨è¶Šå¤šä¸ªåŸå¸‚ã€å›½å®¶æˆ–æ´²é™…ï¼Œè¿æ¥ä¸åŒçš„å±€åŸŸç½‘å’ŒåŸåŸŸç½‘ï¼ˆå¯åŒ…å«å¤šä¸ªéª¨å¹²ç½‘ï¼‰ ä¸­å›½ä¸»è¦çš„éª¨å¹²ç½‘ï¼š ä¸­å›½ç”µä¿¡ CHINANETï¼šä¸­å›½å…¬ç”¨è®¡ç®—æœºäº’è”ç½‘ï¼ŒåŸé‚®ç”µéƒ¨ ä¸­å›½ç§»åŠ¨ CMNETï¼šä¸­å›½ç§»åŠ¨äº’è”ç½‘ ä¸­å›½è”é€š UNINETï¼šä¸­å›½è”é€šè®¡ç®—æœºäº’è”ç½‘ï¼Œè¿˜æœ‰å­å…¬å¸ç½‘é€šçš„ä¸­å›½ç½‘é€šå…¬ç”¨äº’è”ç½‘ï¼ˆCNCNETï¼‰ ä¸­ç§‘é™¢ CSTNETï¼šä¸­å›½ç§‘æŠ€ç½‘ ä¿¡æ¯äº§ä¸šéƒ¨ CHINAGBNï¼šä¸­å›½é‡‘æ¡¥ä¿¡æ¯ç½‘ æ•™è‚²éƒ¨ CERNETï¼šä¸­å›½æ•™è‚²å’Œç§‘ç ”è®¡ç®—æœºç½‘ï¼Œå›½å®¶å…¬ç”¨ç»æµä¿¡æ¯é€šä¿¡ç½‘ 12345ç§»åŠ¨ é“é€š ç”µä¿¡ è”é€š(CDMA) å«é€š è”é€š(GSM) ç½‘é€š | | | | / \\ | | \\ / \\ | / \\ \\ / \\ / \\ | / | \\ / ç§»åŠ¨ ç”µä¿¡ èˆªå¤©ç§‘æŠ€ è”é€š","tags":[{"name":"points","slug":"points","permalink":"https://stu-yue.github.io/tags/points/"}],"categories":[{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"}]},{"title":"Summa | The Majority of Memory Categories","date":"2023-07-20T08:41:53.000Z","path":"jottings/architecture/summa_memory_categories/","text":"Reproduced in 8 types of memory every embedded engineer should know about! The majority of memory can be categorized as shown in the following picture: The real difference between primary and secondary memories is the speed&#x2F;volatility(without power) tradeoffs. Primary MemoryPrimary memory is very fast, but it cannot hold data without power. The popular name for Primary Memory is RAM, which has 2 most important types namely SRAM and DRAM. Bistable Circuit usually consists of two complementary transistors or other switching devices, one used to hold the circuit in one stable state and the other to switch the circuit to another stable state. The switch between these two states is triggered by the input signal. Bistable Circuit can store data. Latches and registers are bistable devices. SRAM is the use of bistable flip-flop to save information, as long as the power is not lost, the information is not lost. DRAM uses capacitors to store charge to store information, so data stored in the DRAM must be constantly refreshed every few milliseconds or else it will end up being erased. The action is taken care of by a special device named DRAM controllers. SRAM DRAM Construction Principle It uses a cross-coupled flip flop configuration of transistors It uses a capacitor transistor circuit to hold data Cost Relatively more expensive, it needs more transistors per bit of data it can store Relatively less expensive, as fewer transistors per bit of storage are needed Speed Faster Slower (capacitor charge and discharge time) Volatility As long as power is ON, it can store data since it uses no capacitors Data needs to be continuously refreshed (usually in the order of 4 times a second) since the capacitors leak power. Power consumption Less More Density Less dense (6 transistors, more area needed) Highly dense (1 pass transistor and 1 capacitor, easy to integrate) Addition components needed None DRAM controllers are needed to make it work like an SRAM. This controller offloads the data refreshing duties of a microprocessor and hence a DRAM coupled with a DRAM controller behaves more like an SRAM from the processorâ€™s perspective. Application areas Cache memory (Ls2) Main memory (memory chips) NVRAM or Non Volatile Random Access Memory, is a special type of RAM that can store data permanently. Itâ€™s basically an SRAM with a power supply Secondary MemoryROM MASK ROM: The main characteristic of this device is the fact that the data is written onto the device as it gets manufactured and it is impossible to change them. This is done by designing the chip in such a manner so that it already contains the necessary data. In order to mass production, the manufacturer makes a ROM or EPROM with original data as a sample in advance, and then mass-produces the same ROM as the sample. This kind of ROM sample for mass production is the MASK ROM, and the data burned in the MASK ROM can never be modified. PROM stands for Programmable Read-Only Memory. These are programmable chips for user needs, the main characteristic being it can only be programmed one time. That is it cannot be erased or reprogrammed. They are also known as One Time Programmable devices or OTPs for short. EPROM stands for Erasable Programmable Read-Only Memory. These chips usually have a small glass window on top and if you expose them to direct sunlight(UV, ultraviolet) that will erase the chipâ€™s data. They can then be programmed again with fresh data. Cons: Inconvenient, instability, can not be exposed to the light source otherwise easy to lead to data loss EEPROM stands for Electrically Erasable Programmable Read-Only Memory. These chips can be erased and reprogrammed using electricity as opposed to exposing them to UV rays as EPROMs. EEPROM can be erased and reprogrammed on a computer or dedicated device, generally plugging and playing. FLASH MEMORY The basic storage unit of flash memory is the transistor-based storage unit, and each storage unit can store 1 bit of data. Storage units are usually organized into a block, and each block contains thousands of storage units. Each storage unit has a floating gate to store electric charges. The state of a storage unit can be determined as â€œ1â€ or â€œ0â€ based on the amount of electric charges stored in the floating gate. The state of a storage unit is changed by injecting or extracting electrons into&#x2F;from the floating gate to modify the amount of electric charges stored in it. Flash memory uses Hot carrier injection(HCI) mechanism to write data. In simple terms, a certain storage unit is grounded at the source, a positive voltage is applied to its control gate, and a positive voltage is applied to the drain to generate a strong electric field between the source and drain. This will give electrons enough energy (hot carriers) to be attracted by the voltage at the control gate and injected into the floating gate. Afterwards, as the insulating material on the top and bottom of the floating gate is not conductive, these electrons are trapped in the floating gate and cannot escape. (Every time electrons enter and exit the surrounding silicon dioxide on the floating gate, it will cause aging[1]) To save cost, flash memory adopts page programming mode. Each page contains a certain number of storage units, and all units in a page are written at the same time. Cons: Flash memory has the issue of wear-out (write&#x2F;erase endurance limits), which is usually mitigated by disabling bad blocks, and then reducing usable capacity. USB flash disk, namely â€œU diskâ€, is a new generation of storage devices based on USB interface and flash memory chip as storage medium. It is basically composed of five parts: USB port, main control chip, flash memory chip, PCB backboard, outer package. USB flash drives, SD cards, and SSDs are a type of storage device that uses flash memory chips as the storage medium. They are primarily composed of a controller (main control) and flash memory chips, and have no mechanical structure, consisting purely of electronic circuitry. They are resistant to physical shocks and impacts. The controller manages data storage and other functions. Even after power loss, data remains stored in the memory cells. USB flash drives generally have a cache on them to prevent the loss of data copies from being quickly plugged in&#x2F;out. OTHER Hard Disk Drive: The disk reads data according to the polarity of the magnetic particle and writes data according to the polarity of the magnetic head. Compact Disk: CD-ROM can only be read and not written to because after being burned once, each unit has a fixed different reflectivity (the reading probe emits laser and the reflected laser is read as â€œ1â€, or non-reflected laser is read as â€œ0â€). Floppy Disk: A type of magnetic disk, less capacity, slower speed.","tags":[{"name":"memory","slug":"memory","permalink":"https://stu-yue.github.io/tags/memory/"}],"categories":[{"name":"architecture","slug":"architecture","permalink":"https://stu-yue.github.io/categories/architecture/"}]},{"title":"Welcome to Yue's Jotter","date":"2023-07-13T08:23:57.000Z","path":"jottings/intro/","text":"","tags":[],"categories":[]},{"title":"Summa | Firmware and Drivers","date":"2023-07-13T06:21:53.000Z","path":"jottings/architecture/summa_firmware_and_drivers/","text":"Reproduced in Firmware vs Device Drivers: Explained with Examples! Firmware vs. Device Drivers Firmware Device Drivers Firmware is a class of software that is written for specific custom hardware. Device drivers are software that is needed to make a given hardware accessory Firmware lives and runs directly on the hardware. Device drivers live on hard-disk and run on the CPU. Firmware is independent of an operating system, i.e., you can run any operating system on top of a given motherboardâ€™s firmware. Device drivers are highly dependent on the operating system on which they are used. For example, for the same hardware device, you need different device drivers for using that on Windows vs Linux. Firmware cannot be updated through an operating system, we need to go into the BIOS&#x2F;UEFI to update the device drivers. Drivers can be updated from within the operating system. Firmware engineers do not need any knowledge of operating systems. But they need core knowledge on processors and the latest RAMs, PCIe standards, and so on to write firmware that complies with the latest standards Device driver engineers need knowledge about the specific device that they are using, the communication standard the device uses to talk to the computer (like Bluetooth, USB, etc), and the operating system the device driver is written for. Firmware is written by motherboard manufacturers Drivers are written by engineers in companies that produce hardware accessories that connect to your computer Examples include the BIOS&#x2F;UEFI interface that comes with the computerâ€™s motherboard Examples include special software you install to handle the extra buttons on your mouse, software that comes with any non-standard hardware like special game controllers, also the software that helps us use all the standard hardware like USB storage devices, keyboards, mice, headphones, etc. Layers of software on a typical computer are shown in the following figure: Firmwareâ€‹ Firmware is a computer program that is written to work directly on specific custom hardware and it lives in non-volatile memory such as a flash chip and it is executed directly from it. The job of the firmware is to make the hardware accessible to the operating system. Firmware can be thought of as the glasses through which the operating system can see the actual hardware! â€‹ Originally Firmware is written on Masked ROMs, which is a special type of memory that can be programmed&#x2F;written-data-to only once. The products were then shipped with these unchangeable programs called firmware and they run for ages till the device goes out of use. â€‹ The first replacement of Masked ROMs came in the form of EPROM which can be erased by exposure to UV light and then reprogrammed as required. Then came EEPROMs which used electricity to change the contents. Nowadays the Masked ROMs have been replaced with Flash memory, which is cheaper and serves the purpose. Device DriversDevice drivers are programs that can control a given hardware and provide a software interface to it. Other programs like Operating Systems can interact with the hardware through this software interface without needing to know the actual underlying implementation of the software interface. The relation graph between firmware and drivers is also shown below: â€‹ Generally speaking, drivers and firmware together form the module that operates hardware. But why not make the firmware perfect so that it doesnâ€™t require driver support? â€‹ The answer to the above question is, there are different operating systems which have completely different ways of operating hardware. So, on the one hand, hardware manufactures need to write firmware to make their hardware easier to use with software, but on the other hand, they cannot make the firmware too rigid in order to be compatible with various operating systems. They must leave enough room for software to freely operate â€”â€” and thatâ€™s where drivers come in.","tags":[{"name":"firmware","slug":"firmware","permalink":"https://stu-yue.github.io/tags/firmware/"},{"name":"driver","slug":"driver","permalink":"https://stu-yue.github.io/tags/driver/"}],"categories":[{"name":"architecture","slug":"architecture","permalink":"https://stu-yue.github.io/categories/architecture/"}]}],"categories":[{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"},{"name":"statistics_ml","slug":"statistics-ml","permalink":"https://stu-yue.github.io/categories/statistics-ml/"},{"name":"architecture","slug":"architecture","permalink":"https://stu-yue.github.io/categories/architecture/"},{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"},{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"},{"name":"networks","slug":"networks","permalink":"https://stu-yue.github.io/categories/networks/"},{"name":"python","slug":"languages/python","permalink":"https://stu-yue.github.io/categories/languages/python/"}],"tags":[{"name":"math","slug":"math","permalink":"https://stu-yue.github.io/tags/math/"},{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"},{"name":"instruction set arch","slug":"instruction-set-arch","permalink":"https://stu-yue.github.io/tags/instruction-set-arch/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"networks","slug":"networks","permalink":"https://stu-yue.github.io/tags/networks/"},{"name":"algebra","slug":"algebra","permalink":"https://stu-yue.github.io/tags/algebra/"},{"name":"statistic","slug":"statistic","permalink":"https://stu-yue.github.io/tags/statistic/"},{"name":"python","slug":"python","permalink":"https://stu-yue.github.io/tags/python/"},{"name":"optimization","slug":"optimization","permalink":"https://stu-yue.github.io/tags/optimization/"},{"name":"points","slug":"points","permalink":"https://stu-yue.github.io/tags/points/"},{"name":"memory","slug":"memory","permalink":"https://stu-yue.github.io/tags/memory/"},{"name":"firmware","slug":"firmware","permalink":"https://stu-yue.github.io/tags/firmware/"},{"name":"driver","slug":"driver","permalink":"https://stu-yue.github.io/tags/driver/"}]}