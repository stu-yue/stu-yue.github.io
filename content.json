{"pages":[{"title":"ABOUT","date":"2023-10-04T06:07:04.840Z","path":"about/index.html","text":"ğŸ‘©â€ğŸ’»: A CODER WITH GREEN HANDS ğŸ’¡: THINK TWICE, CODE ONCE! ğŸ¯: GOTO NIPS, MSRA AND BE REASSURED ğŸ’Œ: BEST WISHES TO LEE XIAOMAO 12345// life mottoif (sad() == true) &#123; sad().stop(); beAwesome();&#125;"},{"title":"TAGS","date":"2023-07-13T06:48:03.646Z","path":"tags/index.html","text":""},{"title":"CATEGORIES","date":"2023-07-13T06:47:46.496Z","path":"categories/index.html","text":""}],"posts":[{"title":"","date":"2024-05-03T03:48:39.342Z","path":"jottings/interview/memo_cpp_notes/","text":"","tags":[],"categories":[{"name":"interview","slug":"interview","permalink":"https://stu-yue.github.io/categories/interview/"}]},{"title":"","date":"2024-05-03T03:48:39.332Z","path":"jottings/interview/Hot100/è¡¨è¾¾å¼æ±‚å’Œ/","text":"","tags":[],"categories":[{"name":"interview","slug":"interview","permalink":"https://stu-yue.github.io/categories/interview/"},{"name":"Hot100","slug":"interview/Hot100","permalink":"https://stu-yue.github.io/categories/interview/Hot100/"}]},{"title":"Memo | Law of Large Number","date":"2023-10-21T05:56:53.000Z","path":"jottings/mathematics/memo_law_of_probability/","text":"1 Law of Large Number1.1 Folk UnderstandingIn simple terms, the large numbers theorem refers to that a random event may or may not occur in a single experiment, but in a large number of repeated experiments, it often shows obvious regularity, that is, the frequency of the random event will converge to a constant value, which is the probability of the event. Another way to express it is that when the sample data is infinite, the sample mean tends to population mean. Because in real life, we can not run an infinite number of experiments, and it is difficult to estimate the parameters of the population. The law of large numbers connects mean values, which belong to mathematical statistics, with expectations, which belong to probability theory. 1.2 Convergence in Probability Weak Law: convergence in probability Strong Law: almost sure convergence (outlier can be negligible in measure) 1.3 Bernoulliâ€™s LawFrom the perspective of defining probability, reveals the relationship between probability and frequency.$$\\lim\\limits_{n\\rightarrow \\infin} P{ |\\frac{f_A}{n} - p| &lt; \\epsilon } &#x3D; 1$$ 1.4 Khinchinâ€™s LawPriori Condition: Independent Identically Distributed, $\\lim\\limits_{n\\rightarrow \\infin} P{ |\\frac{1}{n}\\sum\\limits_{i&#x3D;1}^nX_i - \\frac{1}{n}\\sum\\limits_{i&#x3D;1}^{n}E(X_i)| &lt; \\epsilon } &#x3D; 1$ 1.5 Chebyshevâ€™s LawPriori Condition: Independent Distributed, $\\lim\\limits_{n\\rightarrow \\infin} P{ |\\frac{1}{n}\\sum\\limits_{i&#x3D;1}^nX_i - \\frac{1}{n}\\sum\\limits_{i&#x3D;1}^{n}\\mu_i| &lt; \\epsilon } &#x3D; 1$ 2 Heavy-tailed Distribution Ref: 1, 2 Pareto Distribution:$$P(X&gt;x) &#x3D; \\left{\\begin{align}(\\frac{x_{min}}{x})^\\alpha,&amp;\\quad x\\ge x_{min} \\1, &amp;\\quad x&lt;x_{min}\\end{align}\\right.$$ $$f(x) &#x3D; \\left{\\begin{align}\\frac{1}{x^\\alpha}\\cdot\\frac{\\alpha x_{min}^\\alpha}{x},&amp;\\quad x\\ge x_{min} \\0, &amp;\\quad x&lt;x_{min}\\end{align}\\right.$$ Pareto Principle: states that for many outcomes, roughly 80% of consequences com from 20% of causes (the â€œvital fewâ€). Other names â€”â€” 80&#x2F;20 rule, the law of the vital few (states the imbalance phenomenon); Mathematically, the 80&#x2F;20 rule is roughly described by a power law distribution (also known as a Pareto distribution) for a particular set of parameters. Zipf Distribution:$$f(x) &#x3D; \\frac{1}{x^\\alpha\\sum_{i&#x3D;1}^{n}(1&#x2F;i)^\\alpha}, \\ x &#x3D; 1,2,\\cdots,n$$Zipfâ€™s law states that the value of the nth entry is inversely proportional to n, when a list of measured values is sorted in decreasing order. Zeta Distribution: when $n\\rightarrow \\infty$, $\\text{Zipf}(\\alpha, n)\\rightarrow\\text{Zeta}(\\alpha)$ ; Zeta is regraded as a type of pareto distribution in the discrete distribution.$$f(x) &#x3D; \\frac{1}{x^\\alpha\\sum_{i&#x3D;1}^{\\infty}(1&#x2F;i)^\\alpha}, \\ x &#x3D; 1,2,\\cdots,n,\\text{and}\\ \\alpha &gt; 1$$","tags":[{"name":"math","slug":"math","permalink":"https://stu-yue.github.io/tags/math/"}],"categories":[{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"}]},{"title":"Memo | CTC Introduction","date":"2023-10-17T07:56:53.000Z","path":"jottings/statistics_ml/memo_ctc/","text":"1 Problem DescriptionIn seq2seq structure, given input sequence $X&#x3D;[x_1,\\cdots,x_T]$ with corresponding label $Y &#x3D; [y_1,\\cdots,y_N]$, such as speech recognition. Our job is to find a map, and this algorithm for classifying time series data is called Temporal Classification. Compared with traditional classification, temporal classification has the following difficulties: The lengths of $X$ and $Y$ are variable. The lengths of $X$ and $Y$ are not equal. For an end-to-end model, we donâ€™t want manual design the alignment between $X$ and $Y$. The CTC provides the solution, that for a given input sequence $X$, CTC gives the output distribution of all possible $Y$. Based on this distribution, we can output the most likely outcome or give the probability of a certain output. Loss Function: Given the input sequence $X$, we want to maximize the posterior probability $P(Y|X)$ of $Y$, and $P(Y|X)$ should be derivable so that we can perform the gradient-descent algorithm; Test: Given a trained model and input sequence $X$, we want to output $Y$ with the highest probability:$$Y^* &#x3D; \\arg\\max_YP(Y|X)$$Of course, when testing, we want Y to be searched as soon as possible (greedy, beam, prefix-beam, LM). CTC Procedure REF: https://zhuanlan.zhihu.com/p/42719047 CTC Traits Conditional independence: A very unreasonable assumption of the CTC is its assumption that each time slice is independent of each other, which is a very bad assumption. In OCR or speech recognition, there is some semantic information between each time slice, so the effect should be improved if the language model can be added to the CTC. Monotonic alignment: Another constraint of CTC is the monotonic alignment between input $X$ and output $Y$, which holds true in OCR and speech recognition. However, in some scenarios, such as machine translation, this constraint is not valid. Many-to-one mapping: Another constraint of CTC is that the length of the input sequence $X$ is greater than the length of the label data $Y$, but for scenarios where the length of $Y$ is greater than the length of $X$, CTC is invalid.","tags":[{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"}],"categories":[{"name":"statistics_ml","slug":"statistics-ml","permalink":"https://stu-yue.github.io/categories/statistics-ml/"}]},{"title":"Memo | LM and Word Representation","date":"2023-10-17T07:56:53.000Z","path":"jottings/statistics_ml/memo_lm_and_word_vector/","text":"Language Model è¯­è¨€æ¨¡å‹æ˜¯è¡¡é‡ä¸€å¥è¯å‡ºç°åœ¨è‡ªç„¶è¯­è¨€ä¸­çš„æ¦‚ç‡çš„æ¨¡å‹ï¼› æ•°å­¦å½¢å¼ä¸Šï¼Œç»™å®šä¸€å¥è¯ $s &#x3D; { w_1,\\cdots,w_n }$ï¼Œå®ƒå¯¹åº”çš„æ¦‚ç‡ä¸ºï¼š$$\\begin{align*}P(s) &amp;&#x3D; P(w_1,\\cdots,w_n) \\&amp;&#x3D; P(w_1)\\times P(w_2|w_1) \\times \\cdots \\times P(w_n|w_1,\\cdots,w_{n-1})\\&amp;&#x3D; \\prod\\limits_{i&#x3D;1}^{n}P(w_i|w_1,\\cdots,w_{i-1})\\end{align*}$$ è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒåœ¨äºæ ¹æ®å‰æ–‡é¢„æµ‹ä¸‹ä¸€ä¸ªè¯å‡ºç°çš„æ¦‚ç‡ï¼› $P(w_i|w_1,\\cdots,w_{i-1}),\\ w_i \\in V,\\ V&#x3D;{ w_1,\\cdots,w_{|V|} }$ é©¬å°”å¯å¤«å‡è®¾ (Markov Assumption)ï¼šå½“å‰è¯å‡ºç°çš„æ¦‚ç‡åªå’Œå®ƒå‰é¢çš„kä¸ªè¯ç›¸å…³ï¼›$$\\begin{align*}P(w_i | w_1,\\cdots,w_{i-1}) &amp;&#x3D; P(w_i | w_{i-k},\\cdots,w_{i-1}) \\&amp; &#x3D; P(w_i) \\qquad\\qquad\\qquad \\rightarrow\\quad\\text{k&#x3D;0, Unigram Model} \\&amp; &#x3D; P(w_i | w_{i-1}) \\qquad\\qquad \\rightarrow\\quad\\text{k&#x3D;1, Bigram Model} \\&amp; &#x3D; P(w_i | w_{i-2}, w_{i-1})\\qquad\\rightarrow\\quad\\text{k&#x3D;2, Trigram Model}\\\\end{align*}$$ ç”¨é¢‘ç‡ä¼°è®¡æ¦‚ç‡ï¼ˆå¤§æ•°å®šç†â€”â€”ä¼¯åŠªåˆ©ï¼‰$$\\begin{align*}P(w_i | w_1,\\cdots,w_{i-1}) &amp;&#x3D; P(w_i | w_{i-k},\\cdots,w_{i-1}) \\&amp; &#x3D; \\frac{P(w_{i-k},\\cdots,w_{i-1},w_i)}{P(w_{i-k},\\cdots,w_{i-1})} \\&amp; \\approx \\frac{\\text{count}(w_{i-k},\\cdots,w_{i-1},w_i)}{\\text{count}(w_{i-k},\\cdots,w_{i-1})} \\\\end{align*}$$ Zipf Law, also known as the rank-size rule or Zipf distribution, is an empirical observation about the frequency distribution of words or other items in a given corpus of natural language. It states that the frequency of any word is inversely proportional to its rank in the frequency table. éšè—ä¿¡æ¯ï¼Œæ’ä½é åçš„è¯çš„é¢‘ç‡éå¸¸ä½ï¼Œç”šè‡³æœªå‡ºç°åœ¨è¯­æ–™ä¸­ï¼› æ•°æ®ç¨€ç–ï¼Œå¯¹äºæœªå‡ºç°åœ¨è¯­æ–™ä¸­çš„è¯æˆ–n-gramï¼Œæ— æ³•ä¼°è®¡å…¶æ¦‚ç‡ï¼› å¹³æ»‘æŠ€æœ¯ ï¼ˆæ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ã€å¤å¾·-å›¾çµå¹³æ»‘ã€æ’å€¼å¹³æ»‘ã€Katzå¹³æ»‘ï¼‰ $$\\begin{align*}P(w_i | w_1,\\cdots,w_{i-1}) &amp;&#x3D; P(w_i | w_{i-k},\\cdots,w_{i-1}) \\&amp; &#x3D; \\frac{P(w_{i-k},\\cdots,w_{i-1},w_i)}{P(w_{i-k},\\cdots,w_{i-1})} \\&amp; \\approx \\frac{\\text{count}(w_{i-k},\\cdots,w_{i-1},w_i)+1}{\\text{count}(w_{i-k},\\cdots,w_{i-1})+|V|} \\\\end{align*}$$ å›é€€ç­–ç•¥$$\\begin{align*}P(w_i | w_1,\\cdots,w_{i-1}) &amp;&#x3D; P(w_i | w_{i-k},\\cdots,w_{i-1}) \\&amp; &#x3D; \\frac{P(w_{i-k},\\cdots,w_{i-1},w_i)}{P(w_{i-k},\\cdots,w_{i-1})} \\&amp; \\approx \\frac{\\text{count}(w_{i-k},\\cdots,w_{i-1},w_i)}{\\text{count}(w_{i-k},\\cdots,w_{i-1})}\\qquad \\rightarrow\\quad\\text{students opened their} \\&amp; \\approx \\frac{\\text{count}(w_{i-k+j},\\cdots,w_{i-1},w_i)}{\\text{count}(w_{i-k+j},\\cdots,w_{i-1})}\\quad \\rightarrow\\quad\\text{opened their} \\\\end{align*}$$ å‚æ•°è§„æ¨¡é—®é¢˜ï¼šéšç€kçš„å¢å¤§ï¼Œå‚æ•°æ•°ç›®å‘ˆæŒ‡æ•°å¢é•¿ï¼Œæ— æ³•å­˜å‚¨ï¼› k&#x3D;1ï¼Œå‚æ•°é‡&#x3D;$|V|^2$ï¼›k&#x3D;2ï¼Œå‚æ•°é‡&#x3D;$|V|^3$ï¼›k&#x3D;n-1ï¼Œå‚æ•°é‡&#x3D;$|V|^n$ï¼› å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ ç”¨æ¥è¡¡é‡ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒæˆ–æ¦‚ç‡æ¨¡å‹é¢„æµ‹æ ·æœ¬çš„å¥½åç¨‹åº¦ï¼› å¯ä»¥ç”¨æ¥æ¯”è¾ƒä¸¤ä¸ªæ¦‚ç‡æ¨¡å‹ï¼Œä½å›°æƒ‘åº¦çš„æ¦‚ç‡æ¨¡å‹èƒ½æ›´å¥½åœ°é¢„æµ‹æ ·æœ¬ï¼›$$\\text{Perplexity}(s) &#x3D; 2^{H(s)} &#x3D; \\sqrt[n]{1&#x2F;P(w_1,\\cdots,w_n)}$$ Word Representation è¯åº“ï¼š WordNetï¼šä¸€ä¸ªåŒ…å«åŒä¹‰è¯ï¼ˆ synonym ï¼‰å’Œä¸Šä½è¯ï¼ˆ hypernyms ï¼‰çš„çŸ¥è¯†åº“ï¼› è¯åº“çš„é—®é¢˜ï¼š ç¼ºå°‘å·®å¼‚æ€§ (proficientä¹Ÿè¢«è§†ä¸ºgoodçš„åŒä¹‰è¯)ï¼Œä¸å¤Ÿç²¾ç¡®ï¼› ç¼ºå°‘æ–°è¯ï¼Œæ— æ³•åŠæ—¶æ›´æ–° ä¸»è§‚æ€§ï¼Œäººå·¥æ ‡æ³¨ï¼› ç¦»æ•£è¯è¡¨ç¤ºï¼š One-hotè¡¨ç¤ºï¼š 123456å•è¯è¡¨ç¤º motel = [0 0 0 0 0 1 0] hotel = [0 0 0 1 0 0 0]æ–‡æœ¬è¡¨ç¤º The students opened their books [0 0 1 1 0 0 1 0] â¬† æ¬¡æ•°ã€é¢‘ç‡ã€é€†æ–‡æ¡£é¢‘ç‡ã€TF-IDFã€... è¯è¢‹æ¨¡å‹ï¼ˆBag of Wordï¼‰ï¼šè¯è¢‹æ¨¡å‹ç”¨äºæ–‡æœ¬è¡¨ç¤ºï¼Œå¦‚æœæ¯ä¸ªè¯ä¸ºOne-hotè¡¨ç¤ºï¼Œé‚£ä¹ˆæŠŠæ¯ä¸ªè¯çš„One-hotå‘é‡ç›¸åŠ ï¼Œå¾—åˆ°çš„å‘é‡å°±æ˜¯è¯¥æ–‡æœ¬åŸºäºBOWå¾—åˆ°çš„è¡¨ç¤ºï¼› è¯é¢‘ï¼ˆTerm Frequencyï¼ŒTFï¼‰ï¼šåœ¨æ–‡æ¡£ä¸­å‡ºç°é¢‘ç‡è¶Šé«˜çš„è¯å¯¹å½“å‰æ–‡æ¡£å¯èƒ½è¶Šé‡è¦ï¼›$$f_{ij} &#x3D; \\frac{\\text{count}(\\text{term}\\ i)\\text{in doc} \\ j}{\\text{count}(\\text{all term})\\text{in doc} \\ j}, \\tf_{ij} &#x3D; \\frac{f_{ij}}{\\max_k(f_{kj})}$$ é€†æ–‡æ¡£é¢‘ç‡ï¼ˆInverse Document Frequencyï¼ŒIDFï¼‰ï¼šåœ¨å¾ˆå¤šæ–‡æ¡£ä¸­éƒ½å‡ºç°çš„è¯å¯èƒ½ä¸é‡è¦ï¼ˆå¦‚è™šè¯ï¼‰ï¼›$$df_i &#x3D; \\text{doc frequency of term}\\ i &#x3D; \\text{numbers of doc containing term} \\ i, \\idf_i &#x3D; \\log_2\\frac{N}{df_i} \\ \\text{ï¼ˆNä¸ºæ–‡æ¡£æ€»æ•°ï¼‰}$$ TF-IDFï¼šç»¼åˆä¸€ä¸ªè¯åœ¨å½“å‰æ–‡æ¡£ä¸­çš„é¢‘ç‡å’Œæ‰€æœ‰æ–‡æ¡£ä¸­å‡ºç°çš„æ¬¡æ•°æ¥åº¦é‡è¿™ä¸ªè¯å¯¹å½“å‰æ–‡æ¡£é‡è¦æ€§ï¼›$$tf_{ij}-idf_i &#x3D; tf_{ij}*idf_i &#x3D; tf_{ij}*\\log_2\\frac{N}{df_i}$$ N-gramï¼šNå…ƒç»„æå–å±€éƒ¨çš„ä¸Šä¸‹æ–‡ä½ ä¿¡æ¯ï¼› ç¦»æ•£è¯è¡¨ç¤ºé—®é¢˜ï¼šè¯­ä¹‰é¸¿æ²Ÿã€ç»´åº¦çˆ†ç‚¸ï¼› åˆ†å¸ƒå¼è¯è¡¨ç¤ºï¼ˆè¯åµŒå…¥ï¼‰ ç”¨ä¸€ä¸ªä½ç»´ç¨ å¯†çš„å‘é‡è¡¨ç¤ºå•è¯çš„æ•´ä½“å«ä¹‰ï¼› æ ¸å¿ƒæ€æƒ³ï¼šä¸€ä¸ªè¯çš„å«ä¹‰èƒ½è¢«è¯¥è¯æ‰€åœ¨çš„ä¸Šä¸‹æ–‡åæ˜ ï¼› Co-occurrenceï¼š åŸºäºçª—å£çš„å…±ç°çŸ©é˜µï¼š ç»Ÿè®¡çª—å£å†…å•è¯ä¹‹é—´çš„å…±ç°ä¿¡æ¯ï¼› ç±»ä¼¼äºword2vecï¼› èƒ½å¤Ÿæ•è·ä¸€äº›å¥æ³•å’Œè¯­ä¹‰ä¿¡æ¯ï¼ˆå±€éƒ¨ä¿¡æ¯ï¼‰ï¼› åŸºäºæ–‡æ¡£çš„å…±ç°çŸ©é˜µï¼š ç»Ÿè®¡æ–‡æ¡£å’Œå•è¯ä¹‹é—´çš„å…±ç°ä¿¡æ¯ï¼› Latent Semantics Analysis (LSA)ï¼› èƒ½å¤Ÿæ•è·è¯é¢˜ä¿¡æ¯ï¼ˆå…¨å±€ä¿¡æ¯ï¼‰ï¼› Word2vec[Mikolov et al. 2013] æ˜¯ä¸€å¥—å­¦ä¹ è¯å‘é‡çš„ç®—æ³•æ¡†æ¶ ç®—æ³•æ€æƒ³ï¼šå¤§é‡çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼ˆè®­ç»ƒè¯­æ–™ï¼‰ ä¸ºè¯è¡¨ä¸­çš„æ¯ä¸ªè¯éšæœºåˆå§‹åŒ–ä¸€ä¸ªå‘é‡è¡¨ç¤º éå†æ–‡æœ¬ä¸­çš„æ¯ä¸ªå•è¯ $c$ï¼Œå…¶ä¸Šä¸‹æ–‡å•è¯ä¸º $o$ ä½¿ç”¨å•è¯ $c$ çš„ä¸Šä¸‹æ–‡ $o$ é¢„æµ‹å•è¯ $c$ çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆæ ¸å¿ƒæ€æƒ³ï¼‰ æ›´æ–°è¯å‘é‡çš„è¡¨ç¤ºä½¿å¾—å•è¯ $c$ çš„é¢„æµ‹æ¦‚ç‡æœ€å¤§åŒ– è¿ç»­è¯è¢‹æ¨¡å‹ï¼ˆCBOWï¼ŒContinuous Bag of Wordsï¼‰ ç›®æ ‡ï¼šé€šè¿‡å±€éƒ¨è¯­è¨€æ¨¡å‹çš„ä¼˜åŒ–ï¼Œè·å¾—è¯å‘é‡ ä¼˜åŒ–ç›®æ ‡ï¼šå›ºå®šä¸Šä¸‹æ–‡è¯å‘é‡è¡¨ç¤ºï¼Œè®¡ç®—ä¸­å¿ƒè¯çš„ä¼¼ç„¶å‡½æ•°ï¼Œæœ€å¤§åŒ–å…¶ä¼¼ç„¶ï¼ˆè´Ÿå¯¹æ•°ï¼‰ è®¡ç®—ä¼˜åŒ–ï¼šè´Ÿé‡‡æ ·ï¼ˆNegative Samplingï¼‰ ä¸ºé¿å…softmaxè®¡ç®—æ•´ä¸ªåºå¤§çš„è¯è¡¨ï¼Œé€šå¸¸é‡‡ç”¨è´Ÿé‡‡æ ·çš„æ–¹æ³•ï¼Œå°†å¤šåˆ†ç±»é—®é¢˜è½¬æ¢ä¸ºäºŒåˆ†ç±»é—®é¢˜ï¼›å¤§å¤§å‡å°‘äº†è®­ç»ƒæ—¶é—´å’Œè®¡ç®—æˆæœ¬ï¼› Skip-gramï¼šä¸­å¿ƒè¯ $c$ é¢„æµ‹ä¸Šä¸‹æ–‡ $o$ï¼› ä¼˜ç‚¹ ç¼ºç‚¹ ä»£è¡¨æ–¹æ³• å…±ç°çŸ©é˜µæ³• é€Ÿåº¦å¿«ï¼Œæœ‰æ•ˆåˆ©ç”¨ç»Ÿè®¡æ•°æ® è¿‡åˆ†ä¾èµ–å•è¯å…±ç°æ€§å’Œæ•°æ®é‡ LSA, HAL ç›´æ¥å­¦ä¹ æ³• èƒ½å¤Ÿæ•è·è¯­æ³•å’Œè¯­ä¹‰ä¿¡æ¯ é€Ÿåº¦å’Œæ•°æ®è§„æ¨¡ç›¸å…³ï¼Œæœªæœ‰æ•ˆåˆ©ç”¨ç»Ÿè®¡æ•°æ® Skip-gram, CBOW åŸºäºè®¡æ•°çš„å’ŒåŸºäºé¢„æµ‹çš„éƒ½æ¢ç©¶äº†è¯­æ–™åº“çš„æ½œåœ¨å…±ç°ç»Ÿè®¡ GloVeï¼šé›†ä¸¤å®¶ä¹‹é•¿ å…±ç°æ¦‚ç‡çŸ©é˜µ$X_{ij}$ï¼› å•è¯ $w_i$ï¼Œ$w_j$ çš„è¯å‘é‡ $v_i$ï¼Œ$v_j$ï¼› ä»¥å­¦ä¹ çš„æ–¹å¼ï¼Œç”¨è¯å‘é‡ä¹‹é—´çš„è¯­ä¹‰å…³ç³»æ¥æ‹Ÿåˆå…±ç°æ¦‚ç‡çŸ©é˜µï¼›$$J &#x3D; \\sum\\limits_{i,j&#x3D;1}^{|V|}f(X_{ij})(v_i^Tv_j+b_i+b_j-\\log X_{ij})^2 \\v_i^Tv_j \\quad\\rightarrow\\quad\\text{å±€éƒ¨ä¿¡æ¯} \\\\log X_{ij}\\quad\\rightarrow\\quad\\text{å…¨å±€ç»Ÿè®¡ä¿¡æ¯} \\$$ è®­ç»ƒå¿«ï¼Œé€‚åº”äºå¤§è§„æ¨¡æ•°æ®ï¼Œåœ¨å°è§„æ¨¡æ•°æ®ä¸Šæ€§èƒ½ä¼˜ç§€ï¼›","tags":[{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"}],"categories":[{"name":"statistics_ml","slug":"statistics-ml","permalink":"https://stu-yue.github.io/categories/statistics-ml/"}]},{"title":"Memo | ISA and Micro-architecture","date":"2023-10-14T10:21:53.000Z","path":"jottings/architecture/memo_isa_and_micro_architecture/","text":"What is CPU? CPUs are a general purpose, flexible architecture that take in a stream of instructions from all types of workloads, and compute or process information based on those instructions. Simply put, CPUs do what we tell them or program them to do. This ability to continue shrinking transistors is based on a famous law&#x2F;observation that we in the industry refer to as Mooreâ€™s Law, that is, we can double the number of transistors per unit area about every two year. Bug Aside: Operators traced an error on the computers to a moth trapped in a relay, recoining the term â€œbugâ€. CPU Architecture: **ENIAC: ** In early period, computer programs are hardware-based. Computers with data in memory and programs embedded in the hardware are computationally inefficient and less flexible. Von Neumann Machine: Programs are encoded as data and stored in memory (Principle of Stored Program Control). Harvard Machine: A memory structure that separates program instruction storage from data storage. CPU can access instructions and read&#x2F;write data at the same time. Use two independent memory modules to store instructions and data respectively, and each storage module does not allow instructions and data to coexist; Use two independent buses as a dedicated communication path between the CPU and each memory, and these two buses are unrelated. In fact, the vast majority of modern computers use â€œModified Harvard Architecture,â€ where instructions and data share the same address space, but the cache is separate. As it stands, von Neumann for large-scale processing, and Harvard for small-scale processing. CPU workflow architecture: Instruction Set ArchitectureThe ISA is the dictionary of instructions, data types, and the formats that the CPU adhering to that ISA must execute. The ISA is used as a design spec (specification) that tells the engineer what operations it needs to execute. Because of this layer of abstraction, the instructions in the ISA are implementation independent. Micro-architecture is the concrete implementation of ISA in the hardware. CISC (Complex Instruction Set Computers): Early CPUs all used CISC, which was designed to perform the required computational tasks with minimal machine language instructions. In order to achieve complex operations, microprocessors provide programmers with functions similar to various registers and machine instructions, but also through microprograms stored in read-only memory (ROM) to achieve its extremely powerful functions. RISC (Reduced Instruction Set Computers): In CISC, many complex instructions require extremely complex operations, and most of these instructions are direct copies of some high-level language, so the universality is poor. Because of the secondary microcode execution, it also slows down the operation of simple instruction systems that are frequently invoked. Summary: The complex instructions are converted into a microprogram, which is stored in the microservice memory when the CPU is manufactured. A microprogram contains several microinstructions (also known as microcode), and when executing complex instructions, it is actually executing a microprogram. This also brings a difference between the two instruction sets, the execution of microprograms cannot be interrupted, while RISC instructions can be interrupted between each other, so in theory RISC can respond faster to interrupts. Command Capability: The instruction capability of CISC is strong, but the usage rate of most instructions is low, which increases the complexity of CPU. Instructions are variable length format, which must be divided into different length instructions, so more processing work is needed when executing a single instruction. Most RISC instructions are single-cycle instructions, the length of instructions is fixed, and the CPU is fast and stable when executing instructions. Addressing Mode: CISC supports a variety of addressing methods. RISC supports few addressing methods. Implementation Mode: CISC is implemented through microprogrammed control technology (microcode). RISC adds a general register, hard-wired logic control is the main, suitable for pipelined execution. RISC can optimize compilation and effectively support high-level languages. R&amp;D Cycle: CISC has a long development cycle. RISC hardware is simple, so its manufacturing process is simple and low cost.","tags":[{"name":"instruction set arch","slug":"instruction-set-arch","permalink":"https://stu-yue.github.io/tags/instruction-set-arch/"}],"categories":[{"name":"architecture","slug":"architecture","permalink":"https://stu-yue.github.io/categories/architecture/"}]},{"title":"Memo | Installation","date":"2023-10-04T07:56:53.000Z","path":"jottings/tools/docker/memo_install/","text":"Docker åˆ†ä¸º stable test å’Œ nightly ä¸‰ä¸ªæ›´æ–°é¢‘é“ã€‚ å®˜æ–¹ç½‘ç«™ä¸Šæœ‰å„ç§ç¯å¢ƒä¸‹çš„ å®‰è£…æŒ‡å—ï¼Œè¿™é‡Œä¸»è¦ä»‹ç» Docker åœ¨ Linux ã€Windows 10 å’Œ macOS ä¸Šçš„å®‰è£…ã€‚ Ubuntu è­¦å‘Šï¼šåˆ‡å‹¿åœ¨æ²¡æœ‰é…ç½® Docker APT æºçš„æƒ…å†µä¸‹ç›´æ¥ä½¿ç”¨ apt å‘½ä»¤å®‰è£… Docker. å‡†å¤‡å·¥ä½œç³»ç»Ÿè¦æ±‚Docker æ”¯æŒä»¥ä¸‹ç‰ˆæœ¬çš„ Ubuntu æ“ä½œç³»ç»Ÿï¼š Ubuntu Hirsute 21.04 Ubuntu Groovy 20.10 Ubuntu Focal 20.04 (LTS) Ubuntu Bionic 18.04 (LTS) Docker å¯ä»¥å®‰è£…åœ¨ 64 ä½çš„ x86 å¹³å°æˆ– ARM å¹³å°ä¸Šã€‚Ubuntu å‘è¡Œç‰ˆä¸­ï¼ŒLTSï¼ˆLong-Term-Supportï¼‰é•¿æœŸæ”¯æŒç‰ˆæœ¬ï¼Œä¼šè·å¾— 5 å¹´çš„å‡çº§ç»´æŠ¤æ”¯æŒï¼Œè¿™æ ·çš„ç‰ˆæœ¬ä¼šæ›´ç¨³å®šï¼Œå› æ­¤åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ¨èä½¿ç”¨ LTS ç‰ˆæœ¬ã€‚ å¸è½½æ—§ç‰ˆæœ¬æ—§ç‰ˆæœ¬çš„ Docker ç§°ä¸º docker æˆ–è€… docker-engineï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¸è½½æ—§ç‰ˆæœ¬ï¼š 1sudo apt-get remove docker docker-engine docker.io ä½¿ç”¨ APT å®‰è£…ç”±äº apt æºä½¿ç”¨ HTTPS ä»¥ç¡®ä¿è½¯ä»¶ä¸‹è½½è¿‡ç¨‹ä¸­ä¸è¢«ç¯¡æ”¹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦æ·»åŠ ä½¿ç”¨ HTTPS ä¼ è¾“çš„è½¯ä»¶åŒ…ä»¥åŠ CA è¯ä¹¦ã€‚ 1234sudo apt-get updatesudo apt-get install apt-transport-https \\ ca-certificates curl gnupg lsb-release é‰´äºå›½å†…ç½‘ç»œé—®é¢˜ï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨å›½å†…æºï¼Œå®˜æ–¹æºè¯·åœ¨æ³¨é‡Šä¸­æŸ¥çœ‹ã€‚ ä¸ºäº†ç¡®è®¤æ‰€ä¸‹è½½è½¯ä»¶åŒ…çš„åˆæ³•æ€§ï¼Œéœ€è¦æ·»åŠ è½¯ä»¶æºçš„ GPG å¯†é’¥ã€‚ 12345curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg# å®˜æ–¹æº# curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg ç„¶åï¼Œæˆ‘ä»¬éœ€è¦å‘ sources.list ä¸­æ·»åŠ  Docker è½¯ä»¶æº 12345echo &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null# å®˜æ–¹æº# echo &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null ä»¥ä¸Šå‘½ä»¤ä¼šæ·»åŠ ç¨³å®šç‰ˆæœ¬çš„ Docker APT é•œåƒæºï¼Œå¦‚æœéœ€è¦æµ‹è¯•ç‰ˆæœ¬çš„ Docker è¯·å°† stable æ”¹ä¸º testã€‚ å®‰è£… Dockeræ›´æ–° apt è½¯ä»¶åŒ…ç¼“å­˜ï¼Œå¹¶å®‰è£… docker-ceï¼š 123sudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io ä½¿ç”¨è„šæœ¬è‡ªåŠ¨å®‰è£…åœ¨æµ‹è¯•æˆ–å¼€å‘ç¯å¢ƒä¸­ Docker å®˜æ–¹ä¸ºäº†ç®€åŒ–å®‰è£…æµç¨‹ï¼Œæä¾›äº†ä¸€å¥—ä¾¿æ·çš„å®‰è£…è„šæœ¬ï¼ŒUbuntu ç³»ç»Ÿä¸Šå¯ä»¥ä½¿ç”¨è¿™å¥—è„šæœ¬å®‰è£…ï¼Œå¦å¤–å¯ä»¥é€šè¿‡ --mirror é€‰é¡¹ä½¿ç”¨å›½å†…æºè¿›è¡Œå®‰è£…ï¼š è‹¥ä½ æƒ³å®‰è£…æµ‹è¯•ç‰ˆçš„ Docker, è¯·ä» test.docker.com è·å–è„šæœ¬ 1234# curl -fsSL test.docker.com -o get-docker.shcurl -fsSL get.docker.com -o get-docker.shsudo sh get-docker.sh --mirror Aliyun# sudo sh get-docker.sh --mirror AzureChinaCloud æ‰§è¡Œè¿™ä¸ªå‘½ä»¤åï¼Œè„šæœ¬å°±ä¼šè‡ªåŠ¨çš„å°†ä¸€åˆ‡å‡†å¤‡å·¥ä½œåšå¥½ï¼Œå¹¶ä¸”æŠŠ Docker çš„ç¨³å®š(stable)ç‰ˆæœ¬å®‰è£…åœ¨ç³»ç»Ÿä¸­ã€‚ å¯åŠ¨ Docker12sudo systemctl enable dockersudo systemctl start docker å»ºç«‹ docker ç”¨æˆ·ç»„é»˜è®¤æƒ…å†µä¸‹ï¼Œdocker å‘½ä»¤ä¼šä½¿ç”¨ Unix socket ä¸ Docker å¼•æ“é€šè®¯ã€‚è€Œåªæœ‰ root ç”¨æˆ·å’Œ docker ç»„çš„ç”¨æˆ·æ‰å¯ä»¥è®¿é—® Docker å¼•æ“çš„ Unix socketã€‚å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œä¸€èˆ¬ Linux ç³»ç»Ÿä¸Šä¸ä¼šç›´æ¥ä½¿ç”¨ root ç”¨æˆ·ã€‚å› æ­¤ï¼Œæ›´å¥½åœ°åšæ³•æ˜¯å°†éœ€è¦ä½¿ç”¨ docker çš„ç”¨æˆ·åŠ å…¥ docker ç”¨æˆ·ç»„ã€‚ å»ºç«‹ docker ç»„ï¼š 1sudo groupadd docker å°†å½“å‰ç”¨æˆ·åŠ å…¥ docker ç»„ï¼š 1sudo usermod -aG docker $USER é€€å‡ºå½“å‰ç»ˆç«¯å¹¶é‡æ–°ç™»å½•ï¼Œè¿›è¡Œå¦‚ä¸‹æµ‹è¯•ã€‚ æµ‹è¯• Docker æ˜¯å¦å®‰è£…æ­£ç¡®12345678910111213141516171819202122232425262728docker run --rm hello-worldUnable to find image &#x27;hello-world:latest&#x27; locallylatest: Pulling from library/hello-worldb8dfde127a29: Pull completeDigest: sha256:308866a43596e83578c7dfa15e27a73011bdd402185a84c5cd7f32a88b501a24Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ è‹¥èƒ½æ­£å¸¸è¾“å‡ºä»¥ä¸Šä¿¡æ¯ï¼Œåˆ™è¯´æ˜å®‰è£…æˆåŠŸã€‚ é•œåƒåŠ é€Ÿå¦‚æœåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­å‘ç°æ‹‰å– Docker é•œåƒååˆ†ç¼“æ…¢ï¼Œå¯ä»¥é…ç½® Docker å›½å†…é•œåƒåŠ é€Ÿã€‚","tags":[{"name":"docker","slug":"docker","permalink":"https://stu-yue.github.io/tags/docker/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"tools","slug":"tools","permalink":"https://stu-yue.github.io/categories/tools/"},{"name":"docker","slug":"tools/docker","permalink":"https://stu-yue.github.io/categories/tools/docker/"}]},{"title":"Memo | Network","date":"2023-10-04T07:56:53.000Z","path":"jottings/tools/docker/memo_network/","text":"1 å¤–éƒ¨è®¿é—®å®¹å™¨å®¹å™¨ä¸­å¯ä»¥è¿è¡Œä¸€äº›ç½‘ç»œåº”ç”¨ï¼Œè¦è®©å¤–éƒ¨ä¹Ÿå¯ä»¥è®¿é—®è¿™äº›åº”ç”¨ï¼Œå¯ä»¥é€šè¿‡ -P æˆ– -p å‚æ•°æ¥æŒ‡å®šç«¯å£æ˜ å°„ã€‚ å½“ä½¿ç”¨ -P æ ‡è®°æ—¶ï¼ŒDocker ä¼šéšæœºæ˜ å°„ä¸€ä¸ªç«¯å£åˆ°å†…éƒ¨å®¹å™¨å¼€æ”¾çš„ç½‘ç»œç«¯å£ã€‚ ä½¿ç”¨ docker container ls å¯ä»¥çœ‹åˆ°ï¼Œæœ¬åœ°ä¸»æœºçš„ 32768 è¢«æ˜ å°„åˆ°äº†å®¹å™¨çš„ 80 ç«¯å£ã€‚æ­¤æ—¶è®¿é—®æœ¬æœºçš„ 32768 ç«¯å£å³å¯è®¿é—®å®¹å™¨å†… NGINX é»˜è®¤é¡µé¢ã€‚ 12345$ docker run -d -P nginx:alpine$ docker container ls -lCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESfae320d08268 nginx:alpine &quot;/docker-entrypoint.â€¦&quot; 24 seconds ago Up 20 seconds 0.0.0.0:32768-&gt;80/tcp bold_mcnulty åŒæ ·çš„ï¼Œå¯ä»¥é€šè¿‡ docker logs å‘½ä»¤æ¥æŸ¥çœ‹è®¿é—®è®°å½•ã€‚ 12$ docker logs fa172.17.0.1 - - [25/Aug/2020:08:34:04 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0&quot; &quot;-&quot; -p åˆ™å¯ä»¥æŒ‡å®šè¦æ˜ å°„çš„ç«¯å£ï¼Œå¹¶ä¸”ï¼Œåœ¨ä¸€ä¸ªæŒ‡å®šç«¯å£ä¸Šåªå¯ä»¥ç»‘å®šä¸€ä¸ªå®¹å™¨ã€‚æ”¯æŒçš„æ ¼å¼æœ‰ ip:hostPort:containerPort | ip::containerPort | hostPort:containerPortã€‚ æ˜ å°„æ‰€æœ‰æ¥å£åœ°å€ä½¿ç”¨ hostPort:containerPort æ ¼å¼æœ¬åœ°çš„ 80 ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ 80 ç«¯å£ï¼Œå¯ä»¥æ‰§è¡Œ 1$ docker run -d -p 80:80 nginx:alpine æ­¤æ—¶é»˜è®¤ä¼šç»‘å®šæœ¬åœ°æ‰€æœ‰æ¥å£ä¸Šçš„æ‰€æœ‰åœ°å€ã€‚ æ˜ å°„åˆ°æŒ‡å®šåœ°å€çš„æŒ‡å®šç«¯å£å¯ä»¥ä½¿ç”¨ ip:hostPort:containerPort æ ¼å¼æŒ‡å®šæ˜ å°„ä½¿ç”¨ä¸€ä¸ªç‰¹å®šåœ°å€ï¼Œæ¯”å¦‚ localhost åœ°å€ 127.0.0.1 1$ docker run -d -p 127.0.0.1:80:80 nginx:alpine æ˜ å°„åˆ°æŒ‡å®šåœ°å€çš„ä»»æ„ç«¯å£ä½¿ç”¨ ip::containerPort ç»‘å®š localhost çš„ä»»æ„ç«¯å£åˆ°å®¹å™¨çš„ 80 ç«¯å£ï¼Œæœ¬åœ°ä¸»æœºä¼šè‡ªåŠ¨åˆ†é…ä¸€ä¸ªç«¯å£ã€‚ 1$ docker run -d -p 127.0.0.1::80 nginx:alpine è¿˜å¯ä»¥ä½¿ç”¨ udp æ ‡è®°æ¥æŒ‡å®š udp ç«¯å£ 1$ docker run -d -p 127.0.0.1:80:80/udp nginx:alpine æŸ¥çœ‹æ˜ å°„ç«¯å£é…ç½®ä½¿ç”¨ docker port æ¥æŸ¥çœ‹å½“å‰æ˜ å°„çš„ç«¯å£é…ç½®ï¼Œä¹Ÿå¯ä»¥æŸ¥çœ‹åˆ°ç»‘å®šçš„åœ°å€ 12$ docker port fa 800.0.0.0:32768 æ³¨æ„ï¼š å®¹å™¨æœ‰è‡ªå·±çš„å†…éƒ¨ç½‘ç»œå’Œ ip åœ°å€ï¼ˆä½¿ç”¨ docker inspect æŸ¥çœ‹ï¼ŒDocker è¿˜å¯ä»¥æœ‰ä¸€ä¸ªå¯å˜çš„ç½‘ç»œé…ç½®ã€‚ï¼‰ -p æ ‡è®°å¯ä»¥å¤šæ¬¡ä½¿ç”¨æ¥ç»‘å®šå¤šä¸ªç«¯å£ ä¾‹å¦‚ 1234$ docker run -d \\ -p 80:80 \\ -p 443:443 \\ nginx:alpine 2 å®¹å™¨äº’è”å¦‚æœä½ ä¹‹å‰æœ‰ Docker ä½¿ç”¨ç»éªŒï¼Œä½ å¯èƒ½å·²ç»ä¹ æƒ¯äº†ä½¿ç”¨ --link å‚æ•°æ¥ä½¿å®¹å™¨äº’è”ã€‚ éšç€ Docker ç½‘ç»œçš„å®Œå–„ï¼Œå¼ºçƒˆå»ºè®®å¤§å®¶å°†å®¹å™¨åŠ å…¥è‡ªå®šä¹‰çš„ Docker ç½‘ç»œæ¥è¿æ¥å¤šä¸ªå®¹å™¨ï¼Œè€Œä¸æ˜¯ä½¿ç”¨ --link å‚æ•°ã€‚ æ–°å»ºç½‘ç»œä¸‹é¢å…ˆåˆ›å»ºä¸€ä¸ªæ–°çš„ Docker ç½‘ç»œã€‚ 1$ docker network create -d bridge my-net -d å‚æ•°æŒ‡å®š Docker ç½‘ç»œç±»å‹ï¼Œæœ‰ bridge overlayã€‚å…¶ä¸­ overlay ç½‘ç»œç±»å‹ç”¨äº Swarm modeï¼Œåœ¨æœ¬å°èŠ‚ä¸­ä½ å¯ä»¥å¿½ç•¥å®ƒã€‚ è¿æ¥å®¹å™¨è¿è¡Œä¸€ä¸ªå®¹å™¨å¹¶è¿æ¥åˆ°æ–°å»ºçš„ my-net ç½‘ç»œ 1$ docker run -it --rm --name busybox1 --network my-net busybox sh æ‰“å¼€æ–°çš„ç»ˆç«¯ï¼Œå†è¿è¡Œä¸€ä¸ªå®¹å™¨å¹¶åŠ å…¥åˆ° my-net ç½‘ç»œ 1$ docker run -it --rm --name busybox2 --network my-net busybox sh å†æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯æŸ¥çœ‹å®¹å™¨ä¿¡æ¯ 12345$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb47060aca56b busybox &quot;sh&quot; 11 minutes ago Up 11 minutes busybox28720575823ec busybox &quot;sh&quot; 16 minutes ago Up 16 minutes busybox1 ä¸‹é¢é€šè¿‡ ping æ¥è¯æ˜ busybox1 å®¹å™¨å’Œ busybox2 å®¹å™¨å»ºç«‹äº†äº’è”å…³ç³»ã€‚ åœ¨ busybox1 å®¹å™¨è¾“å…¥ä»¥ä¸‹å‘½ä»¤ 1234/ # ping busybox2PING busybox2 (172.19.0.3): 56 data bytes64 bytes from 172.19.0.3: seq=0 ttl=64 time=0.072 ms64 bytes from 172.19.0.3: seq=1 ttl=64 time=0.118 ms ç”¨ ping æ¥æµ‹è¯•è¿æ¥ busybox2 å®¹å™¨ï¼Œå®ƒä¼šè§£ææˆ 172.19.0.3ã€‚ åŒç†åœ¨ busybox2 å®¹å™¨æ‰§è¡Œ ping busybox1ï¼Œä¹Ÿä¼šæˆåŠŸè¿æ¥åˆ°ã€‚ 1234/ # ping busybox1PING busybox1 (172.19.0.2): 56 data bytes64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.064 ms64 bytes from 172.19.0.2: seq=1 ttl=64 time=0.143 ms è¿™æ ·ï¼Œbusybox1 å®¹å™¨å’Œ busybox2 å®¹å™¨å»ºç«‹äº†äº’è”å…³ç³»ã€‚ 3 é…ç½® DNSå¦‚ä½•è‡ªå®šä¹‰é…ç½®å®¹å™¨çš„ä¸»æœºåå’Œ DNS å‘¢ï¼Ÿç§˜è¯€å°±æ˜¯ Docker åˆ©ç”¨è™šæ‹Ÿæ–‡ä»¶æ¥æŒ‚è½½å®¹å™¨çš„ 3 ä¸ªç›¸å…³é…ç½®æ–‡ä»¶ã€‚ åœ¨å®¹å™¨ä¸­ä½¿ç”¨ mount å‘½ä»¤å¯ä»¥çœ‹åˆ°æŒ‚è½½ä¿¡æ¯ï¼š 1234$ mount/dev/disk/by-uuid/1fec...ebdf on /etc/hostname type ext4 .../dev/disk/by-uuid/1fec...ebdf on /etc/hosts type ext4 ...tmpfs on /etc/resolv.conf type tmpfs ... è¿™ç§æœºåˆ¶å¯ä»¥è®©å®¿ä¸»ä¸»æœº DNS ä¿¡æ¯å‘ç”Ÿæ›´æ–°åï¼Œæ‰€æœ‰ Docker å®¹å™¨çš„ DNS é…ç½®é€šè¿‡ /etc/resolv.conf æ–‡ä»¶ç«‹åˆ»å¾—åˆ°æ›´æ–°ã€‚ é…ç½®å…¨éƒ¨å®¹å™¨çš„ DNS ï¼Œä¹Ÿå¯ä»¥åœ¨ /etc/docker/daemon.json æ–‡ä»¶ä¸­å¢åŠ ä»¥ä¸‹å†…å®¹æ¥è®¾ç½®ã€‚ 123456&#123; &quot;dns&quot; : [ &quot;114.114.114.114&quot;, &quot;8.8.8.8&quot; ]&#125; è¿™æ ·æ¯æ¬¡å¯åŠ¨çš„å®¹å™¨ DNS è‡ªåŠ¨é…ç½®ä¸º 114.114.114.114 å’Œ 8.8.8.8ã€‚ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¥è¯æ˜å…¶å·²ç»ç”Ÿæ•ˆã€‚ 1234$ docker run -it --rm ubuntu:18.04 cat etc/resolv.confnameserver 114.114.114.114nameserver 8.8.8.8 å¦‚æœç”¨æˆ·æƒ³è¦æ‰‹åŠ¨æŒ‡å®šå®¹å™¨çš„é…ç½®ï¼Œå¯ä»¥åœ¨ä½¿ç”¨ docker run å‘½ä»¤å¯åŠ¨å®¹å™¨æ—¶åŠ å…¥å¦‚ä¸‹å‚æ•°ï¼š -h HOSTNAME æˆ–è€… --hostname=HOSTNAME è®¾å®šå®¹å™¨çš„ä¸»æœºåï¼Œå®ƒä¼šè¢«å†™åˆ°å®¹å™¨å†…çš„ /etc/hostname å’Œ /etc/hostsã€‚ä½†å®ƒåœ¨å®¹å™¨å¤–éƒ¨çœ‹ä¸åˆ°ï¼Œæ—¢ä¸ä¼šåœ¨ docker container ls ä¸­æ˜¾ç¤ºï¼Œä¹Ÿä¸ä¼šåœ¨å…¶ä»–çš„å®¹å™¨çš„ /etc/hosts çœ‹åˆ°ã€‚ --dns=IP_ADDRESS æ·»åŠ  DNS æœåŠ¡å™¨åˆ°å®¹å™¨çš„ /etc/resolv.conf ä¸­ï¼Œè®©å®¹å™¨ç”¨è¿™ä¸ªæœåŠ¡å™¨æ¥è§£ææ‰€æœ‰ä¸åœ¨ /etc/hosts ä¸­çš„ä¸»æœºåã€‚ --dns-search=DOMAIN è®¾å®šå®¹å™¨çš„æœç´¢åŸŸï¼Œå½“è®¾å®šæœç´¢åŸŸä¸º .example.com æ—¶ï¼Œåœ¨æœç´¢ä¸€ä¸ªåä¸º host çš„ä¸»æœºæ—¶ï¼ŒDNS ä¸ä»…æœç´¢ hostï¼Œè¿˜ä¼šæœç´¢ host.example.comã€‚ æ³¨æ„ï¼šå¦‚æœåœ¨å®¹å™¨å¯åŠ¨æ—¶æ²¡æœ‰æŒ‡å®šæœ€åä¸¤ä¸ªå‚æ•°ï¼ŒDocker ä¼šé»˜è®¤ç”¨ä¸»æœºä¸Šçš„ /etc/resolv.conf æ¥é…ç½®å®¹å™¨ã€‚","tags":[{"name":"docker","slug":"docker","permalink":"https://stu-yue.github.io/tags/docker/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"tools","slug":"tools","permalink":"https://stu-yue.github.io/categories/tools/"},{"name":"docker","slug":"tools/docker","permalink":"https://stu-yue.github.io/categories/tools/docker/"}]},{"title":"Memo | Operation","date":"2023-10-04T07:56:53.000Z","path":"jottings/tools/docker/memo_operation/","text":"1 å¯åŠ¨å¯åŠ¨å®¹å™¨æœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯åŸºäºé•œåƒæ–°å»ºä¸€ä¸ªå®¹å™¨å¹¶å¯åŠ¨ï¼Œå¦å¤–ä¸€ä¸ªæ˜¯å°†åœ¨ç»ˆæ­¢çŠ¶æ€ï¼ˆexitedï¼‰çš„å®¹å™¨é‡æ–°å¯åŠ¨ã€‚ å› ä¸º Docker çš„å®¹å™¨å®åœ¨å¤ªè½»é‡çº§äº†ï¼Œå¾ˆå¤šæ—¶å€™ç”¨æˆ·éƒ½æ˜¯éšæ—¶åˆ é™¤å’Œæ–°åˆ›å»ºå®¹å™¨ã€‚ æ–°å»ºå¹¶å¯åŠ¨æ‰€éœ€è¦çš„å‘½ä»¤ä¸»è¦ä¸º docker runã€‚ ä¾‹å¦‚ï¼Œä¸‹é¢çš„å‘½ä»¤è¾“å‡ºä¸€ä¸ª â€œHello Worldâ€ï¼Œä¹‹åç»ˆæ­¢å®¹å™¨ã€‚ 12$ docker run ubuntu:18.04 /bin/echo &#x27;Hello world&#x27;Hello world è¿™è·Ÿåœ¨æœ¬åœ°ç›´æ¥æ‰§è¡Œ /bin/echo &#39;hello world&#39; å‡ ä¹æ„Ÿè§‰ä¸å‡ºä»»ä½•åŒºåˆ«ã€‚ ä¸‹é¢çš„å‘½ä»¤åˆ™å¯åŠ¨ä¸€ä¸ª bash ç»ˆç«¯ï¼Œå…è®¸ç”¨æˆ·è¿›è¡Œäº¤äº’ã€‚ 12$ docker run -t -i ubuntu:18.04 /bin/bashroot@af8bae53bdd3:/# å…¶ä¸­ï¼Œ-t é€‰é¡¹è®©Dockeråˆ†é…ä¸€ä¸ªä¼ªç»ˆç«¯ï¼ˆpseudo-ttyï¼‰å¹¶ç»‘å®šåˆ°å®¹å™¨çš„æ ‡å‡†è¾“å…¥ä¸Šï¼Œ -i åˆ™è®©å®¹å™¨çš„æ ‡å‡†è¾“å…¥ä¿æŒæ‰“å¼€ã€‚ åœ¨äº¤äº’æ¨¡å¼ä¸‹ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡æ‰€åˆ›å»ºçš„ç»ˆç«¯æ¥è¾“å…¥å‘½ä»¤ï¼Œä¾‹å¦‚ 1234root@af8bae53bdd3:/# pwd/root@af8bae53bdd3:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var å½“åˆ©ç”¨ docker run æ¥åˆ›å»ºå®¹å™¨æ—¶ï¼ŒDocker åœ¨åå°è¿è¡Œçš„æ ‡å‡†æ“ä½œåŒ…æ‹¬ï¼š æ£€æŸ¥æœ¬åœ°æ˜¯å¦å­˜åœ¨æŒ‡å®šçš„é•œåƒï¼Œä¸å­˜åœ¨å°±ä» registry ä¸‹è½½ åˆ©ç”¨é•œåƒåˆ›å»ºå¹¶å¯åŠ¨ä¸€ä¸ªå®¹å™¨ åˆ†é…ä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿï¼Œå¹¶åœ¨åªè¯»çš„é•œåƒå±‚å¤–é¢æŒ‚è½½ä¸€å±‚å¯è¯»å†™å±‚ ä»å®¿ä¸»ä¸»æœºé…ç½®çš„ç½‘æ¡¥æ¥å£ä¸­æ¡¥æ¥ä¸€ä¸ªè™šæ‹Ÿæ¥å£åˆ°å®¹å™¨ä¸­å» ä»åœ°å€æ± é…ç½®ä¸€ä¸ª ip åœ°å€ç»™å®¹å™¨ æ‰§è¡Œç”¨æˆ·æŒ‡å®šçš„åº”ç”¨ç¨‹åº æ‰§è¡Œå®Œæ¯•åå®¹å™¨è¢«ç»ˆæ­¢ å¯åŠ¨å·²ç»ˆæ­¢å®¹å™¨å¯ä»¥åˆ©ç”¨ docker container start å‘½ä»¤ï¼Œç›´æ¥å°†ä¸€ä¸ªå·²ç»ç»ˆæ­¢ï¼ˆexitedï¼‰çš„å®¹å™¨å¯åŠ¨è¿è¡Œã€‚ å®¹å™¨çš„æ ¸å¿ƒä¸ºæ‰€æ‰§è¡Œçš„åº”ç”¨ç¨‹åºï¼Œæ‰€éœ€è¦çš„èµ„æºéƒ½æ˜¯åº”ç”¨ç¨‹åºè¿è¡Œæ‰€å¿…éœ€çš„ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå¹¶æ²¡æœ‰å…¶å®ƒçš„èµ„æºã€‚å¯ä»¥åœ¨ä¼ªç»ˆç«¯ä¸­åˆ©ç”¨ ps æˆ– top æ¥æŸ¥çœ‹è¿›ç¨‹ä¿¡æ¯ã€‚ 1234root@ba267838cc1b:/# ps PID TTY TIME CMD 1 ? 00:00:00 bash 11 ? 00:00:00 ps å¯è§ï¼Œå®¹å™¨ä¸­ä»…è¿è¡Œäº†æŒ‡å®šçš„ bash åº”ç”¨ã€‚è¿™ç§ç‰¹ç‚¹ä½¿å¾— Docker å¯¹èµ„æºçš„åˆ©ç”¨ç‡æé«˜ï¼Œæ˜¯è´§çœŸä»·å®çš„è½»é‡çº§è™šæ‹ŸåŒ–ã€‚ 2 å®ˆæŠ¤æ€è¿è¡Œæ›´å¤šçš„æ—¶å€™ï¼Œéœ€è¦è®© Docker åœ¨åå°è¿è¡Œè€Œä¸æ˜¯ç›´æ¥æŠŠæ‰§è¡Œå‘½ä»¤çš„ç»“æœè¾“å‡ºåœ¨å½“å‰å®¿ä¸»æœºä¸‹ã€‚æ­¤æ—¶ï¼Œå¯ä»¥é€šè¿‡æ·»åŠ  **-d å‚æ•° (Detach)**æ¥å®ç°ã€‚ ä¸‹é¢ä¸¾ä¸¤ä¸ªä¾‹å­æ¥è¯´æ˜ä¸€ä¸‹ã€‚ å¦‚æœä¸ä½¿ç”¨ -d å‚æ•°è¿è¡Œå®¹å™¨ã€‚ 12345$ docker run ubuntu:18.04 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;hello worldhello worldhello worldhello world å®¹å™¨ä¼šæŠŠè¾“å‡ºçš„ç»“æœ (STDOUT) æ‰“å°åˆ°å®¿ä¸»æœºä¸Šé¢ å¦‚æœä½¿ç”¨äº† -d å‚æ•°è¿è¡Œå®¹å™¨ã€‚ 12$ docker run -d ubuntu:18.04 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;77b2dc01fe0f3f1265df143181e7b9af5e05279a884f4776ee75350ea9d8017a æ­¤æ—¶å®¹å™¨ä¼šåœ¨åå°è¿è¡Œå¹¶ä¸ä¼šæŠŠè¾“å‡ºçš„ç»“æœ (STDOUT) æ‰“å°åˆ°å®¿ä¸»æœºä¸Šé¢(è¾“å‡ºç»“æœå¯ä»¥ç”¨ docker logs æŸ¥çœ‹)ã€‚ æ³¨ï¼š å®¹å™¨æ˜¯å¦ä¼šé•¿ä¹…è¿è¡Œï¼Œæ˜¯å’Œ docker run æŒ‡å®šçš„å‘½ä»¤æœ‰å…³ï¼Œå’Œ -d å‚æ•°æ— å…³ã€‚ ä½¿ç”¨ -d å‚æ•°å¯åŠ¨åä¼šè¿”å›ä¸€ä¸ªå”¯ä¸€çš„ idï¼Œä¹Ÿå¯ä»¥é€šè¿‡ docker container ls å‘½ä»¤æ¥æŸ¥çœ‹å®¹å™¨ä¿¡æ¯ã€‚ 123$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES77b2dc01fe0f ubuntu:18.04 /bin/sh -c &#x27;while tr 2 minutes ago Up 1 minute agitated_wright è¦è·å–å®¹å™¨çš„è¾“å‡ºä¿¡æ¯ï¼Œå¯ä»¥é€šè¿‡ docker container logs å‘½ä»¤ã€‚ 12345$ docker container logs [container ID or NAMES]hello worldhello worldhello world. . . 3 ç»ˆæ­¢å¯ä»¥ä½¿ç”¨ docker container stop æ¥ç»ˆæ­¢ä¸€ä¸ªè¿è¡Œä¸­çš„å®¹å™¨ã€‚ æ­¤å¤–ï¼Œå½“ Docker å®¹å™¨ä¸­æŒ‡å®šçš„åº”ç”¨ç»ˆç»“æ—¶ï¼Œå®¹å™¨ä¹Ÿè‡ªåŠ¨ç»ˆæ­¢ã€‚ ä¾‹å¦‚å¯¹äºä¸Šä¸€ç« èŠ‚ä¸­åªå¯åŠ¨äº†ä¸€ä¸ªç»ˆç«¯çš„å®¹å™¨ï¼Œç”¨æˆ·é€šè¿‡ exit å‘½ä»¤æˆ– Ctrl+d æ¥é€€å‡ºç»ˆç«¯æ—¶ï¼Œæ‰€åˆ›å»ºçš„å®¹å™¨ç«‹åˆ»ç»ˆæ­¢ã€‚ ç»ˆæ­¢çŠ¶æ€çš„å®¹å™¨å¯ä»¥ç”¨ docker container ls -a å‘½ä»¤çœ‹åˆ°ã€‚ä¾‹å¦‚ 123$ docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESba267838cc1b ubuntu:18.04 &quot;/bin/bash&quot; 30 minutes ago Exited (0) About a minute ago trusting_newton å¤„äºç»ˆæ­¢çŠ¶æ€çš„å®¹å™¨ï¼Œå¯ä»¥é€šè¿‡ docker container start å‘½ä»¤æ¥é‡æ–°å¯åŠ¨ã€‚ æ­¤å¤–ï¼Œdocker container restart å‘½ä»¤ä¼šå°†ä¸€ä¸ªè¿è¡Œæ€çš„å®¹å™¨ç»ˆæ­¢ï¼Œç„¶åå†é‡æ–°å¯åŠ¨å®ƒã€‚ 4 è¿›å…¥å®¹å™¨åœ¨ä½¿ç”¨ -d å‚æ•°æ—¶ï¼Œå®¹å™¨å¯åŠ¨åä¼šè¿›å…¥åå°ã€‚ æŸäº›æ—¶å€™éœ€è¦è¿›å…¥å®¹å™¨è¿›è¡Œæ“ä½œï¼ŒåŒ…æ‹¬ä½¿ç”¨ docker attach å‘½ä»¤æˆ– docker exec å‘½ä»¤ï¼Œæ¨èå¤§å®¶ä½¿ç”¨ docker exec å‘½ä»¤ï¼ŒåŸå› ä¼šåœ¨ä¸‹é¢è¯´æ˜ã€‚ attach å‘½ä»¤ä¸‹é¢ç¤ºä¾‹å¦‚ä½•ä½¿ç”¨ docker attach å‘½ä»¤ã€‚ 123456789$ docker run -dit ubuntu243c32535da7d142fb0e6df616a3c3ada0b8ab417937c853a9e1c251f499f550$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES243c32535da7 ubuntu:latest &quot;/bin/bash&quot; 18 seconds ago Up 17 seconds nostalgic_hypatia$ docker attach 243croot@243c32535da7:/# æ³¨æ„ï¼š å¦‚æœä»è¿™ä¸ª stdin ä¸­ exitï¼Œä¼šå¯¼è‡´å®¹å™¨çš„åœæ­¢ã€‚ exec å‘½ä»¤-i -t å‚æ•°docker exec åè¾¹å¯ä»¥è·Ÿå¤šä¸ªå‚æ•°ï¼Œè¿™é‡Œä¸»è¦è¯´æ˜ -i -t å‚æ•°ã€‚ åªç”¨ -i å‚æ•°æ—¶ï¼Œç”±äºæ²¡æœ‰åˆ†é…ä¼ªç»ˆç«¯ï¼Œç•Œé¢æ²¡æœ‰æˆ‘ä»¬ç†Ÿæ‚‰çš„ Linux å‘½ä»¤æç¤ºç¬¦ï¼Œä½†å‘½ä»¤æ‰§è¡Œç»“æœä»ç„¶å¯ä»¥è¿”å›ã€‚ å½“ -i -t å‚æ•°ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œåˆ™å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ç†Ÿæ‚‰çš„ Linux å‘½ä»¤æç¤ºç¬¦ã€‚ 12345678910111213141516$ docker run -dit ubuntu69d137adef7a8a689cbcb059e94da5489d3cddd240ff675c640c8d96e84fe1f6$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES69d137adef7a ubuntu:latest &quot;/bin/bash&quot; 18 seconds ago Up 17 seconds zealous_swirles$ docker exec -i 69d1 bashlsbinbootdev...$ docker exec -it 69d1 bashroot@69d137adef7a:/# å¦‚æœä»è¿™ä¸ª stdin ä¸­ exitï¼Œä¸ä¼šå¯¼è‡´å®¹å™¨çš„åœæ­¢ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ¨èå¤§å®¶ä½¿ç”¨ docker exec çš„åŸå› ã€‚ 4 å¯¼å‡ºå’Œå¯¼å…¥å¯¼å‡ºå®¹å™¨å¦‚æœè¦å¯¼å‡ºæœ¬åœ°æŸä¸ªå®¹å™¨ï¼Œå¯ä»¥ä½¿ç”¨ docker export å‘½ä»¤ã€‚ 1234$ docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7691a814370e ubuntu:18.04 &quot;/bin/bash&quot; 36 hours ago Exited (0) 21 hours ago test$ docker export 7691a814370e &gt; ubuntu.tar è¿™æ ·å°†å¯¼å‡ºå®¹å™¨å¿«ç…§åˆ°æœ¬åœ°æ–‡ä»¶ã€‚ å¯¼å…¥å®¹å™¨å¿«ç…§å¯ä»¥ä½¿ç”¨ docker import ä»å®¹å™¨å¿«ç…§æ–‡ä»¶ä¸­å†å¯¼å…¥ä¸ºé•œåƒï¼Œä¾‹å¦‚ 1234$ cat ubuntu.tar | docker import - test/ubuntu:v1.0$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEtest/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB æ­¤å¤–ï¼Œä¹Ÿå¯ä»¥é€šè¿‡æŒ‡å®š URL æˆ–è€…æŸä¸ªç›®å½•æ¥å¯¼å…¥ï¼Œä¾‹å¦‚ 1$ docker import http://example.com/exampleimage.tgz example/imagerepo æ³¨ï¼šç”¨æˆ·æ—¢å¯ä»¥ä½¿ç”¨ docker load æ¥å¯¼å…¥é•œåƒå­˜å‚¨æ–‡ä»¶åˆ°æœ¬åœ°é•œåƒåº“ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ docker importæ¥å¯¼å…¥ä¸€ä¸ªå®¹å™¨å¿«ç…§åˆ°æœ¬åœ°é•œåƒåº“ã€‚è¿™ä¸¤è€…çš„åŒºåˆ«åœ¨äºå®¹å™¨å¿«ç…§æ–‡ä»¶å°†ä¸¢å¼ƒæ‰€æœ‰çš„å†å²è®°å½•å’Œå…ƒæ•°æ®ä¿¡æ¯ï¼ˆå³ä»…ä¿å­˜å®¹å™¨å½“æ—¶çš„å¿«ç…§çŠ¶æ€ï¼‰ï¼Œè€Œé•œåƒå­˜å‚¨æ–‡ä»¶å°†ä¿å­˜å®Œæ•´è®°å½•ï¼Œä½“ç§¯ä¹Ÿè¦å¤§ã€‚æ­¤å¤–ï¼Œä»å®¹å™¨å¿«ç…§æ–‡ä»¶å¯¼å…¥æ—¶å¯ä»¥é‡æ–°æŒ‡å®šæ ‡ç­¾ç­‰å…ƒæ•°æ®ä¿¡æ¯ã€‚ ä¿å­˜é•œåƒå½’æ¡£æ–‡ä»¶ å°†ä¸€ä¸ªé•œåƒä¿å­˜åˆ°ä¸€ä¸ª tar æ–‡ä»¶ 1docker save -o myimage_v1.tar myimage:v1 å°†å¤šä¸ªé•œåƒä¿å­˜åˆ°ä¸€ä¸ª tar æ–‡ä»¶ 1docker save -o myimages.tar myimage:v1 myimage:v2 é€šè¿‡é‡å®šå‘æ¥ä¿å­˜é•œåƒ ï¼ˆä¸ç”¨-oå‚æ•°ï¼‰ 1docker save myimage:v1 &gt; myimage_v1.tar åŠ è½½é•œåƒå½’æ¡£æ–‡ä»¶ ä½¿ç”¨ --input é€‰é¡¹ 1docker load --input[-i] myimage.tar ä½¿ç”¨ç®¡é“ 1cat myimage.tar | docker load [-] å…¶ä¸­ - ä»£è¡¨æ ‡å‡†è¾“å…¥&#x2F;è¾“å‡ºã€‚ 5 åˆ é™¤åˆ é™¤å®¹å™¨å¯ä»¥ä½¿ç”¨ docker container rm æ¥åˆ é™¤ä¸€ä¸ªå¤„äºç»ˆæ­¢çŠ¶æ€çš„å®¹å™¨ã€‚ä¾‹å¦‚ 12$ docker container rm trusting_newtontrusting_newton å¦‚æœè¦åˆ é™¤ä¸€ä¸ªè¿è¡Œä¸­çš„å®¹å™¨ï¼Œå¯ä»¥æ·»åŠ  -f å‚æ•°ã€‚Docker ä¼šå‘é€ SIGKILL ä¿¡å·ç»™å®¹å™¨ã€‚ æ¸…ç†æ‰€æœ‰å¤„äºç»ˆæ­¢çŠ¶æ€çš„å®¹å™¨ç”¨ docker container ls -a å‘½ä»¤å¯ä»¥æŸ¥çœ‹æ‰€æœ‰å·²ç»åˆ›å»ºçš„åŒ…æ‹¬ç»ˆæ­¢çŠ¶æ€çš„å®¹å™¨ï¼Œå¦‚æœæ•°é‡å¤ªå¤šè¦ä¸€ä¸ªä¸ªåˆ é™¤å¯èƒ½ä¼šå¾ˆéº»çƒ¦ï¼Œç”¨ä¸‹é¢çš„å‘½ä»¤å¯ä»¥æ¸…ç†æ‰æ‰€æœ‰å¤„äºç»ˆæ­¢çŠ¶æ€çš„å®¹å™¨ã€‚ 1$ docker container prune","tags":[{"name":"docker","slug":"docker","permalink":"https://stu-yue.github.io/tags/docker/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"tools","slug":"tools","permalink":"https://stu-yue.github.io/categories/tools/"},{"name":"docker","slug":"tools/docker","permalink":"https://stu-yue.github.io/categories/tools/docker/"}]},{"title":"Memo | Regitstry and Data","date":"2023-10-04T07:56:53.000Z","path":"jottings/tools/docker/memo_registry_and_data/","text":"1 ç§æœ‰ä»“åº“æœ‰æ—¶å€™ä½¿ç”¨ Docker Hub è¿™æ ·çš„å…¬å…±ä»“åº“å¯èƒ½ä¸æ–¹ä¾¿ï¼Œç”¨æˆ·å¯ä»¥åˆ›å»ºä¸€ä¸ªæœ¬åœ°ä»“åº“ä¾›ç§äººä½¿ç”¨ã€‚ docker-registry æ˜¯å®˜æ–¹æä¾›çš„å·¥å…·ï¼Œå¯ä»¥ç”¨äºæ„å»ºç§æœ‰çš„é•œåƒä»“åº“ã€‚æœ¬æ–‡å†…å®¹åŸºäº docker-registry v2.x ç‰ˆæœ¬ã€‚ å®‰è£…è¿è¡Œ docker-registryå®¹å™¨è¿è¡Œä½ å¯ä»¥ä½¿ç”¨å®˜æ–¹ registry é•œåƒæ¥è¿è¡Œã€‚ 1$ docker run -d -p 5000:5000 --restart=always --name registry registry è¿™å°†ä½¿ç”¨å®˜æ–¹çš„ registry é•œåƒæ¥å¯åŠ¨ç§æœ‰ä»“åº“ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä»“åº“ä¼šè¢«åˆ›å»ºåœ¨å®¹å™¨çš„ /var/lib/registry ç›®å½•ä¸‹ã€‚ä½ å¯ä»¥é€šè¿‡ -v å‚æ•°æ¥å°†é•œåƒæ–‡ä»¶å­˜æ”¾åœ¨æœ¬åœ°çš„æŒ‡å®šè·¯å¾„ã€‚ä¾‹å¦‚ä¸‹é¢çš„ä¾‹å­å°†ä¸Šä¼ çš„é•œåƒæ”¾åˆ°æœ¬åœ°çš„ /opt/data/registry ç›®å½•ã€‚ 1234$ docker run -d \\ -p 5000:5000 \\ -v /opt/data/registry:/var/lib/registry \\ registry åœ¨ç§æœ‰ä»“åº“ä¸Šä¼ ã€æœç´¢ã€ä¸‹è½½é•œåƒåˆ›å»ºå¥½ç§æœ‰ä»“åº“ä¹‹åï¼Œå°±å¯ä»¥ä½¿ç”¨ docker tag æ¥æ ‡è®°ä¸€ä¸ªé•œåƒï¼Œç„¶åæ¨é€å®ƒåˆ°ä»“åº“ã€‚ä¾‹å¦‚ç§æœ‰ä»“åº“åœ°å€ä¸º 127.0.0.1:5000ã€‚ å…ˆåœ¨æœ¬æœºæŸ¥çœ‹å·²æœ‰çš„é•œåƒã€‚ 123$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB ä½¿ç”¨ docker tag å°† ubuntu:latest è¿™ä¸ªé•œåƒæ ‡è®°ä¸º 127.0.0.1:5000/ubuntu:latestã€‚ æ ¼å¼ä¸º docker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG]ã€‚ 12345$ docker tag ubuntu:latest 127.0.0.1:5000/ubuntu:latest$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB127.0.0.1:5000/ubuntu:latest latest ba5877dc9bec 6 weeks ago 192.7 MB ä½¿ç”¨ docker push ä¸Šä¼ æ ‡è®°çš„é•œåƒã€‚ 123456789$ docker push 127.0.0.1:5000/ubuntu:latestThe push refers to repository [127.0.0.1:5000/ubuntu]373a30c24545: Pusheda9148f5200b0: Pushedcdd3de0940ab: Pushedfc56279bbb33: Pushedb38367233d37: Pushed2aebd096e0e2: Pushedlatest: digest: sha256:fe4277621f10b5026266932ddf760f5a756d2facd505a94d2da12f4f52f71f5a size: 1568 ç”¨ curl æŸ¥çœ‹ä»“åº“ä¸­çš„é•œåƒã€‚ 12$ curl 127.0.0.1:5000/v2/_catalog&#123;&quot;repositories&quot;:[&quot;ubuntu&quot;]&#125; è¿™é‡Œå¯ä»¥çœ‹åˆ° &#123;&quot;repositories&quot;:[&quot;ubuntu&quot;]&#125;ï¼Œè¡¨æ˜é•œåƒå·²ç»è¢«æˆåŠŸä¸Šä¼ äº†ã€‚ å…ˆåˆ é™¤å·²æœ‰é•œåƒï¼Œå†å°è¯•ä»ç§æœ‰ä»“åº“ä¸­ä¸‹è½½è¿™ä¸ªé•œåƒã€‚ 1234567891011121314$ docker image rm 127.0.0.1:5000/ubuntu:latest$ docker pull 127.0.0.1:5000/ubuntu:latestPulling repository 127.0.0.1:5000/ubuntu:latestba5877dc9bec: Download complete511136ea3c5a: Download complete9bad880da3d2: Download complete25f11f5fb0cb: Download completeebc34468f71d: Download complete2318d26665ef: Download complete$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE127.0.0.1:5000/ubuntu:latest latest ba5877dc9bec 6 weeks ago 192.7 MB é…ç½®é https ä»“åº“åœ°å€å¦‚æœä½ ä¸æƒ³ä½¿ç”¨ 127.0.0.1:5000 ä½œä¸ºä»“åº“åœ°å€ï¼Œæ¯”å¦‚æƒ³è®©æœ¬ç½‘æ®µçš„å…¶ä»–ä¸»æœºä¹Ÿèƒ½æŠŠé•œåƒæ¨é€åˆ°ç§æœ‰ä»“åº“ã€‚ä½ å°±å¾—æŠŠä¾‹å¦‚ 192.168.199.100:5000 è¿™æ ·çš„å†…ç½‘åœ°å€ä½œä¸ºç§æœ‰ä»“åº“åœ°å€ï¼Œè¿™æ—¶ä½ ä¼šå‘ç°æ— æ³•æˆåŠŸæ¨é€é•œåƒã€‚ è¿™æ˜¯å› ä¸º Docker é»˜è®¤ä¸å…è®¸é HTTPS æ–¹å¼æ¨é€é•œåƒã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ Docker çš„é…ç½®é€‰é¡¹æ¥å–æ¶ˆè¿™ä¸ªé™åˆ¶ï¼Œæˆ–è€…æŸ¥çœ‹ä¸‹ä¸€èŠ‚é…ç½®èƒ½å¤Ÿé€šè¿‡ HTTPS è®¿é—®çš„ç§æœ‰ä»“åº“ã€‚ Ubuntu 16.04+, Debian 8+, centos 7å¯¹äºä½¿ç”¨ systemd çš„ç³»ç»Ÿï¼Œè¯·åœ¨ /etc/docker/daemon.json ä¸­å†™å…¥å¦‚ä¸‹å†…å®¹ï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨è¯·æ–°å»ºè¯¥æ–‡ä»¶ï¼‰ 123456789&#123; &quot;registry-mirrors&quot;: [ &quot;https://hub-mirror.c.163.com&quot;, &quot;https://mirror.baidubce.com&quot; ], &quot;insecure-registries&quot;: [ &quot;192.168.199.100:5000&quot; ]&#125; æ³¨æ„ï¼šè¯¥æ–‡ä»¶å¿…é¡»ç¬¦åˆ json è§„èŒƒï¼Œå¦åˆ™ Docker å°†ä¸èƒ½å¯åŠ¨ã€‚ å…¶ä»–å¯¹äº Docker Desktop for Windows ã€ Docker Desktop for Mac åœ¨è®¾ç½®ä¸­çš„ Docker Engine ä¸­è¿›è¡Œç¼–è¾‘ ï¼Œå¢åŠ å’Œä¸Šè¾¹ä¸€æ ·çš„å­—ç¬¦ä¸²å³å¯ã€‚ 2 æ•°æ®å·æ•°æ®å· æ˜¯ä¸€ä¸ªå¯ä¾›ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨ä½¿ç”¨çš„ç‰¹æ®Šç›®å½•ï¼Œå®ƒç»•è¿‡ UnionFSï¼Œå¯ä»¥æä¾›å¾ˆå¤šæœ‰ç”¨çš„ç‰¹æ€§ï¼š æ•°æ®å· å¯ä»¥åœ¨å®¹å™¨ä¹‹é—´å…±äº«å’Œé‡ç”¨ å¯¹ æ•°æ®å· çš„ä¿®æ”¹ä¼šç«‹é©¬ç”Ÿæ•ˆ å¯¹ æ•°æ®å· çš„æ›´æ–°ï¼Œä¸ä¼šå½±å“é•œåƒ æ•°æ®å· é»˜è®¤ä¼šä¸€ç›´å­˜åœ¨ï¼Œå³ä½¿å®¹å™¨è¢«åˆ é™¤ æ³¨æ„ï¼šæ•°æ®å· çš„ä½¿ç”¨ï¼Œç±»ä¼¼äº Linux ä¸‹å¯¹ç›®å½•æˆ–æ–‡ä»¶è¿›è¡Œ mountï¼Œé•œåƒä¸­çš„è¢«æŒ‡å®šä¸ºæŒ‚è½½ç‚¹çš„ç›®å½•ä¸­çš„æ–‡ä»¶ä¼šå¤åˆ¶åˆ°æ•°æ®å·ä¸­ï¼ˆä»…æ•°æ®å·ä¸ºç©ºæ—¶ä¼šå¤åˆ¶ï¼‰ã€‚ åˆ›å»ºä¸€ä¸ªæ•°æ®å·1$ docker volume create my-vol æŸ¥çœ‹æ‰€æœ‰çš„ æ•°æ®å· 1234$ docker volume lsDRIVER VOLUME NAMElocal my-vol åœ¨ä¸»æœºé‡Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯ä»¥æŸ¥çœ‹æŒ‡å®š æ•°æ®å· çš„ä¿¡æ¯ å¤åˆ¶ 1234567891011$ docker volume inspect my-vol[ &#123; &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;] å¯åŠ¨ä¸€ä¸ªæŒ‚è½½æ•°æ®å·çš„å®¹å™¨åœ¨ç”¨ docker run å‘½ä»¤çš„æ—¶å€™ï¼Œä½¿ç”¨ --mount æ ‡è®°æ¥å°† æ•°æ®å· æŒ‚è½½åˆ°å®¹å™¨é‡Œã€‚åœ¨ä¸€æ¬¡ docker run ä¸­å¯ä»¥æŒ‚è½½å¤šä¸ª æ•°æ®å·ã€‚ ä¸‹é¢åˆ›å»ºä¸€ä¸ªåä¸º web çš„å®¹å™¨ï¼Œå¹¶åŠ è½½ä¸€ä¸ª æ•°æ®å· åˆ°å®¹å™¨çš„ /usr/share/nginx/html ç›®å½•ã€‚ 12345$ docker run -d -P \\ --name web \\ # -v my-vol:/usr/share/nginx/html \\ --mount source=my-vol,target=/usr/share/nginx/html \\ nginx:alpine æŸ¥çœ‹æ•°æ®å·çš„å…·ä½“ä¿¡æ¯åœ¨ä¸»æœºé‡Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯ä»¥æŸ¥çœ‹ web å®¹å™¨çš„ä¿¡æ¯ 1$ docker inspect web æ•°æ®å· ä¿¡æ¯åœ¨ â€œMountsâ€ Key ä¸‹é¢ 123456789101112&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125;], åˆ é™¤æ•°æ®å·1$ docker volume rm my-vol æ•°æ®å· æ˜¯è¢«è®¾è®¡ç”¨æ¥æŒä¹…åŒ–æ•°æ®çš„ï¼Œå®ƒçš„ç”Ÿå‘½å‘¨æœŸç‹¬ç«‹äºå®¹å™¨ï¼ŒDocker ä¸ä¼šåœ¨å®¹å™¨è¢«åˆ é™¤åè‡ªåŠ¨åˆ é™¤ æ•°æ®å·ï¼Œå¹¶ä¸”ä¹Ÿä¸å­˜åœ¨åƒåœ¾å›æ”¶è¿™æ ·çš„æœºåˆ¶æ¥å¤„ç†æ²¡æœ‰ä»»ä½•å®¹å™¨å¼•ç”¨çš„ æ•°æ®å·ã€‚å¦‚æœéœ€è¦åœ¨åˆ é™¤å®¹å™¨çš„åŒæ—¶ç§»é™¤æ•°æ®å·ã€‚å¯ä»¥åœ¨åˆ é™¤å®¹å™¨çš„æ—¶å€™ä½¿ç”¨ docker rm -v è¿™ä¸ªå‘½ä»¤ã€‚ æ— ä¸»çš„æ•°æ®å·å¯èƒ½ä¼šå æ®å¾ˆå¤šç©ºé—´ï¼Œè¦æ¸…ç†è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ 1$ docker volume prune 3 æŒ‚è½½ä¸»æœºç›®å½•æŒ‚è½½ä¸€ä¸ªä¸»æœºç›®å½•ä½œä¸ºæ•°æ®å·ä½¿ç”¨ --mount æ ‡è®°å¯ä»¥æŒ‡å®šæŒ‚è½½ä¸€ä¸ªæœ¬åœ°ä¸»æœºçš„ç›®å½•åˆ°å®¹å™¨ä¸­å»ã€‚ 12345$ docker run -d -P \\ --name web \\ # -v /src/webapp:/usr/share/nginx/html \\ --mount type=bind,source=/src/webapp,target=/usr/share/nginx/html \\ nginx:alpine ä¸Šé¢çš„å‘½ä»¤åŠ è½½ä¸»æœºçš„ /src/webapp ç›®å½•åˆ°å®¹å™¨çš„ /usr/share/nginx/htmlç›®å½•ã€‚è¿™ä¸ªåŠŸèƒ½åœ¨è¿›è¡Œæµ‹è¯•çš„æ—¶å€™ååˆ†æ–¹ä¾¿ï¼Œæ¯”å¦‚ç”¨æˆ·å¯ä»¥æ”¾ç½®ä¸€äº›ç¨‹åºåˆ°æœ¬åœ°ç›®å½•ä¸­ï¼Œæ¥æŸ¥çœ‹å®¹å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚æœ¬åœ°ç›®å½•çš„è·¯å¾„å¿…é¡»æ˜¯ç»å¯¹è·¯å¾„ï¼Œä»¥å‰ä½¿ç”¨ -v å‚æ•°æ—¶å¦‚æœæœ¬åœ°ç›®å½•ä¸å­˜åœ¨ Docker ä¼šè‡ªåŠ¨ä¸ºä½ åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œç°åœ¨ä½¿ç”¨ --mount å‚æ•°æ—¶å¦‚æœæœ¬åœ°ç›®å½•ä¸å­˜åœ¨ï¼ŒDocker ä¼šæŠ¥é”™ã€‚ **Docker æŒ‚è½½ä¸»æœºç›®å½•çš„é»˜è®¤æƒé™æ˜¯ è¯»å†™ï¼Œç”¨æˆ·ä¹Ÿå¯ä»¥é€šè¿‡å¢åŠ  readonly æŒ‡å®šä¸º åªè¯»**ã€‚ 12345$ docker run -d -P \\ --name web \\ # -v /src/webapp:/usr/share/nginx/html:ro \\ --mount type=bind,source=/src/webapp,target=/usr/share/nginx/html,readonly \\ nginx:alpine åŠ äº† readonly ä¹‹åï¼Œå°±æŒ‚è½½ä¸º åªè¯» äº†ã€‚å¦‚æœä½ åœ¨å®¹å™¨å†… /usr/share/nginx/html ç›®å½•æ–°å»ºæ–‡ä»¶ï¼Œä¼šæ˜¾ç¤ºå¦‚ä¸‹é”™è¯¯ 12/usr/share/nginx/html # touch new.txttouch: new.txt: Read-only file system æŸ¥çœ‹æ•°æ®å·çš„å…·ä½“ä¿¡æ¯åœ¨ä¸»æœºé‡Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯ä»¥æŸ¥çœ‹ web å®¹å™¨çš„ä¿¡æ¯ 1$ docker inspect web æŒ‚è½½ä¸»æœºç›®å½• çš„é…ç½®ä¿¡æ¯åœ¨ â€œMountsâ€ Key ä¸‹é¢ 12345678910&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/src/webapp&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125;], æŒ‚è½½ä¸€ä¸ªæœ¬åœ°ä¸»æœºæ–‡ä»¶ä½œä¸ºæ•°æ®å·--mount æ ‡è®°ä¹Ÿå¯ä»¥ä»ä¸»æœºæŒ‚è½½å•ä¸ªæ–‡ä»¶åˆ°å®¹å™¨ä¸­ 123456789$ docker run --rm -it \\ # -v $HOME/.bash_history:/root/.bash_history \\ --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history \\ ubuntu:18.04 \\ bashroot@2affd44b4667:/# history1 ls2 diskutil list è¿™æ ·å°±å¯ä»¥è®°å½•åœ¨å®¹å™¨è¾“å…¥è¿‡çš„å‘½ä»¤äº†ã€‚","tags":[{"name":"docker","slug":"docker","permalink":"https://stu-yue.github.io/tags/docker/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"tools","slug":"tools","permalink":"https://stu-yue.github.io/categories/tools/"},{"name":"docker","slug":"tools/docker","permalink":"https://stu-yue.github.io/categories/tools/docker/"}]},{"title":"Memo | Usage","date":"2023-10-04T07:56:53.000Z","path":"jottings/tools/docker/memo_usage/","text":"0 Dockerå‘½ä»¤ç®€ä»‹ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485Usage: docker [OPTIONS] COMMANDA self-sufficient runtime for containersCommon Commands: run Create and run a new container from an image exec Execute a command in a running container ps List containers build Build an image from a Dockerfile pull Download an image from a registry push Upload an image to a registry images List images login Log in to a registry logout Log out from a registry search Search Docker Hub for images version Show the Docker version information info Display system-wide informationManagement Commands: builder Manage builds buildx* Docker Buildx checkpoint Manage checkpoints compose* Docker Compose container Manage containers context Manage contexts image Manage images manifest Manage Docker image manifests and manifest lists network Manage networks plugin Manage plugins system Manage Docker trust Manage trust on Docker images volume Manage volumesSwarm Commands: swarm Manage SwarmCommands: attach Attach local standard input, output, and error streams to a running container commit Create a new image from a container&#x27;s changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes to files or directories on a container&#x27;s filesystem events Get real time events from the server export Export a container&#x27;s filesystem as a tar archive history Show the history of an image import Import the contents from a tarball to create a filesystem image inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images save Save one or more images to a tar archive (streamed to STDOUT by default) start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers wait Block until one or more containers stop, then print their exit codesGlobal Options: --config string Location of client config files (default &quot;/home/wangy/.docker&quot;) -c, --context string Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with &quot;docker context use&quot;) -D, --debug Enable debug mode -H, --host list Daemon socket to connect to -l, --log-level string Set the logging level (&quot;debug&quot;, &quot;info&quot;, &quot;warn&quot;, &quot;error&quot;, &quot;fatal&quot;) (default &quot;info&quot;) --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default &quot;/home/wangy/.docker/ca.pem&quot;) --tlscert string Path to TLS certificate file (default &quot;/home/wangy/.docker/cert.pem&quot;) --tlskey string Path to TLS key file (default &quot;/home/wangy/.docker/key.pem&quot;) --tlsverify Use TLS and verify the remote -v, --version Print version information and quitRun &#x27;docker COMMAND --help&#x27; for more information on a command. 1 è·å–é•œåƒä¹‹å‰æåˆ°è¿‡ï¼ŒDocker Hub ä¸Šæœ‰å¤§é‡çš„é«˜è´¨é‡çš„é•œåƒå¯ä»¥ç”¨ï¼Œè¿™é‡Œæˆ‘ä»¬å°±è¯´ä¸€ä¸‹æ€ä¹ˆè·å–è¿™äº›é•œåƒã€‚ ä» Docker é•œåƒä»“åº“è·å–é•œåƒçš„å‘½ä»¤æ˜¯ docker pullã€‚å…¶å‘½ä»¤æ ¼å¼ä¸ºï¼š 1$ docker pull [é€‰é¡¹] [Docker Registry åœ°å€[:ç«¯å£å·]/]ä»“åº“å[:æ ‡ç­¾] å…·ä½“çš„é€‰é¡¹å¯ä»¥é€šè¿‡ docker pull --help å‘½ä»¤çœ‹åˆ°ï¼Œè¿™é‡Œæˆ‘ä»¬è¯´ä¸€ä¸‹é•œåƒåç§°çš„æ ¼å¼ã€‚ Docker é•œåƒä»“åº“åœ°å€ï¼šåœ°å€çš„æ ¼å¼ä¸€èˆ¬æ˜¯ &lt;åŸŸå/IP&gt;[:ç«¯å£å·]ã€‚é»˜è®¤åœ°å€æ˜¯ Docker Hub(docker.io)ã€‚ ä»“åº“åï¼šå¦‚ä¹‹å‰æ‰€è¯´ï¼Œè¿™é‡Œçš„ä»“åº“åæ˜¯ä¸¤æ®µå¼åç§°ï¼Œå³ &lt;ç”¨æˆ·å&gt;/&lt;è½¯ä»¶å&gt;ã€‚å¯¹äº Docker Hubï¼Œå¦‚æœä¸ç»™å‡ºç”¨æˆ·åï¼Œåˆ™é»˜è®¤ä¸º libraryï¼Œä¹Ÿå°±æ˜¯å®˜æ–¹é•œåƒã€‚ æ¯”å¦‚ï¼š 12345678$ docker pull ubuntu:18.0418.04: Pulling from library/ubuntu92dc2a97ff99: Pull completebe13a9d27eb8: Pull completec8299583700a: Pull completeDigest: sha256:4bc3ae6596938cb0d9e5ac51a1152ec9dcac2a1c50829c74abd9c4361e321b26Status: Downloaded newer image for ubuntu:18.04docker.io/library/ubuntu:18.04 ä¸Šé¢çš„å‘½ä»¤ä¸­æ²¡æœ‰ç»™å‡º Docker é•œåƒä»“åº“åœ°å€ï¼Œå› æ­¤å°†ä¼šä» Docker Hub ï¼ˆdocker.ioï¼‰è·å–é•œåƒã€‚è€Œé•œåƒåç§°æ˜¯ ubuntu:18.04ï¼Œå› æ­¤å°†ä¼šè·å–å®˜æ–¹é•œåƒ library/ubuntu ä»“åº“ä¸­æ ‡ç­¾ä¸º 18.04 çš„é•œåƒã€‚docker pull **å‘½ä»¤çš„è¾“å‡ºç»“æœæœ€åä¸€è¡Œç»™å‡ºäº†é•œåƒçš„å®Œæ•´åç§°ï¼Œå³ï¼š docker.io/library/ubuntu:18.04**ã€‚ ä»ä¸‹è½½è¿‡ç¨‹ä¸­å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ä¹‹å‰æåŠçš„åˆ†å±‚å­˜å‚¨çš„æ¦‚å¿µï¼Œé•œåƒæ˜¯ç”±å¤šå±‚å­˜å‚¨æ‰€æ„æˆã€‚ä¸‹è½½ä¹Ÿæ˜¯ä¸€å±‚å±‚çš„å»ä¸‹è½½ï¼Œå¹¶éå•ä¸€æ–‡ä»¶ã€‚ä¸‹è½½è¿‡ç¨‹ä¸­ç»™å‡ºäº†æ¯ä¸€å±‚çš„ ID çš„å‰ 12 ä½ã€‚å¹¶ä¸”ä¸‹è½½ç»“æŸåï¼Œç»™å‡ºè¯¥é•œåƒå®Œæ•´çš„ sha256 çš„æ‘˜è¦ï¼Œä»¥ç¡®ä¿ä¸‹è½½ä¸€è‡´æ€§ã€‚ åœ¨ä½¿ç”¨ä¸Šé¢å‘½ä»¤çš„æ—¶å€™ï¼Œä½ å¯èƒ½ä¼šå‘ç°ï¼Œä½ æ‰€çœ‹åˆ°çš„å±‚ ID ä»¥åŠ sha256 çš„æ‘˜è¦å’Œè¿™é‡Œçš„ä¸ä¸€æ ·ã€‚è¿™æ˜¯å› ä¸ºå®˜æ–¹é•œåƒæ˜¯ä¸€ç›´åœ¨ç»´æŠ¤çš„ï¼Œæœ‰ä»»ä½•æ–°çš„ bugï¼Œæˆ–è€…ç‰ˆæœ¬æ›´æ–°ï¼Œéƒ½ä¼šè¿›è¡Œä¿®å¤å†ä»¥åŸæ¥çš„æ ‡ç­¾å‘å¸ƒï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ä»»ä½•ä½¿ç”¨è¿™ä¸ªæ ‡ç­¾çš„ç”¨æˆ·å¯ä»¥è·å¾—æ›´å®‰å…¨ã€æ›´ç¨³å®šçš„é•œåƒã€‚ å¦‚æœä» Docker Hub ä¸‹è½½é•œåƒéå¸¸ç¼“æ…¢ï¼Œå¯ä»¥å‚ç…§ é•œåƒåŠ é€Ÿå™¨ ä¸€èŠ‚é…ç½®åŠ é€Ÿå™¨ã€‚ è¿è¡Œæœ‰äº†é•œåƒåï¼Œæˆ‘ä»¬å°±èƒ½å¤Ÿä»¥è¿™ä¸ªé•œåƒä¸ºåŸºç¡€å¯åŠ¨å¹¶è¿è¡Œä¸€ä¸ªå®¹å™¨ã€‚ä»¥ä¸Šé¢çš„ ubuntu:18.04 ä¸ºä¾‹ï¼Œå¦‚æœæˆ‘ä»¬æ‰“ç®—å¯åŠ¨é‡Œé¢çš„ bash å¹¶ä¸”è¿›è¡Œäº¤äº’å¼æ“ä½œçš„è¯ï¼Œå¯ä»¥æ‰§è¡Œä¸‹é¢çš„å‘½ä»¤ã€‚ å¤åˆ¶ 123456789101112131415$ docker run -it --rm ubuntu:18.04 bashroot@e7009c6ce357:/# cat /etc/os-releaseNAME=&quot;Ubuntu&quot;VERSION=&quot;18.04.1 LTS (Bionic Beaver)&quot;ID=ubuntuID_LIKE=debianPRETTY_NAME=&quot;Ubuntu 18.04.1 LTS&quot;VERSION_ID=&quot;18.04&quot;HOME_URL=&quot;https://www.ubuntu.com/&quot;SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;VERSION_CODENAME=bionicUBUNTU_CODENAME=bionic docker run å°±æ˜¯è¿è¡Œå®¹å™¨çš„å‘½ä»¤ï¼Œå…·ä½“æ ¼å¼æˆ‘ä»¬ä¼šåœ¨ å®¹å™¨ ä¸€èŠ‚è¿›è¡Œè¯¦ç»†è®²è§£ï¼Œæˆ‘ä»¬è¿™é‡Œç®€è¦çš„è¯´æ˜ä¸€ä¸‹ä¸Šé¢ç”¨åˆ°çš„å‚æ•°ã€‚ -itï¼šè¿™æ˜¯ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªæ˜¯ -iï¼šäº¤äº’å¼æ“ä½œï¼Œä¸€ä¸ªæ˜¯ -t ç»ˆç«¯ã€‚æˆ‘ä»¬è¿™é‡Œæ‰“ç®—è¿›å…¥ bash æ‰§è¡Œä¸€äº›å‘½ä»¤å¹¶æŸ¥çœ‹è¿”å›ç»“æœï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦äº¤äº’å¼ç»ˆç«¯ã€‚ --rmï¼šè¿™ä¸ªå‚æ•°æ˜¯è¯´å®¹å™¨é€€å‡ºåéšä¹‹å°†å…¶åˆ é™¤ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä¸ºäº†æ’éšœéœ€æ±‚ï¼Œé€€å‡ºçš„å®¹å™¨å¹¶ä¸ä¼šç«‹å³åˆ é™¤ï¼Œé™¤éæ‰‹åŠ¨ docker rmã€‚æˆ‘ä»¬è¿™é‡Œåªæ˜¯éšä¾¿æ‰§è¡Œä¸ªå‘½ä»¤ï¼Œçœ‹çœ‹ç»“æœï¼Œä¸éœ€è¦æ’éšœå’Œä¿ç•™ç»“æœï¼Œå› æ­¤ä½¿ç”¨ --rm å¯ä»¥é¿å…æµªè´¹ç©ºé—´ã€‚ ubuntu:18.04ï¼šè¿™æ˜¯æŒ‡ç”¨ ubuntu:18.04 é•œåƒä¸ºåŸºç¡€æ¥å¯åŠ¨å®¹å™¨ã€‚ bashï¼šæ”¾åœ¨é•œåƒååçš„æ˜¯ å‘½ä»¤ï¼Œè¿™é‡Œæˆ‘ä»¬å¸Œæœ›æœ‰ä¸ªäº¤äº’å¼ Shellï¼Œå› æ­¤ç”¨çš„æ˜¯ bashã€‚ è¿›å…¥å®¹å™¨åï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ Shell ä¸‹æ“ä½œï¼Œæ‰§è¡Œä»»ä½•æ‰€éœ€çš„å‘½ä»¤ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬æ‰§è¡Œäº† cat /etc/os-releaseï¼Œè¿™æ˜¯ Linux å¸¸ç”¨çš„æŸ¥çœ‹å½“å‰ç³»ç»Ÿç‰ˆæœ¬çš„å‘½ä»¤ï¼Œä»è¿”å›çš„ç»“æœå¯ä»¥çœ‹åˆ°å®¹å™¨å†…æ˜¯ Ubuntu 18.04.1 LTS ç³»ç»Ÿã€‚ æœ€åæˆ‘ä»¬é€šè¿‡ exit é€€å‡ºäº†è¿™ä¸ªå®¹å™¨ã€‚ 2 åˆ—å‡ºé•œåƒè¦æƒ³åˆ—å‡ºå·²ç»ä¸‹è½½ä¸‹æ¥çš„é•œåƒï¼Œå¯ä»¥ä½¿ç”¨ docker image ls å‘½ä»¤ã€‚ 12345678$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEredis latest 5f515359c7f8 5 days ago 183 MBnginx latest 05a60462f8ba 5 days ago 181 MBmongo 3.2 fe9198c04d62 5 days ago 342 MB&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MBubuntu 18.04 329ed837d508 3 days ago 63.3MBubuntu bionic 329ed837d508 3 days ago 63.3MB åˆ—è¡¨åŒ…å«äº† ä»“åº“åã€æ ‡ç­¾ã€é•œåƒ IDã€åˆ›å»ºæ—¶é—´ ä»¥åŠ æ‰€å ç”¨çš„ç©ºé—´ã€‚ å…¶ä¸­ä»“åº“åã€æ ‡ç­¾åœ¨ä¹‹å‰çš„åŸºç¡€æ¦‚å¿µç« èŠ‚å·²ç»ä»‹ç»è¿‡äº†ã€‚é•œåƒ ID åˆ™æ˜¯é•œåƒçš„å”¯ä¸€æ ‡è¯†ï¼Œä¸€ä¸ªé•œåƒå¯ä»¥å¯¹åº”å¤šä¸ª æ ‡ç­¾ã€‚å› æ­¤ï¼Œåœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° ubuntu:18.04 å’Œ ubuntu:bionic æ‹¥æœ‰ç›¸åŒçš„ IDï¼Œå› ä¸ºå®ƒä»¬å¯¹åº”çš„æ˜¯åŒä¸€ä¸ªé•œåƒã€‚ é•œåƒä½“ç§¯å¦‚æœä»”ç»†è§‚å¯Ÿï¼Œä¼šæ³¨æ„åˆ°ï¼Œè¿™é‡Œæ ‡è¯†çš„æ‰€å ç”¨ç©ºé—´å’Œåœ¨ Docker Hub ä¸Šçœ‹åˆ°çš„é•œåƒå¤§å°ä¸åŒã€‚æ¯”å¦‚ï¼Œubuntu:18.04 é•œåƒå¤§å°ï¼Œåœ¨è¿™é‡Œæ˜¯ 63.3MBï¼Œä½†æ˜¯åœ¨ Docker Hub æ˜¾ç¤ºçš„å´æ˜¯ 25.47 MBã€‚è¿™æ˜¯å› ä¸º Docker Hub ä¸­æ˜¾ç¤ºçš„ä½“ç§¯æ˜¯å‹ç¼©åçš„ä½“ç§¯ã€‚åœ¨é•œåƒä¸‹è½½å’Œä¸Šä¼ è¿‡ç¨‹ä¸­é•œåƒæ˜¯ä¿æŒç€å‹ç¼©çŠ¶æ€çš„ï¼Œå› æ­¤ Docker Hub æ‰€æ˜¾ç¤ºçš„å¤§å°æ˜¯ç½‘ç»œä¼ è¾“ä¸­æ›´å…³å¿ƒçš„æµé‡å¤§å°ã€‚è€Œ docker image ls æ˜¾ç¤ºçš„æ˜¯é•œåƒä¸‹è½½åˆ°æœ¬åœ°åï¼Œå±•å¼€çš„å¤§å°ï¼Œå‡†ç¡®è¯´ï¼Œæ˜¯å±•å¼€åçš„å„å±‚æ‰€å ç©ºé—´çš„æ€»å’Œï¼Œå› ä¸ºé•œåƒåˆ°æœ¬åœ°åï¼ŒæŸ¥çœ‹ç©ºé—´çš„æ—¶å€™ï¼Œæ›´å…³å¿ƒçš„æ˜¯æœ¬åœ°ç£ç›˜ç©ºé—´å ç”¨çš„å¤§å°ã€‚ å¦å¤–ä¸€ä¸ªéœ€è¦æ³¨æ„çš„é—®é¢˜æ˜¯ï¼Œ**docker image ls åˆ—è¡¨ä¸­çš„é•œåƒä½“ç§¯æ€»å’Œå¹¶éæ˜¯æ‰€æœ‰é•œåƒå®é™…ç¡¬ç›˜æ¶ˆè€—**ã€‚ç”±äº Docker é•œåƒæ˜¯å¤šå±‚å­˜å‚¨ç»“æ„ï¼Œå¹¶ä¸”å¯ä»¥ç»§æ‰¿ã€å¤ç”¨ï¼Œå› æ­¤ä¸åŒé•œåƒå¯èƒ½ä¼šå› ä¸ºä½¿ç”¨ç›¸åŒçš„åŸºç¡€é•œåƒï¼Œä»è€Œæ‹¥æœ‰å…±åŒçš„å±‚ã€‚ç”±äº Docker ä½¿ç”¨ Union FSï¼Œç›¸åŒçš„å±‚åªéœ€è¦ä¿å­˜ä¸€ä»½å³å¯ï¼Œå› æ­¤å®é™…é•œåƒç¡¬ç›˜å ç”¨ç©ºé—´å¾ˆå¯èƒ½è¦æ¯”è¿™ä¸ªåˆ—è¡¨é•œåƒå¤§å°çš„æ€»å’Œè¦å°çš„å¤šã€‚ ä½ å¯ä»¥é€šè¿‡ docker system df å‘½ä»¤æ¥ä¾¿æ·çš„æŸ¥çœ‹é•œåƒã€å®¹å™¨ã€æ•°æ®å·æ‰€å ç”¨çš„ç©ºé—´ã€‚ 1234567$ docker system dfTYPE TOTAL ACTIVE SIZE RECLAIMABLEImages 24 0 1.992GB 1.992GB (100%)Containers 1 0 62.82MB 62.82MB (100%)Local Volumes 9 0 652.2MB 652.2MB (100%)Build Cache 0B 0B è™šæ‚¬é•œåƒä¸Šé¢çš„é•œåƒåˆ—è¡¨ä¸­ï¼Œè¿˜å¯ä»¥çœ‹åˆ°ä¸€ä¸ªç‰¹æ®Šçš„é•œåƒï¼Œè¿™ä¸ªé•œåƒæ—¢æ²¡æœ‰ä»“åº“åï¼Œä¹Ÿæ²¡æœ‰æ ‡ç­¾ï¼Œå‡ä¸º &lt;none&gt;ã€‚ï¼š 1&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MB è¿™ä¸ªé•œåƒåŸæœ¬æ˜¯æœ‰é•œåƒåå’Œæ ‡ç­¾çš„ï¼ŒåŸæ¥ä¸º mongo:3.2ï¼Œéšç€å®˜æ–¹é•œåƒç»´æŠ¤ï¼Œå‘å¸ƒäº†æ–°ç‰ˆæœ¬åï¼Œé‡æ–° docker pull mongo:3.2 æ—¶ï¼Œmongo:3.2 è¿™ä¸ªé•œåƒåè¢«è½¬ç§»åˆ°äº†æ–°ä¸‹è½½çš„é•œåƒèº«ä¸Šï¼Œè€Œæ—§çš„é•œåƒä¸Šçš„è¿™ä¸ªåç§°åˆ™è¢«å–æ¶ˆï¼Œä»è€Œæˆä¸ºäº† &lt;none&gt;ã€‚é™¤äº† docker pull å¯èƒ½å¯¼è‡´è¿™ç§æƒ…å†µï¼Œ**docker build ä¹ŸåŒæ ·å¯ä»¥å¯¼è‡´è¿™ç§ç°è±¡ã€‚ç”±äºæ–°æ—§é•œåƒåŒåï¼Œæ—§é•œåƒåç§°è¢«å–æ¶ˆï¼Œä»è€Œå‡ºç°ä»“åº“åã€æ ‡ç­¾å‡ä¸º &lt;none&gt; çš„é•œåƒ**ã€‚è¿™ç±»æ— æ ‡ç­¾é•œåƒä¹Ÿè¢«ç§°ä¸º è™šæ‚¬é•œåƒ(dangling image) ï¼Œå¯ä»¥ç”¨ä¸‹é¢çš„å‘½ä»¤ä¸“é—¨æ˜¾ç¤ºè¿™ç±»é•œåƒï¼š 123$ docker image ls -f dangling=trueREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MB ä¸€èˆ¬æ¥è¯´ï¼Œè™šæ‚¬é•œåƒå·²ç»å¤±å»äº†å­˜åœ¨çš„ä»·å€¼ï¼Œæ˜¯å¯ä»¥éšæ„åˆ é™¤çš„ï¼Œå¯ä»¥ç”¨ä¸‹é¢çš„å‘½ä»¤åˆ é™¤ã€‚ 1$ docker image prune ä¸­é—´å±‚é•œåƒä¸ºäº†åŠ é€Ÿé•œåƒæ„å»ºã€é‡å¤åˆ©ç”¨èµ„æºï¼ŒDocker ä¼šåˆ©ç”¨ ä¸­é—´å±‚é•œåƒã€‚æ‰€ä»¥åœ¨ä½¿ç”¨ä¸€æ®µæ—¶é—´åï¼Œå¯èƒ½ä¼šçœ‹åˆ°ä¸€äº›ä¾èµ–çš„ä¸­é—´å±‚é•œåƒã€‚é»˜è®¤çš„ docker image ls åˆ—è¡¨ä¸­åªä¼šæ˜¾ç¤ºé¡¶å±‚é•œåƒï¼Œå¦‚æœå¸Œæœ›æ˜¾ç¤ºåŒ…æ‹¬ä¸­é—´å±‚é•œåƒåœ¨å†…çš„æ‰€æœ‰é•œåƒçš„è¯ï¼Œéœ€è¦åŠ  -a å‚æ•°ã€‚ å¤åˆ¶ 1$ docker image ls -a è¿™æ ·ä¼šçœ‹åˆ°å¾ˆå¤šæ— æ ‡ç­¾çš„é•œåƒï¼Œä¸ä¹‹å‰çš„è™šæ‚¬é•œåƒä¸åŒï¼Œè¿™äº›æ— æ ‡ç­¾çš„é•œåƒå¾ˆå¤šéƒ½æ˜¯ä¸­é—´å±‚é•œåƒï¼Œæ˜¯å…¶å®ƒé•œåƒæ‰€ä¾èµ–çš„é•œåƒã€‚è¿™äº›æ— æ ‡ç­¾é•œåƒä¸åº”è¯¥åˆ é™¤ï¼Œå¦åˆ™ä¼šå¯¼è‡´ä¸Šå±‚é•œåƒå› ä¸ºä¾èµ–ä¸¢å¤±è€Œå‡ºé”™ã€‚å®é™…ä¸Šï¼Œè¿™äº›é•œåƒä¹Ÿæ²¡å¿…è¦åˆ é™¤ï¼Œå› ä¸ºä¹‹å‰è¯´è¿‡ï¼Œç›¸åŒçš„å±‚åªä¼šå­˜ä¸€éï¼Œè€Œè¿™äº›é•œåƒæ˜¯åˆ«çš„é•œåƒçš„ä¾èµ–ï¼Œå› æ­¤å¹¶ä¸ä¼šå› ä¸ºå®ƒä»¬è¢«åˆ—å‡ºæ¥è€Œå¤šå­˜äº†ä¸€ä»½ï¼Œæ— è®ºå¦‚ä½•ä½ ä¹Ÿä¼šéœ€è¦å®ƒä»¬ã€‚åªè¦åˆ é™¤é‚£äº›ä¾èµ–å®ƒä»¬çš„é•œåƒåï¼Œè¿™äº›ä¾èµ–çš„ä¸­é—´å±‚é•œåƒä¹Ÿä¼šè¢«è¿å¸¦åˆ é™¤ã€‚ åˆ—å‡ºéƒ¨åˆ†é•œåƒä¸åŠ ä»»ä½•å‚æ•°çš„æƒ…å†µä¸‹ï¼Œdocker image ls ä¼šåˆ—å‡ºæ‰€æœ‰é¡¶å±‚é•œåƒï¼Œä½†æ˜¯æœ‰æ—¶å€™æˆ‘ä»¬åªå¸Œæœ›åˆ—å‡ºéƒ¨åˆ†é•œåƒã€‚docker image ls æœ‰å¥½å‡ ä¸ªå‚æ•°å¯ä»¥å¸®åŠ©åšåˆ°è¿™ä¸ªäº‹æƒ…ã€‚ æ ¹æ®ä»“åº“ååˆ—å‡ºé•œåƒ 1234$ docker image ls ubuntuREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 18.04 329ed837d508 3 days ago 63.3MBubuntu bionic 329ed837d508 3 days ago 63.3MB åˆ—å‡ºç‰¹å®šçš„æŸä¸ªé•œåƒï¼Œä¹Ÿå°±æ˜¯è¯´æŒ‡å®šä»“åº“åå’Œæ ‡ç­¾ 123$ docker image ls ubuntu:18.04REPOSITORY TAG IMAGE ID CREATED SIZEubuntu 18.04 329ed837d508 3 days ago 63.3MB é™¤æ­¤ä»¥å¤–ï¼Œ**docker image ls è¿˜æ”¯æŒå¼ºå¤§çš„è¿‡æ»¤å™¨å‚æ•° --filterï¼Œæˆ–è€…ç®€å†™ -f**ã€‚ä¹‹å‰æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†ä½¿ç”¨è¿‡æ»¤å™¨æ¥åˆ—å‡ºè™šæ‚¬é•œåƒçš„ç”¨æ³•ï¼Œå®ƒè¿˜æœ‰æ›´å¤šçš„ç”¨æ³•ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬å¸Œæœ›çœ‹åˆ°åœ¨ mongo:3.2 ä¹‹åå»ºç«‹çš„é•œåƒï¼Œå¯ä»¥ç”¨ä¸‹é¢çš„å‘½ä»¤ï¼š 1234$ docker image ls -f since=mongo:3.2REPOSITORY TAG IMAGE ID CREATED SIZEredis latest 5f515359c7f8 5 days ago 183 MBnginx latest 05a60462f8ba 5 days ago 181 MB æƒ³æŸ¥çœ‹æŸä¸ªä½ç½®ä¹‹å‰çš„é•œåƒä¹Ÿå¯ä»¥ï¼Œåªéœ€è¦æŠŠ since æ¢æˆ before å³å¯ã€‚ æ­¤å¤–ï¼Œå¦‚æœé•œåƒæ„å»ºæ—¶ï¼Œå®šä¹‰äº† LABELï¼Œè¿˜å¯ä»¥é€šè¿‡ LABEL æ¥è¿‡æ»¤ã€‚ 12$ docker image ls -f label=com.example.version=0.1... ä»¥ç‰¹å®šæ ¼å¼æ˜¾ç¤ºé»˜è®¤æƒ…å†µä¸‹ï¼Œdocker image ls ä¼šè¾“å‡ºä¸€ä¸ªå®Œæ•´çš„è¡¨æ ¼ï¼Œä½†æ˜¯æˆ‘ä»¬å¹¶éæ‰€æœ‰æ—¶å€™éƒ½ä¼šéœ€è¦è¿™äº›å†…å®¹ã€‚æ¯”å¦‚ï¼Œåˆšæ‰åˆ é™¤è™šæ‚¬é•œåƒçš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦åˆ©ç”¨ docker image ls æŠŠæ‰€æœ‰çš„è™šæ‚¬é•œåƒçš„ ID åˆ—å‡ºæ¥ï¼Œç„¶åæ‰å¯ä»¥äº¤ç»™ docker image rm å‘½ä»¤ä½œä¸ºå‚æ•°æ¥åˆ é™¤æŒ‡å®šçš„è¿™äº›é•œåƒï¼Œè¿™ä¸ªæ—¶å€™å°±ç”¨åˆ°äº† -q å‚æ•°ã€‚ 1234567$ docker image ls -q5f515359c7f805a60462f8bafe9198c04d6200285df0df87329ed837d508329ed837d508 --filter é…åˆ -q äº§ç”Ÿå‡ºæŒ‡å®šèŒƒå›´çš„ ID åˆ—è¡¨ï¼Œç„¶åé€ç»™å¦ä¸€ä¸ª docker å‘½ä»¤ä½œä¸ºå‚æ•°ï¼Œä»è€Œé’ˆå¯¹è¿™ç»„å®ä½“æˆæ‰¹çš„è¿›è¡ŒæŸç§æ“ä½œçš„åšæ³•åœ¨ Docker å‘½ä»¤è¡Œä½¿ç”¨è¿‡ç¨‹ä¸­éå¸¸å¸¸è§ï¼Œä¸ä»…ä»…æ˜¯é•œåƒï¼Œå°†æ¥æˆ‘ä»¬ä¼šåœ¨å„ä¸ªå‘½ä»¤ä¸­çœ‹åˆ°è¿™ç±»æ­é…ä»¥å®Œæˆå¾ˆå¼ºå¤§çš„åŠŸèƒ½ã€‚å› æ­¤æ¯æ¬¡åœ¨æ–‡æ¡£çœ‹åˆ°è¿‡æ»¤å™¨åï¼Œå¯ä»¥å¤šæ³¨æ„ä¸€ä¸‹å®ƒä»¬çš„ç”¨æ³•ã€‚ å¦å¤–ä¸€äº›æ—¶å€™ï¼Œæˆ‘ä»¬å¯èƒ½åªæ˜¯å¯¹è¡¨æ ¼çš„ç»“æ„ä¸æ»¡æ„ï¼Œå¸Œæœ›è‡ªå·±ç»„ç»‡åˆ—ï¼›æˆ–è€…ä¸å¸Œæœ›æœ‰æ ‡é¢˜ï¼Œè¿™æ ·æ–¹ä¾¿å…¶å®ƒç¨‹åºè§£æç»“æœç­‰ï¼Œè¿™å°±ç”¨åˆ°äº† Go çš„æ¨¡æ¿è¯­æ³•ã€‚ æ¯”å¦‚ï¼Œä¸‹é¢çš„å‘½ä»¤ä¼šç›´æ¥åˆ—å‡ºé•œåƒç»“æœï¼Œå¹¶ä¸”åªåŒ…å«é•œåƒIDå’Œä»“åº“åï¼š 1234567$ docker image ls --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;&quot;5f515359c7f8: redis05a60462f8ba: nginxfe9198c04d62: mongo00285df0df87: &lt;none&gt;329ed837d508: ubuntu329ed837d508: ubuntu æˆ–è€…æ‰“ç®—ä»¥è¡¨æ ¼ç­‰è·æ˜¾ç¤ºï¼Œå¹¶ä¸”æœ‰æ ‡é¢˜è¡Œï¼Œå’Œé»˜è®¤ä¸€æ ·ï¼Œä¸è¿‡è‡ªå·±å®šä¹‰åˆ—ï¼š 12345678$ docker image ls --format &quot;table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Repository&#125;&#125;\\t&#123;&#123;.Tag&#125;&#125;&quot;IMAGE ID REPOSITORY TAG5f515359c7f8 redis latest05a60462f8ba nginx latestfe9198c04d62 mongo 3.200285df0df87 &lt;none&gt; &lt;none&gt;329ed837d508 ubuntu 18.04329ed837d508 ubuntu bionic 3 åˆ é™¤æœ¬åœ°é•œåƒå¦‚æœè¦åˆ é™¤æœ¬åœ°çš„é•œåƒï¼Œå¯ä»¥ä½¿ç”¨ docker image rm å‘½ä»¤ï¼Œå…¶æ ¼å¼ä¸ºï¼š 1$ docker image rm [é€‰é¡¹] &lt;é•œåƒ1&gt; [&lt;é•œåƒ2&gt; ...] ç”¨ IDã€é•œåƒåã€æ‘˜è¦åˆ é™¤é•œåƒå…¶ä¸­ï¼Œ&lt;é•œåƒ&gt; å¯ä»¥æ˜¯ é•œåƒçŸ­ IDã€é•œåƒé•¿ IDã€é•œåƒå æˆ–è€… é•œåƒæ‘˜è¦ã€‚ æ¯”å¦‚æˆ‘ä»¬æœ‰è¿™ä¹ˆä¸€äº›é•œåƒï¼š 123456$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 0584b3d2cf6d 3 weeks ago 196.5 MBredis alpine 501ad78535f0 3 weeks ago 21.03 MBdocker latest cf693ec9b5c7 3 weeks ago 105.1 MBnginx latest e43d811ce2f4 5 weeks ago 181.5 MB æˆ‘ä»¬å¯ä»¥ç”¨é•œåƒçš„å®Œæ•´ IDï¼Œä¹Ÿç§°ä¸º é•¿ IDï¼Œæ¥åˆ é™¤é•œåƒã€‚ä½¿ç”¨è„šæœ¬çš„æ—¶å€™å¯èƒ½ä¼šç”¨é•¿ IDï¼Œä½†æ˜¯äººå·¥è¾“å…¥å°±å¤ªç´¯äº†ï¼Œæ‰€ä»¥æ›´å¤šçš„æ—¶å€™æ˜¯ç”¨ çŸ­ ID æ¥åˆ é™¤é•œåƒã€‚docker image ls é»˜è®¤åˆ—å‡ºçš„å°±å·²ç»æ˜¯çŸ­ ID äº†ï¼Œä¸€èˆ¬å–å‰3ä¸ªå­—ç¬¦ä»¥ä¸Šï¼Œåªè¦è¶³å¤ŸåŒºåˆ†äºåˆ«çš„é•œåƒå°±å¯ä»¥äº†ã€‚ æ¯”å¦‚è¿™é‡Œï¼Œå¦‚æœæˆ‘ä»¬è¦åˆ é™¤ redis:alpine é•œåƒï¼Œå¯ä»¥æ‰§è¡Œï¼š 123456789$ docker image rm 501Untagged: redis:alpineUntagged: redis@sha256:f1ed3708f538b537eb9c2a7dd50dc90a706f7debd7e1196c9264edeea521a86dDeleted: sha256:501ad78535f015d88872e13fa87a828425117e3d28075d0c117932b05bf189b7Deleted: sha256:96167737e29ca8e9d74982ef2a0dda76ed7b430da55e321c071f0dbff8c2899bDeleted: sha256:32770d1dcf835f192cafd6b9263b7b597a1778a403a109e2cc2ee866f74adf23Deleted: sha256:127227698ad74a5846ff5153475e03439d96d4b1c7f2a449c7a826ef74a2d2faDeleted: sha256:1333ecc582459bac54e1437335c0816bc17634e131ea0cc48daa27d32c75eab3Deleted: sha256:4fc455b921edf9c4aea207c51ab39b10b06540c8b4825ba57b3feed1668fa7c7 æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨é•œåƒåï¼Œä¹Ÿå°±æ˜¯ &lt;ä»“åº“å&gt;:&lt;æ ‡ç­¾&gt;ï¼Œæ¥åˆ é™¤é•œåƒã€‚ 12345$ docker image rm centosUntagged: centos:latestUntagged: centos@sha256:b2f9d1c0ff5f87a4743104d099a3d561002ac500db1b9bfa02a783a46e0d366cDeleted: sha256:0584b3d2cf6d235ee310cf14b54667d889887b838d3f3d3033acd70fc3c48b8aDeleted: sha256:97ca462ad9eeae25941546209454496e1d66749d53dfa2ee32bf1faabd239d38 å½“ç„¶ï¼Œæ›´ç²¾ç¡®çš„æ˜¯ä½¿ç”¨ é•œåƒæ‘˜è¦ åˆ é™¤é•œåƒã€‚ 123456$ docker image ls --digestsREPOSITORY TAG DIGEST IMAGE ID CREATED SIZEnode slim sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 6e0c4c8e3913 3 weeks ago 214 MB$ docker image rm node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228Untagged: node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 Untagged å’Œ Deletedå¦‚æœè§‚å¯Ÿä¸Šé¢è¿™å‡ ä¸ªå‘½ä»¤çš„è¿è¡Œè¾“å‡ºä¿¡æ¯çš„è¯ï¼Œä½ ä¼šæ³¨æ„åˆ°åˆ é™¤è¡Œä¸ºåˆ†ä¸ºä¸¤ç±»ï¼Œä¸€ç±»æ˜¯ Untaggedï¼Œå¦ä¸€ç±»æ˜¯ Deletedã€‚æˆ‘ä»¬ä¹‹å‰ä»‹ç»è¿‡ï¼Œé•œåƒçš„å”¯ä¸€æ ‡è¯†æ˜¯å…¶ ID å’Œæ‘˜è¦ï¼Œè€Œä¸€ä¸ªé•œåƒå¯ä»¥æœ‰å¤šä¸ªæ ‡ç­¾ã€‚ å› æ­¤å½“æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢å‘½ä»¤åˆ é™¤é•œåƒçš„æ—¶å€™ï¼Œå®é™…ä¸Šæ˜¯åœ¨è¦æ±‚åˆ é™¤æŸä¸ªæ ‡ç­¾çš„é•œåƒã€‚æ‰€ä»¥é¦–å…ˆéœ€è¦åšçš„æ˜¯å°†æ»¡è¶³æˆ‘ä»¬è¦æ±‚çš„æ‰€æœ‰é•œåƒæ ‡ç­¾éƒ½å–æ¶ˆï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çœ‹åˆ°çš„ Untagged çš„ä¿¡æ¯ã€‚å› ä¸ºä¸€ä¸ªé•œåƒå¯ä»¥å¯¹åº”å¤šä¸ªæ ‡ç­¾ï¼Œå› æ­¤å½“æˆ‘ä»¬åˆ é™¤äº†æ‰€æŒ‡å®šçš„æ ‡ç­¾åï¼Œå¯èƒ½è¿˜æœ‰åˆ«çš„æ ‡ç­¾æŒ‡å‘äº†è¿™ä¸ªé•œåƒï¼Œå¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œé‚£ä¹ˆ Delete è¡Œä¸ºå°±ä¸ä¼šå‘ç”Ÿã€‚æ‰€ä»¥å¹¶éæ‰€æœ‰çš„ docker image rm éƒ½ä¼šäº§ç”Ÿåˆ é™¤é•œåƒçš„è¡Œä¸ºï¼Œæœ‰å¯èƒ½ä»…ä»…æ˜¯å–æ¶ˆäº†æŸä¸ªæ ‡ç­¾è€Œå·²ã€‚ å½“è¯¥é•œåƒæ‰€æœ‰çš„æ ‡ç­¾éƒ½è¢«å–æ¶ˆäº†ï¼Œè¯¥é•œåƒå¾ˆå¯èƒ½ä¼šå¤±å»äº†å­˜åœ¨çš„æ„ä¹‰ï¼Œå› æ­¤ä¼šè§¦å‘åˆ é™¤è¡Œä¸ºã€‚é•œåƒæ˜¯å¤šå±‚å­˜å‚¨ç»“æ„ï¼Œå› æ­¤åœ¨åˆ é™¤çš„æ—¶å€™ä¹Ÿæ˜¯ä»ä¸Šå±‚å‘åŸºç¡€å±‚æ–¹å‘ä¾æ¬¡è¿›è¡Œåˆ¤æ–­åˆ é™¤ã€‚é•œåƒçš„å¤šå±‚ç»“æ„è®©é•œåƒå¤ç”¨å˜å¾—éå¸¸å®¹æ˜“ï¼Œå› æ­¤å¾ˆæœ‰å¯èƒ½æŸä¸ªå…¶å®ƒé•œåƒæ­£ä¾èµ–äºå½“å‰é•œåƒçš„æŸä¸€å±‚ã€‚è¿™ç§æƒ…å†µï¼Œä¾æ—§ä¸ä¼šè§¦å‘åˆ é™¤è¯¥å±‚çš„è¡Œä¸ºã€‚ç›´åˆ°æ²¡æœ‰ä»»ä½•å±‚ä¾èµ–å½“å‰å±‚æ—¶ï¼Œæ‰ä¼šçœŸå®çš„åˆ é™¤å½“å‰å±‚ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆï¼Œæœ‰æ—¶å€™ä¼šå¥‡æ€ªï¼Œä¸ºä»€ä¹ˆæ˜æ˜æ²¡æœ‰åˆ«çš„æ ‡ç­¾æŒ‡å‘è¿™ä¸ªé•œåƒï¼Œä½†æ˜¯å®ƒè¿˜æ˜¯å­˜åœ¨çš„åŸå› ï¼Œä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæœ‰æ—¶å€™ä¼šå‘ç°æ‰€åˆ é™¤çš„å±‚æ•°å’Œè‡ªå·± docker pull çœ‹åˆ°çš„å±‚æ•°ä¸ä¸€æ ·çš„åŸå› ã€‚ é™¤äº†é•œåƒä¾èµ–ä»¥å¤–ï¼Œè¿˜éœ€è¦æ³¨æ„çš„æ˜¯å®¹å™¨å¯¹é•œåƒçš„ä¾èµ–ã€‚å¦‚æœæœ‰ç”¨è¿™ä¸ªé•œåƒå¯åŠ¨çš„å®¹å™¨å­˜åœ¨ï¼ˆå³ä½¿å®¹å™¨æ²¡æœ‰è¿è¡Œï¼‰ï¼Œé‚£ä¹ˆåŒæ ·ä¸å¯ä»¥åˆ é™¤è¿™ä¸ªé•œåƒã€‚ä¹‹å‰è®²è¿‡ï¼Œå®¹å™¨æ˜¯ä»¥é•œåƒä¸ºåŸºç¡€ï¼Œå†åŠ ä¸€å±‚å®¹å™¨å­˜å‚¨å±‚ï¼Œç»„æˆè¿™æ ·çš„å¤šå±‚å­˜å‚¨ç»“æ„å»è¿è¡Œçš„ã€‚å› æ­¤è¯¥é•œåƒå¦‚æœè¢«è¿™ä¸ªå®¹å™¨æ‰€ä¾èµ–çš„ï¼Œé‚£ä¹ˆåˆ é™¤å¿…ç„¶ä¼šå¯¼è‡´æ•…éšœã€‚å¦‚æœè¿™äº›å®¹å™¨æ˜¯ä¸éœ€è¦çš„ï¼Œåº”è¯¥å…ˆå°†å®ƒä»¬åˆ é™¤ï¼Œç„¶åå†æ¥åˆ é™¤é•œåƒã€‚ ç”¨ docker image ls å‘½ä»¤æ¥é…åˆåƒå…¶å®ƒå¯ä»¥æ‰¿æ¥å¤šä¸ªå®ä½“çš„å‘½ä»¤ä¸€æ ·ï¼Œå¯ä»¥ä½¿ç”¨ docker image ls -q æ¥é…åˆä½¿ç”¨ docker image rmï¼Œè¿™æ ·å¯ä»¥æˆæ‰¹çš„åˆ é™¤å¸Œæœ›åˆ é™¤çš„é•œåƒã€‚æˆ‘ä»¬åœ¨â€œé•œåƒåˆ—è¡¨â€ç« èŠ‚ä»‹ç»è¿‡å¾ˆå¤šè¿‡æ»¤é•œåƒåˆ—è¡¨çš„æ–¹å¼éƒ½å¯ä»¥æ‹¿è¿‡æ¥ä½¿ç”¨ã€‚ æ¯”å¦‚ï¼Œæˆ‘ä»¬éœ€è¦åˆ é™¤æ‰€æœ‰ä»“åº“åä¸º redis çš„é•œåƒï¼š 1$ docker image rm $(docker image ls -q redis) æˆ–è€…åˆ é™¤æ‰€æœ‰åœ¨ mongo:3.2 ä¹‹å‰çš„é•œåƒï¼š 1$ docker image rm $(docker image ls -q -f before=mongo:3.2) å……åˆ†åˆ©ç”¨ä½ çš„æƒ³è±¡åŠ›å’Œ Linux å‘½ä»¤è¡Œçš„å¼ºå¤§ï¼Œä½ å¯ä»¥å®Œæˆå¾ˆå¤šéå¸¸èµçš„åŠŸèƒ½ã€‚ 4 åˆ©ç”¨ commit ç†è§£é•œåƒæ„æˆ æ³¨æ„ï¼šå¦‚æœæ‚¨æ˜¯åˆå­¦è€…ï¼Œæ‚¨å¯ä»¥æš‚æ—¶è·³è¿‡åé¢çš„å†…å®¹ï¼Œç›´æ¥å­¦ä¹  å®¹å™¨ ä¸€èŠ‚ã€‚ æ³¨æ„ï¼š docker commit å‘½ä»¤é™¤äº†å­¦ä¹ ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€äº›ç‰¹æ®Šçš„åº”ç”¨åœºåˆï¼Œæ¯”å¦‚è¢«å…¥ä¾µåä¿å­˜ç°åœºç­‰ã€‚ä½†æ˜¯ï¼Œä¸è¦ä½¿ç”¨ docker commit å®šåˆ¶é•œåƒï¼Œå®šåˆ¶é•œåƒåº”è¯¥ä½¿ç”¨ Dockerfile æ¥å®Œæˆã€‚å¦‚æœä½ æƒ³è¦å®šåˆ¶é•œåƒè¯·æŸ¥çœ‹ä¸‹ä¸€å°èŠ‚ã€‚ é•œåƒæ˜¯å®¹å™¨çš„åŸºç¡€ï¼Œæ¯æ¬¡æ‰§è¡Œ docker run çš„æ—¶å€™éƒ½ä¼šæŒ‡å®šå“ªä¸ªé•œåƒä½œä¸ºå®¹å™¨è¿è¡Œçš„åŸºç¡€ã€‚åœ¨ä¹‹å‰çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ‰€ä½¿ç”¨çš„éƒ½æ˜¯æ¥è‡ªäº Docker Hub çš„é•œåƒã€‚ç›´æ¥ä½¿ç”¨è¿™äº›é•œåƒæ˜¯å¯ä»¥æ»¡è¶³ä¸€å®šçš„éœ€æ±‚ï¼Œè€Œå½“è¿™äº›é•œåƒæ— æ³•ç›´æ¥æ»¡è¶³éœ€æ±‚æ—¶ï¼Œæˆ‘ä»¬å°±éœ€è¦å®šåˆ¶è¿™äº›é•œåƒã€‚æ¥ä¸‹æ¥çš„å‡ èŠ‚å°±å°†è®²è§£å¦‚ä½•å®šåˆ¶é•œåƒã€‚ å›é¡¾ä¸€ä¸‹ä¹‹å‰æˆ‘ä»¬å­¦åˆ°çš„çŸ¥è¯†ï¼Œé•œåƒæ˜¯å¤šå±‚å­˜å‚¨ï¼Œæ¯ä¸€å±‚æ˜¯åœ¨å‰ä¸€å±‚çš„åŸºç¡€ä¸Šè¿›è¡Œçš„ä¿®æ”¹ï¼›è€Œå®¹å™¨åŒæ ·ä¹Ÿæ˜¯å¤šå±‚å­˜å‚¨ï¼Œæ˜¯åœ¨ä»¥é•œåƒä¸ºåŸºç¡€å±‚ï¼Œåœ¨å…¶åŸºç¡€ä¸ŠåŠ ä¸€å±‚ä½œä¸ºå®¹å™¨è¿è¡Œæ—¶çš„å­˜å‚¨å±‚ã€‚ ç°åœ¨è®©æˆ‘ä»¬ä»¥å®šåˆ¶ä¸€ä¸ª Web æœåŠ¡å™¨ä¸ºä¾‹å­ï¼Œæ¥è®²è§£é•œåƒæ˜¯å¦‚ä½•æ„å»ºçš„ã€‚ 1$ docker run --name webserver -d -p 80:80 nginx è¿™æ¡å‘½ä»¤ä¼šç”¨ nginx é•œåƒå¯åŠ¨ä¸€ä¸ªå®¹å™¨ï¼Œå‘½åä¸º webserverï¼Œå¹¶ä¸”æ˜ å°„äº† 80 ç«¯å£ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥ç”¨æµè§ˆå™¨å»è®¿é—®è¿™ä¸ª nginx æœåŠ¡å™¨ã€‚ å¦‚æœæ˜¯åœ¨æœ¬æœºè¿è¡Œçš„ Dockerï¼Œé‚£ä¹ˆå¯ä»¥ç›´æ¥è®¿é—®ï¼šhttp://localhost ï¼Œå¦‚æœæ˜¯åœ¨è™šæ‹Ÿæœºã€äº‘æœåŠ¡å™¨ä¸Šå®‰è£…çš„ Dockerï¼Œåˆ™éœ€è¦å°† localhost æ¢ä¸ºè™šæ‹Ÿæœºåœ°å€æˆ–è€…å®é™…äº‘æœåŠ¡å™¨åœ°å€ã€‚ ç›´æ¥ç”¨æµè§ˆå™¨è®¿é—®çš„è¯ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°é»˜è®¤çš„ Nginx æ¬¢è¿é¡µé¢ã€‚ ç°åœ¨ï¼Œå‡è®¾æˆ‘ä»¬éå¸¸ä¸å–œæ¬¢è¿™ä¸ªæ¬¢è¿é¡µé¢ï¼Œæˆ‘ä»¬å¸Œæœ›æ”¹æˆæ¬¢è¿ Docker çš„æ–‡å­—ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ docker exec å‘½ä»¤è¿›å…¥å®¹å™¨ï¼Œä¿®æ”¹å…¶å†…å®¹ã€‚ 1234$ docker exec -it webserver bashroot@3729b97e8226:/# echo &#x27;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#x27; &gt; /usr/share/nginx/html/index.htmlroot@3729b97e8226:/# exitexit æˆ‘ä»¬ä»¥äº¤äº’å¼ç»ˆç«¯æ–¹å¼è¿›å…¥ webserver å®¹å™¨ï¼Œå¹¶æ‰§è¡Œäº† bash å‘½ä»¤ï¼Œä¹Ÿå°±æ˜¯è·å¾—ä¸€ä¸ªå¯æ“ä½œçš„ Shellã€‚ ç„¶åï¼Œæˆ‘ä»¬ç”¨ &lt;h1&gt;Hello, Docker!&lt;/h1&gt; è¦†ç›–äº† /usr/share/nginx/html/index.html çš„å†…å®¹ã€‚ ç°åœ¨æˆ‘ä»¬å†åˆ·æ–°æµè§ˆå™¨çš„è¯ï¼Œä¼šå‘ç°å†…å®¹è¢«æ”¹å˜äº†ã€‚ æˆ‘ä»¬ä¿®æ”¹äº†å®¹å™¨çš„æ–‡ä»¶ï¼Œä¹Ÿå°±æ˜¯æ”¹åŠ¨äº†å®¹å™¨çš„å­˜å‚¨å±‚ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ docker diff å‘½ä»¤çœ‹åˆ°å…·ä½“çš„æ”¹åŠ¨ã€‚ 1234567891011121314151617$ docker diff webserverC /rootA /root/.bash_historyC /runC /usrC /usr/shareC /usr/share/nginxC /usr/share/nginx/htmlC /usr/share/nginx/html/index.htmlC /varC /var/cacheC /var/cache/nginxA /var/cache/nginx/client_tempA /var/cache/nginx/fastcgi_tempA /var/cache/nginx/proxy_tempA /var/cache/nginx/scgi_tempA /var/cache/nginx/uwsgi_temp ç°åœ¨æˆ‘ä»¬å®šåˆ¶å¥½äº†å˜åŒ–ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å°†å…¶ä¿å­˜ä¸‹æ¥å½¢æˆé•œåƒã€‚ è¦çŸ¥é“ï¼Œå½“æˆ‘ä»¬è¿è¡Œä¸€ä¸ªå®¹å™¨çš„æ—¶å€™ï¼ˆå¦‚æœä¸ä½¿ç”¨å·çš„è¯ï¼‰ï¼Œæˆ‘ä»¬åšçš„ä»»ä½•æ–‡ä»¶ä¿®æ”¹éƒ½ä¼šè¢«è®°å½•äºå®¹å™¨å­˜å‚¨å±‚é‡Œã€‚è€Œ Docker æä¾›äº†ä¸€ä¸ª docker commit å‘½ä»¤ï¼Œå¯ä»¥å°†å®¹å™¨çš„å­˜å‚¨å±‚ä¿å­˜ä¸‹æ¥æˆä¸ºé•œåƒã€‚æ¢å¥è¯è¯´ï¼Œå°±æ˜¯åœ¨åŸæœ‰é•œåƒçš„åŸºç¡€ä¸Šï¼Œå†å åŠ ä¸Šå®¹å™¨çš„å­˜å‚¨å±‚ï¼Œå¹¶æ„æˆæ–°çš„é•œåƒã€‚ä»¥åæˆ‘ä»¬è¿è¡Œè¿™ä¸ªæ–°é•œåƒçš„æ—¶å€™ï¼Œå°±ä¼šæ‹¥æœ‰åŸæœ‰å®¹å™¨æœ€åçš„æ–‡ä»¶å˜åŒ–ã€‚ docker commit çš„è¯­æ³•æ ¼å¼ä¸ºï¼š 1$ docker commit [é€‰é¡¹] &lt;å®¹å™¨IDæˆ–å®¹å™¨å&gt; [&lt;ä»“åº“å&gt;[:&lt;æ ‡ç­¾&gt;]] æˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢çš„å‘½ä»¤å°†å®¹å™¨ä¿å­˜ä¸ºé•œåƒï¼š 1234567$ docker commit \\ [-a]--author &quot;Tao Wang &lt;twang2218@gmail.com&gt;&quot; \\ [-m]--message &quot;ä¿®æ”¹äº†é»˜è®¤ç½‘é¡µ&quot; \\ # [-c] list # apply dockerfile instruction to the created image webserver \\ nginx:v2sha256:07e33465974800ce65751acc279adc6ed2dc5ed4e0838f8b86f0c87aa1795214 å…¶ä¸­ --author æ˜¯æŒ‡å®šä¿®æ”¹çš„ä½œè€…ï¼Œè€Œ --message åˆ™æ˜¯è®°å½•æœ¬æ¬¡ä¿®æ”¹çš„å†…å®¹ã€‚è¿™ç‚¹å’Œ git ç‰ˆæœ¬æ§åˆ¶ç›¸ä¼¼ï¼Œä¸è¿‡è¿™é‡Œè¿™äº›ä¿¡æ¯å¯ä»¥çœç•¥ç•™ç©ºã€‚ æˆ‘ä»¬å¯ä»¥åœ¨ docker image ls ä¸­çœ‹åˆ°è¿™ä¸ªæ–°å®šåˆ¶çš„é•œåƒï¼š 12345$ docker image ls nginxREPOSITORY TAG IMAGE ID CREATED SIZEnginx v2 07e334659748 9 seconds ago 181.5 MBnginx 1.11 05a60462f8ba 12 days ago 181.5 MBnginx latest e43d811ce2f4 4 weeks ago 181.5 MB æˆ‘ä»¬è¿˜å¯ä»¥ç”¨ docker history å…·ä½“æŸ¥çœ‹é•œåƒå†…çš„å†å²è®°å½•ï¼Œå¦‚æœæ¯”è¾ƒ nginx:latest çš„å†å²è®°å½•ï¼Œæˆ‘ä»¬ä¼šå‘ç°æ–°å¢äº†æˆ‘ä»¬åˆšåˆšæäº¤çš„è¿™ä¸€å±‚ã€‚ 1234567891011$ docker history nginx:v2IMAGE CREATED CREATED BY SIZE COMMENT07e334659748 54 seconds ago nginx -g daemon off; 95 B ä¿®æ”¹äº†é»˜è®¤ç½‘é¡µe43d811ce2f4 4 weeks ago /bin/sh -c #(nop) CMD [&quot;nginx&quot; &quot;-g&quot; &quot;daemon 0 B&lt;missing&gt; 4 weeks ago /bin/sh -c #(nop) EXPOSE 443/tcp 80/tcp 0 B&lt;missing&gt; 4 weeks ago /bin/sh -c ln -sf /dev/stdout /var/log/nginx/ 22 B&lt;missing&gt; 4 weeks ago /bin/sh -c apt-key adv --keyserver hkp://pgp. 58.46 MB&lt;missing&gt; 4 weeks ago /bin/sh -c #(nop) ENV NGINX_VERSION=1.11.5-1 0 B&lt;missing&gt; 4 weeks ago /bin/sh -c #(nop) MAINTAINER NGINX Docker Ma 0 B&lt;missing&gt; 4 weeks ago /bin/sh -c #(nop) CMD [&quot;/bin/bash&quot;] 0 B&lt;missing&gt; 4 weeks ago /bin/sh -c #(nop) ADD file:23aa4f893e3288698c 123 MB æ–°çš„é•œåƒå®šåˆ¶å¥½åï¼Œæˆ‘ä»¬å¯ä»¥æ¥è¿è¡Œè¿™ä¸ªé•œåƒã€‚ 1docker run --name web2 -d -p 81:80 nginx:v2 è¿™é‡Œæˆ‘ä»¬å‘½åä¸ºæ–°çš„æœåŠ¡ä¸º web2ï¼Œå¹¶ä¸”æ˜ å°„åˆ° 81 ç«¯å£ã€‚è®¿é—® http://localhost:81 çœ‹åˆ°ç»“æœï¼Œå…¶å†…å®¹åº”è¯¥å’Œä¹‹å‰ä¿®æ”¹åçš„ webserver ä¸€æ ·ã€‚ è‡³æ­¤ï¼Œæˆ‘ä»¬ç¬¬ä¸€æ¬¡å®Œæˆäº†å®šåˆ¶é•œåƒï¼Œä½¿ç”¨çš„æ˜¯ docker commit å‘½ä»¤ï¼Œæ‰‹åŠ¨æ“ä½œç»™æ—§çš„é•œåƒæ·»åŠ äº†æ–°çš„ä¸€å±‚ï¼Œå½¢æˆæ–°çš„é•œåƒï¼Œå¯¹é•œåƒå¤šå±‚å­˜å‚¨åº”è¯¥æœ‰äº†æ›´ç›´è§‚çš„æ„Ÿè§‰ã€‚ æ…ç”¨ docker commitä½¿ç”¨ docker commit å‘½ä»¤è™½ç„¶å¯ä»¥æ¯”è¾ƒç›´è§‚çš„å¸®åŠ©ç†è§£é•œåƒåˆ†å±‚å­˜å‚¨çš„æ¦‚å¿µï¼Œä½†æ˜¯å®é™…ç¯å¢ƒä¸­å¹¶ä¸ä¼šè¿™æ ·ä½¿ç”¨ã€‚ é¦–å…ˆï¼Œå¦‚æœä»”ç»†è§‚å¯Ÿä¹‹å‰çš„ docker diff webserver çš„ç»“æœï¼Œä½ ä¼šå‘ç°é™¤äº†çœŸæ­£æƒ³è¦ä¿®æ”¹çš„ /usr/share/nginx/html/index.html æ–‡ä»¶å¤–ï¼Œç”±äºå‘½ä»¤çš„æ‰§è¡Œï¼Œè¿˜æœ‰å¾ˆå¤šæ–‡ä»¶è¢«æ”¹åŠ¨æˆ–æ·»åŠ äº†ã€‚è¿™è¿˜ä»…ä»…æ˜¯æœ€ç®€å•çš„æ“ä½œï¼Œå¦‚æœæ˜¯å®‰è£…è½¯ä»¶åŒ…ã€ç¼–è¯‘æ„å»ºï¼Œé‚£ä¼šæœ‰å¤§é‡çš„æ— å…³å†…å®¹è¢«æ·»åŠ è¿›æ¥ï¼Œå°†ä¼šå¯¼è‡´é•œåƒæä¸ºè‡ƒè‚¿ã€‚ æ­¤å¤–ï¼Œä½¿ç”¨ docker commit æ„å‘³ç€æ‰€æœ‰å¯¹é•œåƒçš„æ“ä½œéƒ½æ˜¯é»‘ç®±æ“ä½œï¼Œç”Ÿæˆçš„é•œåƒä¹Ÿè¢«ç§°ä¸º é»‘ç®±é•œåƒï¼Œæ¢å¥è¯è¯´ï¼Œå°±æ˜¯é™¤äº†åˆ¶ä½œé•œåƒçš„äººçŸ¥é“æ‰§è¡Œè¿‡ä»€ä¹ˆå‘½ä»¤ã€æ€ä¹ˆç”Ÿæˆçš„é•œåƒï¼Œåˆ«äººæ ¹æœ¬æ— ä»å¾—çŸ¥ã€‚è€Œä¸”ï¼Œå³ä½¿æ˜¯è¿™ä¸ªåˆ¶ä½œé•œåƒçš„äººï¼Œè¿‡ä¸€æ®µæ—¶é—´åä¹Ÿæ— æ³•è®°æ¸…å…·ä½“çš„æ“ä½œã€‚è¿™ç§é»‘ç®±é•œåƒçš„ç»´æŠ¤å·¥ä½œæ˜¯éå¸¸ç—›è‹¦çš„ã€‚ è€Œä¸”ï¼Œå›é¡¾ä¹‹å‰æåŠçš„é•œåƒæ‰€ä½¿ç”¨çš„åˆ†å±‚å­˜å‚¨çš„æ¦‚å¿µï¼Œé™¤å½“å‰å±‚å¤–ï¼Œä¹‹å‰çš„æ¯ä¸€å±‚éƒ½æ˜¯ä¸ä¼šå‘ç”Ÿæ”¹å˜çš„ï¼Œæ¢å¥è¯è¯´ï¼Œä»»ä½•ä¿®æ”¹çš„ç»“æœä»…ä»…æ˜¯åœ¨å½“å‰å±‚è¿›è¡Œæ ‡è®°ã€æ·»åŠ ã€ä¿®æ”¹ï¼Œè€Œä¸ä¼šæ”¹åŠ¨ä¸Šä¸€å±‚ã€‚å¦‚æœä½¿ç”¨ docker commit åˆ¶ä½œé•œåƒï¼Œä»¥åŠåæœŸä¿®æ”¹çš„è¯ï¼Œæ¯ä¸€æ¬¡ä¿®æ”¹éƒ½ä¼šè®©é•œåƒæ›´åŠ è‡ƒè‚¿ä¸€æ¬¡ï¼Œæ‰€åˆ é™¤çš„ä¸Šä¸€å±‚çš„ä¸œè¥¿å¹¶ä¸ä¼šä¸¢å¤±ï¼Œä¼šä¸€ç›´å¦‚å½±éšå½¢çš„è·Ÿç€è¿™ä¸ªé•œåƒï¼Œå³ä½¿æ ¹æœ¬æ— æ³•è®¿é—®åˆ°ã€‚è¿™ä¼šè®©é•œåƒæ›´åŠ è‡ƒè‚¿ã€‚ 5 ä½¿ç”¨ Dockerfile å®šåˆ¶é•œåƒä»åˆšæ‰çš„ docker commit çš„å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£åˆ°ï¼Œé•œåƒçš„å®šåˆ¶å®é™…ä¸Šå°±æ˜¯å®šåˆ¶æ¯ä¸€å±‚æ‰€æ·»åŠ çš„é…ç½®ã€æ–‡ä»¶ã€‚å¦‚æœæˆ‘ä»¬å¯ä»¥æŠŠæ¯ä¸€å±‚ä¿®æ”¹ã€å®‰è£…ã€æ„å»ºã€æ“ä½œçš„å‘½ä»¤éƒ½å†™å…¥ä¸€ä¸ªè„šæœ¬ï¼Œç”¨è¿™ä¸ªè„šæœ¬æ¥æ„å»ºã€å®šåˆ¶é•œåƒï¼Œé‚£ä¹ˆä¹‹å‰æåŠçš„æ— æ³•é‡å¤çš„é—®é¢˜ã€é•œåƒæ„å»ºé€æ˜æ€§çš„é—®é¢˜ã€ä½“ç§¯çš„é—®é¢˜å°±éƒ½ä¼šè§£å†³ã€‚è¿™ä¸ªè„šæœ¬å°±æ˜¯ Dockerfileã€‚ Dockerfile æ˜¯ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œå…¶å†…åŒ…å«äº†ä¸€æ¡æ¡çš„ æŒ‡ä»¤(Instruction)ï¼Œæ¯ä¸€æ¡æŒ‡ä»¤æ„å»ºä¸€å±‚ï¼Œå› æ­¤æ¯ä¸€æ¡æŒ‡ä»¤çš„å†…å®¹ï¼Œå°±æ˜¯æè¿°è¯¥å±‚åº”å½“å¦‚ä½•æ„å»ºã€‚ è¿˜ä»¥ä¹‹å‰å®šåˆ¶ nginx é•œåƒä¸ºä¾‹ï¼Œè¿™æ¬¡æˆ‘ä»¬ä½¿ç”¨ Dockerfile æ¥å®šåˆ¶ã€‚ åœ¨ä¸€ä¸ªç©ºç™½ç›®å½•ä¸­ï¼Œå»ºç«‹ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œå¹¶å‘½åä¸º Dockerfileï¼š 123$ mkdir mynginx$ cd mynginx$ touch Dockerfile å…¶å†…å®¹ä¸ºï¼š 12FROM nginxRUN echo &#x27;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#x27; &gt; /usr/share/nginx/html/index.html è¿™ä¸ª Dockerfile å¾ˆç®€å•ï¼Œä¸€å…±å°±ä¸¤è¡Œã€‚æ¶‰åŠåˆ°äº†ä¸¤æ¡æŒ‡ä»¤ï¼ŒFROM å’Œ RUNã€‚ FROM æŒ‡å®šåŸºç¡€é•œåƒæ‰€è°“å®šåˆ¶é•œåƒï¼Œé‚£ä¸€å®šæ˜¯ä»¥ä¸€ä¸ªé•œåƒä¸ºåŸºç¡€ï¼Œåœ¨å…¶ä¸Šè¿›è¡Œå®šåˆ¶ã€‚å°±åƒæˆ‘ä»¬ä¹‹å‰è¿è¡Œäº†ä¸€ä¸ª nginx é•œåƒçš„å®¹å™¨ï¼Œå†è¿›è¡Œä¿®æ”¹ä¸€æ ·ï¼ŒåŸºç¡€é•œåƒæ˜¯å¿…é¡»æŒ‡å®šçš„ã€‚è€Œ FROM å°±æ˜¯æŒ‡å®š åŸºç¡€é•œåƒï¼Œå› æ­¤ä¸€ä¸ª Dockerfile ä¸­ FROM æ˜¯å¿…å¤‡çš„æŒ‡ä»¤ï¼Œå¹¶ä¸”å¿…é¡»æ˜¯ç¬¬ä¸€æ¡æŒ‡ä»¤ã€‚ åœ¨ Docker Hub ä¸Šæœ‰éå¸¸å¤šçš„é«˜è´¨é‡çš„å®˜æ–¹é•œåƒï¼Œæœ‰å¯ä»¥ç›´æ¥æ‹¿æ¥ä½¿ç”¨çš„æœåŠ¡ç±»çš„é•œåƒï¼Œå¦‚ nginxã€redisã€mongoã€mysqlã€httpdã€phpã€tomcat ç­‰ï¼›ä¹Ÿæœ‰ä¸€äº›æ–¹ä¾¿å¼€å‘ã€æ„å»ºã€è¿è¡Œå„ç§è¯­è¨€åº”ç”¨çš„é•œåƒï¼Œå¦‚ nodeã€openjdkã€pythonã€rubyã€golang ç­‰ã€‚å¯ä»¥åœ¨å…¶ä¸­å¯»æ‰¾ä¸€ä¸ªæœ€ç¬¦åˆæˆ‘ä»¬æœ€ç»ˆç›®æ ‡çš„é•œåƒä¸ºåŸºç¡€é•œåƒè¿›è¡Œå®šåˆ¶ã€‚ å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”æœåŠ¡çš„é•œåƒï¼Œå®˜æ–¹é•œåƒä¸­è¿˜æä¾›äº†ä¸€äº›æ›´ä¸ºåŸºç¡€çš„æ“ä½œç³»ç»Ÿé•œåƒï¼Œå¦‚ ubuntuã€debianã€centosã€fedoraã€alpine ç­‰ï¼Œè¿™äº›æ“ä½œç³»ç»Ÿçš„è½¯ä»¶åº“ä¸ºæˆ‘ä»¬æä¾›äº†æ›´å¹¿é˜”çš„æ‰©å±•ç©ºé—´ã€‚ é™¤äº†é€‰æ‹©ç°æœ‰é•œåƒä¸ºåŸºç¡€é•œåƒå¤–ï¼ŒDocker è¿˜å­˜åœ¨ä¸€ä¸ªç‰¹æ®Šçš„é•œåƒï¼Œåä¸º scratchã€‚è¿™ä¸ªé•œåƒæ˜¯è™šæ‹Ÿçš„æ¦‚å¿µï¼Œå¹¶ä¸å®é™…å­˜åœ¨ï¼Œå®ƒè¡¨ç¤ºä¸€ä¸ªç©ºç™½çš„é•œåƒã€‚ 12FROM scratch... å¦‚æœä½ ä»¥ scratch ä¸ºåŸºç¡€é•œåƒçš„è¯ï¼Œæ„å‘³ç€ä½ ä¸ä»¥ä»»ä½•é•œåƒä¸ºåŸºç¡€ï¼Œæ¥ä¸‹æ¥æ‰€å†™çš„æŒ‡ä»¤å°†ä½œä¸ºé•œåƒç¬¬ä¸€å±‚å¼€å§‹å­˜åœ¨ã€‚ ä¸ä»¥ä»»ä½•ç³»ç»Ÿä¸ºåŸºç¡€ï¼Œç›´æ¥å°†å¯æ‰§è¡Œæ–‡ä»¶å¤åˆ¶è¿›é•œåƒçš„åšæ³•å¹¶ä¸ç½•è§ï¼Œå¯¹äº Linux ä¸‹é™æ€ç¼–è¯‘çš„ç¨‹åºæ¥è¯´ï¼Œå¹¶ä¸éœ€è¦æœ‰æ“ä½œç³»ç»Ÿæä¾›è¿è¡Œæ—¶æ”¯æŒï¼Œæ‰€éœ€çš„ä¸€åˆ‡åº“éƒ½å·²ç»åœ¨å¯æ‰§è¡Œæ–‡ä»¶é‡Œäº†ï¼Œå› æ­¤ç›´æ¥ FROM scratch ä¼šè®©é•œåƒä½“ç§¯æ›´åŠ å°å·§ã€‚ä½¿ç”¨ Go è¯­è¨€ å¼€å‘çš„åº”ç”¨å¾ˆå¤šä¼šä½¿ç”¨è¿™ç§æ–¹å¼æ¥åˆ¶ä½œé•œåƒï¼Œè¿™ä¹Ÿæ˜¯æœ‰äººè®¤ä¸º Go æ˜¯ç‰¹åˆ«é€‚åˆå®¹å™¨å¾®æœåŠ¡æ¶æ„çš„è¯­è¨€çš„åŸå› ä¹‹ä¸€ã€‚ RUN æ‰§è¡Œå‘½ä»¤RUN æŒ‡ä»¤æ˜¯ç”¨æ¥æ‰§è¡Œå‘½ä»¤è¡Œå‘½ä»¤çš„ã€‚ç”±äºå‘½ä»¤è¡Œçš„å¼ºå¤§èƒ½åŠ›ï¼ŒRUN æŒ‡ä»¤åœ¨å®šåˆ¶é•œåƒæ—¶æ˜¯æœ€å¸¸ç”¨çš„æŒ‡ä»¤ä¹‹ä¸€ã€‚å…¶æ ¼å¼æœ‰ä¸¤ç§ï¼š shell æ ¼å¼ï¼šRUN &lt;å‘½ä»¤&gt;ï¼Œå°±åƒç›´æ¥åœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥çš„å‘½ä»¤ä¸€æ ·ã€‚åˆšæ‰å†™çš„ Dockerfile ä¸­çš„ RUN æŒ‡ä»¤å°±æ˜¯è¿™ç§æ ¼å¼ã€‚ 1RUN echo &#x27;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#x27; &gt; /usr/share/nginx/html/index.html exec æ ¼å¼ï¼šRUN [&quot;å¯æ‰§è¡Œæ–‡ä»¶&quot;, &quot;å‚æ•°1&quot;, &quot;å‚æ•°2&quot;]ï¼Œè¿™æ›´åƒæ˜¯å‡½æ•°è°ƒç”¨ä¸­çš„æ ¼å¼ã€‚ æ—¢ç„¶ RUN å°±åƒ Shell è„šæœ¬ä¸€æ ·å¯ä»¥æ‰§è¡Œå‘½ä»¤ï¼Œé‚£ä¹ˆæˆ‘ä»¬æ˜¯å¦å°±å¯ä»¥åƒ Shell è„šæœ¬ä¸€æ ·æŠŠæ¯ä¸ªå‘½ä»¤å¯¹åº”ä¸€ä¸ª RUN å‘¢ï¼Ÿæ¯”å¦‚è¿™æ ·ï¼š 123456789FROM debian:stretchRUN apt-get updateRUN apt-get install -y gcc libc6-dev make wgetRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot;RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install ä¹‹å‰è¯´è¿‡ï¼ŒDockerfile ä¸­æ¯ä¸€ä¸ªæŒ‡ä»¤éƒ½ä¼šå»ºç«‹ä¸€å±‚ï¼ŒRUN ä¹Ÿä¸ä¾‹å¤–ã€‚æ¯ä¸€ä¸ª RUN çš„è¡Œä¸ºï¼Œå°±å’Œåˆšæ‰æˆ‘ä»¬æ‰‹å·¥å»ºç«‹é•œåƒçš„è¿‡ç¨‹ä¸€æ ·ï¼šæ–°å»ºç«‹ä¸€å±‚ï¼Œåœ¨å…¶ä¸Šæ‰§è¡Œè¿™äº›å‘½ä»¤ï¼Œæ‰§è¡Œç»“æŸåï¼Œcommit è¿™ä¸€å±‚çš„ä¿®æ”¹ï¼Œæ„æˆæ–°çš„é•œåƒã€‚ è€Œä¸Šé¢çš„è¿™ç§å†™æ³•ï¼Œåˆ›å»ºäº† 7 å±‚é•œåƒã€‚è¿™æ˜¯å®Œå…¨æ²¡æœ‰æ„ä¹‰çš„ï¼Œè€Œä¸”å¾ˆå¤šè¿è¡Œæ—¶ä¸éœ€è¦çš„ä¸œè¥¿ï¼Œéƒ½è¢«è£…è¿›äº†é•œåƒé‡Œï¼Œæ¯”å¦‚ç¼–è¯‘ç¯å¢ƒã€æ›´æ–°çš„è½¯ä»¶åŒ…ç­‰ç­‰ã€‚ç»“æœå°±æ˜¯äº§ç”Ÿéå¸¸è‡ƒè‚¿ã€éå¸¸å¤šå±‚çš„é•œåƒï¼Œä¸ä»…ä»…å¢åŠ äº†æ„å»ºéƒ¨ç½²çš„æ—¶é—´ï¼Œä¹Ÿå¾ˆå®¹æ˜“å‡ºé”™ã€‚ è¿™æ˜¯å¾ˆå¤šåˆå­¦ Docker çš„äººå¸¸çŠ¯çš„ä¸€ä¸ªé”™è¯¯ã€‚ Union FS æ˜¯æœ‰æœ€å¤§å±‚æ•°é™åˆ¶çš„ï¼Œæ¯”å¦‚ AUFSï¼Œæ›¾ç»æ˜¯æœ€å¤§ä¸å¾—è¶…è¿‡ 42 å±‚ï¼Œç°åœ¨æ˜¯ä¸å¾—è¶…è¿‡ 127 å±‚ã€‚ ä¸Šé¢çš„ Dockerfile æ­£ç¡®çš„å†™æ³•åº”è¯¥æ˜¯è¿™æ ·ï¼š 1234567891011121314FROM debian:stretchRUN set -x; buildDeps=&#x27;gcc libc6-dev make wget&#x27; \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install -y $buildDeps \\ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot; \\ &amp;&amp; mkdir -p /usr/src/redis \\ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\ &amp;&amp; make -C /usr/src/redis \\ &amp;&amp; make -C /usr/src/redis install \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; rm redis.tar.gz \\ &amp;&amp; rm -r /usr/src/redis \\ &amp;&amp; apt-get purge -y --auto-remove $buildDeps é¦–å…ˆï¼Œä¹‹å‰æ‰€æœ‰çš„å‘½ä»¤åªæœ‰ä¸€ä¸ªç›®çš„ï¼Œå°±æ˜¯ç¼–è¯‘ã€å®‰è£… redis å¯æ‰§è¡Œæ–‡ä»¶ã€‚å› æ­¤æ²¡æœ‰å¿…è¦å»ºç«‹å¾ˆå¤šå±‚ï¼Œè¿™åªæ˜¯ä¸€å±‚çš„äº‹æƒ…ã€‚å› æ­¤ï¼Œè¿™é‡Œæ²¡æœ‰ä½¿ç”¨å¾ˆå¤šä¸ª RUN ä¸€ä¸€å¯¹åº”ä¸åŒçš„å‘½ä»¤ï¼Œè€Œæ˜¯ä»…ä»…ä½¿ç”¨ä¸€ä¸ª RUN æŒ‡ä»¤ï¼Œå¹¶ä½¿ç”¨ &amp;&amp; å°†å„ä¸ªæ‰€éœ€å‘½ä»¤ä¸²è”èµ·æ¥ã€‚å°†ä¹‹å‰çš„ 7 å±‚ï¼Œç®€åŒ–ä¸ºäº† 1 å±‚ã€‚åœ¨æ’°å†™ Dockerfile çš„æ—¶å€™ï¼Œè¦ç»å¸¸æé†’è‡ªå·±ï¼Œè¿™å¹¶ä¸æ˜¯åœ¨å†™ Shell è„šæœ¬ï¼Œè€Œæ˜¯åœ¨å®šä¹‰æ¯ä¸€å±‚è¯¥å¦‚ä½•æ„å»ºã€‚ å¹¶ä¸”ï¼Œè¿™é‡Œä¸ºäº†æ ¼å¼åŒ–è¿˜è¿›è¡Œäº†æ¢è¡Œã€‚Dockerfile æ”¯æŒ Shell ç±»çš„è¡Œå°¾æ·»åŠ  \\ çš„å‘½ä»¤æ¢è¡Œæ–¹å¼ï¼Œä»¥åŠè¡Œé¦– # è¿›è¡Œæ³¨é‡Šçš„æ ¼å¼ã€‚è‰¯å¥½çš„æ ¼å¼ï¼Œæ¯”å¦‚æ¢è¡Œã€ç¼©è¿›ã€æ³¨é‡Šç­‰ï¼Œä¼šè®©ç»´æŠ¤ã€æ’éšœæ›´ä¸ºå®¹æ˜“ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¥½çš„ä¹ æƒ¯ã€‚ æ­¤å¤–ï¼Œè¿˜å¯ä»¥çœ‹åˆ°è¿™ä¸€ç»„å‘½ä»¤çš„æœ€åæ·»åŠ äº†æ¸…ç†å·¥ä½œçš„å‘½ä»¤ï¼Œåˆ é™¤äº†ä¸ºäº†ç¼–è¯‘æ„å»ºæ‰€éœ€è¦çš„è½¯ä»¶ï¼Œæ¸…ç†äº†æ‰€æœ‰ä¸‹è½½ã€å±•å¼€çš„æ–‡ä»¶ï¼Œå¹¶ä¸”è¿˜æ¸…ç†äº† apt ç¼“å­˜æ–‡ä»¶ã€‚è¿™æ˜¯å¾ˆé‡è¦çš„ä¸€æ­¥ï¼Œæˆ‘ä»¬ä¹‹å‰è¯´è¿‡ï¼Œé•œåƒæ˜¯å¤šå±‚å­˜å‚¨ï¼Œæ¯ä¸€å±‚çš„ä¸œè¥¿å¹¶ä¸ä¼šåœ¨ä¸‹ä¸€å±‚è¢«åˆ é™¤ï¼Œä¼šä¸€ç›´è·Ÿéšç€é•œåƒã€‚å› æ­¤é•œåƒæ„å»ºæ—¶ï¼Œä¸€å®šè¦ç¡®ä¿æ¯ä¸€å±‚åªæ·»åŠ çœŸæ­£éœ€è¦æ·»åŠ çš„ä¸œè¥¿ï¼Œä»»ä½•æ— å…³çš„ä¸œè¥¿éƒ½åº”è¯¥æ¸…ç†æ‰ã€‚ å¾ˆå¤šäººåˆå­¦ Docker åˆ¶ä½œå‡ºäº†å¾ˆè‡ƒè‚¿çš„é•œåƒçš„åŸå› ä¹‹ä¸€ï¼Œå°±æ˜¯å¿˜è®°äº†æ¯ä¸€å±‚æ„å»ºçš„æœ€åä¸€å®šè¦æ¸…ç†æ‰æ— å…³æ–‡ä»¶ã€‚ æ„å»ºé•œåƒå¥½äº†ï¼Œè®©æˆ‘ä»¬å†å›åˆ°ä¹‹å‰å®šåˆ¶çš„ nginx é•œåƒçš„ Dockerfile æ¥ã€‚ç°åœ¨æˆ‘ä»¬æ˜ç™½äº†è¿™ä¸ª Dockerfile çš„å†…å®¹ï¼Œé‚£ä¹ˆè®©æˆ‘ä»¬æ¥æ„å»ºè¿™ä¸ªé•œåƒå§ã€‚ åœ¨ Dockerfile æ–‡ä»¶æ‰€åœ¨ç›®å½•æ‰§è¡Œï¼š 123456789$ docker build -t nginx:v3 .Sending build context to Docker daemon 2.048 kBStep 1 : FROM nginx ---&gt; e43d811ce2f4Step 2 : RUN echo &#x27;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#x27; &gt; /usr/share/nginx/html/index.html ---&gt; Running in 9cdc27646c7b ---&gt; 44aa4490ce2cRemoving intermediate container 9cdc27646c7bSuccessfully built 44aa4490ce2c ä»å‘½ä»¤çš„è¾“å‡ºç»“æœä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ¸…æ™°çš„çœ‹åˆ°é•œåƒçš„æ„å»ºè¿‡ç¨‹ã€‚åœ¨ Step 2 ä¸­ï¼Œå¦‚åŒæˆ‘ä»¬ä¹‹å‰æ‰€è¯´çš„é‚£æ ·ï¼ŒRUN æŒ‡ä»¤å¯åŠ¨äº†ä¸€ä¸ªå®¹å™¨ 9cdc27646c7bï¼Œæ‰§è¡Œäº†æ‰€è¦æ±‚çš„å‘½ä»¤ï¼Œå¹¶æœ€åæäº¤äº†è¿™ä¸€å±‚ 44aa4490ce2cï¼Œéšååˆ é™¤äº†æ‰€ç”¨åˆ°çš„è¿™ä¸ªå®¹å™¨ 9cdc27646c7bã€‚ è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨äº† docker build å‘½ä»¤è¿›è¡Œé•œåƒæ„å»ºã€‚å…¶æ ¼å¼ä¸ºï¼š 1docker build [é€‰é¡¹] &lt;ä¸Šä¸‹æ–‡è·¯å¾„/URL/-&gt; åœ¨è¿™é‡Œæˆ‘ä»¬æŒ‡å®šäº†æœ€ç»ˆé•œåƒçš„åç§° -t nginx:v3ï¼Œæ„å»ºæˆåŠŸåï¼Œæˆ‘ä»¬å¯ä»¥åƒä¹‹å‰è¿è¡Œ nginx:v2 é‚£æ ·æ¥è¿è¡Œè¿™ä¸ªé•œåƒï¼Œå…¶ç»“æœä¼šå’Œ nginx:v2 ä¸€æ ·ã€‚ é•œåƒæ„å»ºä¸Šä¸‹æ–‡ï¼ˆContextï¼‰å¦‚æœæ³¨æ„ï¼Œä¼šçœ‹åˆ° docker build å‘½ä»¤æœ€åæœ‰ä¸€ä¸ª .ã€‚. è¡¨ç¤ºå½“å‰ç›®å½•ï¼Œè€Œ Dockerfile å°±åœ¨å½“å‰ç›®å½•ï¼Œå› æ­¤ä¸å°‘åˆå­¦è€…ä»¥ä¸ºè¿™ä¸ªè·¯å¾„æ˜¯åœ¨æŒ‡å®š Dockerfile æ‰€åœ¨è·¯å¾„ï¼Œè¿™ä¹ˆç†è§£å…¶å®æ˜¯ä¸å‡†ç¡®çš„ã€‚å¦‚æœå¯¹åº”ä¸Šé¢çš„å‘½ä»¤æ ¼å¼ï¼Œä½ å¯èƒ½ä¼šå‘ç°ï¼Œè¿™æ˜¯åœ¨æŒ‡å®š ä¸Šä¸‹æ–‡è·¯å¾„ã€‚é‚£ä¹ˆä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡å‘¢ï¼Ÿ é¦–å…ˆæˆ‘ä»¬è¦ç†è§£ docker build çš„å·¥ä½œåŸç†ã€‚Docker åœ¨è¿è¡Œæ—¶åˆ†ä¸º Docker å¼•æ“ï¼ˆä¹Ÿå°±æ˜¯æœåŠ¡ç«¯å®ˆæŠ¤è¿›ç¨‹ï¼‰å’Œå®¢æˆ·ç«¯å·¥å…·ã€‚Docker çš„å¼•æ“æä¾›äº†ä¸€ç»„ REST APIï¼Œè¢«ç§°ä¸º Docker Remote APIï¼Œè€Œå¦‚ docker å‘½ä»¤è¿™æ ·çš„å®¢æˆ·ç«¯å·¥å…·ï¼Œåˆ™æ˜¯é€šè¿‡è¿™ç»„ API ä¸ Docker å¼•æ“äº¤äº’ï¼Œä»è€Œå®Œæˆå„ç§åŠŸèƒ½ã€‚å› æ­¤ï¼Œè™½ç„¶è¡¨é¢ä¸Šæˆ‘ä»¬å¥½åƒæ˜¯åœ¨æœ¬æœºæ‰§è¡Œå„ç§ docker åŠŸèƒ½ï¼Œä½†å®é™…ä¸Šï¼Œä¸€åˆ‡éƒ½æ˜¯ä½¿ç”¨çš„è¿œç¨‹è°ƒç”¨å½¢å¼åœ¨æœåŠ¡ç«¯ï¼ˆDocker å¼•æ“ï¼‰å®Œæˆã€‚ä¹Ÿå› ä¸ºè¿™ç§ C&#x2F;S è®¾è®¡ï¼Œè®©æˆ‘ä»¬æ“ä½œè¿œç¨‹æœåŠ¡å™¨çš„ Docker å¼•æ“å˜å¾—è½»è€Œæ˜“ä¸¾ã€‚ å½“æˆ‘ä»¬è¿›è¡Œé•œåƒæ„å»ºçš„æ—¶å€™ï¼Œå¹¶éæ‰€æœ‰å®šåˆ¶éƒ½ä¼šé€šè¿‡ RUN æŒ‡ä»¤å®Œæˆï¼Œç»å¸¸ä¼šéœ€è¦å°†ä¸€äº›æœ¬åœ°æ–‡ä»¶å¤åˆ¶è¿›é•œåƒï¼Œæ¯”å¦‚é€šè¿‡ COPY æŒ‡ä»¤ã€ADD æŒ‡ä»¤ç­‰ã€‚è€Œ docker build å‘½ä»¤æ„å»ºé•œåƒï¼Œå…¶å®å¹¶éåœ¨æœ¬åœ°æ„å»ºï¼Œè€Œæ˜¯åœ¨æœåŠ¡ç«¯ï¼Œä¹Ÿå°±æ˜¯ Docker å¼•æ“ä¸­æ„å»ºçš„ã€‚é‚£ä¹ˆåœ¨è¿™ç§å®¢æˆ·ç«¯&#x2F;æœåŠ¡ç«¯çš„æ¶æ„ä¸­ï¼Œå¦‚ä½•æ‰èƒ½è®©æœåŠ¡ç«¯è·å¾—æœ¬åœ°æ–‡ä»¶å‘¢ï¼Ÿ è¿™å°±å¼•å…¥äº†ä¸Šä¸‹æ–‡çš„æ¦‚å¿µã€‚å½“æ„å»ºçš„æ—¶å€™ï¼Œç”¨æˆ·ä¼šæŒ‡å®šæ„å»ºé•œåƒä¸Šä¸‹æ–‡çš„è·¯å¾„ï¼Œdocker build å‘½ä»¤å¾—çŸ¥è¿™ä¸ªè·¯å¾„åï¼Œä¼šå°†è·¯å¾„ä¸‹çš„æ‰€æœ‰å†…å®¹æ‰“åŒ…ï¼Œç„¶åä¸Šä¼ ç»™ Docker å¼•æ“ã€‚è¿™æ · Docker å¼•æ“æ”¶åˆ°è¿™ä¸ªä¸Šä¸‹æ–‡åŒ…åï¼Œå±•å¼€å°±ä¼šè·å¾—æ„å»ºé•œåƒæ‰€éœ€çš„ä¸€åˆ‡æ–‡ä»¶ã€‚ å¦‚æœåœ¨ Dockerfile ä¸­è¿™ä¹ˆå†™ï¼š 1COPY ./package.json /app/ è¿™å¹¶ä¸æ˜¯è¦å¤åˆ¶æ‰§è¡Œ docker build å‘½ä»¤æ‰€åœ¨çš„ç›®å½•ä¸‹çš„ package.jsonï¼Œä¹Ÿä¸æ˜¯å¤åˆ¶ Dockerfile æ‰€åœ¨ç›®å½•ä¸‹çš„ package.jsonï¼Œè€Œæ˜¯å¤åˆ¶ ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰ ç›®å½•ä¸‹çš„ package.jsonã€‚ å› æ­¤ï¼ŒCOPY è¿™ç±»æŒ‡ä»¤ä¸­çš„æºæ–‡ä»¶çš„è·¯å¾„éƒ½æ˜¯ç›¸å¯¹è·¯å¾„ã€‚è¿™ä¹Ÿæ˜¯åˆå­¦è€…ç»å¸¸ä¼šé—®çš„ä¸ºä»€ä¹ˆ COPY ../package.json /app æˆ–è€… COPY /opt/xxxx /app æ— æ³•å·¥ä½œçš„åŸå› ï¼Œå› ä¸ºè¿™äº›è·¯å¾„å·²ç»è¶…å‡ºäº†ä¸Šä¸‹æ–‡çš„èŒƒå›´ï¼ŒDocker å¼•æ“æ— æ³•è·å¾—è¿™äº›ä½ç½®çš„æ–‡ä»¶ã€‚å¦‚æœçœŸçš„éœ€è¦é‚£äº›æ–‡ä»¶ï¼Œåº”è¯¥å°†å®ƒä»¬å¤åˆ¶åˆ°ä¸Šä¸‹æ–‡ç›®å½•ä¸­å»ã€‚ ç°åœ¨å°±å¯ä»¥ç†è§£åˆšæ‰çš„å‘½ä»¤ docker build -t nginx:v3 . ä¸­çš„è¿™ä¸ª .ï¼Œå®é™…ä¸Šæ˜¯åœ¨æŒ‡å®šä¸Šä¸‹æ–‡çš„ç›®å½•ï¼Œdocker build å‘½ä»¤ä¼šå°†è¯¥ç›®å½•ä¸‹çš„å†…å®¹æ‰“åŒ…äº¤ç»™ Docker å¼•æ“ä»¥å¸®åŠ©æ„å»ºé•œåƒã€‚ å¦‚æœè§‚å¯Ÿ docker build è¾“å‡ºï¼Œæˆ‘ä»¬å…¶å®å·²ç»çœ‹åˆ°äº†è¿™ä¸ªå‘é€ä¸Šä¸‹æ–‡çš„è¿‡ç¨‹ï¼š 123$ docker build -t nginx:v3 .Sending build context to Docker daemon 2.048 kB... ç†è§£æ„å»ºä¸Šä¸‹æ–‡å¯¹äºé•œåƒæ„å»ºæ˜¯å¾ˆé‡è¦çš„ï¼Œé¿å…çŠ¯ä¸€äº›ä¸åº”è¯¥çš„é”™è¯¯ã€‚æ¯”å¦‚æœ‰äº›åˆå­¦è€…åœ¨å‘ç° COPY /opt/xxxx /app ä¸å·¥ä½œåï¼Œäºæ˜¯å¹²è„†å°† Dockerfile æ”¾åˆ°äº†ç¡¬ç›˜æ ¹ç›®å½•å»æ„å»ºï¼Œç»“æœå‘ç° docker build æ‰§è¡Œåï¼Œåœ¨å‘é€ä¸€ä¸ªå‡ å GB çš„ä¸œè¥¿ï¼Œæä¸ºç¼“æ…¢è€Œä¸”å¾ˆå®¹æ˜“æ„å»ºå¤±è´¥ã€‚é‚£æ˜¯å› ä¸ºè¿™ç§åšæ³•æ˜¯åœ¨è®© docker build æ‰“åŒ…æ•´ä¸ªç¡¬ç›˜ï¼Œè¿™æ˜¾ç„¶æ˜¯ä½¿ç”¨é”™è¯¯ã€‚ ä¸€èˆ¬æ¥è¯´ï¼Œåº”è¯¥ä¼šå°† Dockerfile ç½®äºä¸€ä¸ªç©ºç›®å½•ä¸‹ï¼Œæˆ–è€…é¡¹ç›®æ ¹ç›®å½•ä¸‹ã€‚å¦‚æœè¯¥ç›®å½•ä¸‹æ²¡æœ‰æ‰€éœ€æ–‡ä»¶ï¼Œé‚£ä¹ˆåº”è¯¥æŠŠæ‰€éœ€æ–‡ä»¶å¤åˆ¶ä¸€ä»½è¿‡æ¥ã€‚å¦‚æœç›®å½•ä¸‹æœ‰äº›ä¸œè¥¿ç¡®å®ä¸å¸Œæœ›æ„å»ºæ—¶ä¼ ç»™ Docker å¼•æ“ï¼Œé‚£ä¹ˆå¯ä»¥ç”¨ .gitignore ä¸€æ ·çš„è¯­æ³•å†™ä¸€ä¸ª .dockerignoreï¼Œè¯¥æ–‡ä»¶æ˜¯ç”¨äºå‰”é™¤ä¸éœ€è¦ä½œä¸ºä¸Šä¸‹æ–‡ä¼ é€’ç»™ Docker å¼•æ“çš„ã€‚ é‚£ä¹ˆä¸ºä»€ä¹ˆä¼šæœ‰äººè¯¯ä»¥ä¸º . æ˜¯æŒ‡å®š Dockerfile æ‰€åœ¨ç›®å½•å‘¢ï¼Ÿè¿™æ˜¯å› ä¸ºåœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœä¸é¢å¤–æŒ‡å®š Dockerfile çš„è¯ï¼Œä¼šå°†ä¸Šä¸‹æ–‡ç›®å½•ä¸‹çš„åä¸º Dockerfile çš„æ–‡ä»¶ä½œä¸º Dockerfileã€‚ è¿™åªæ˜¯é»˜è®¤è¡Œä¸ºï¼Œå®é™…ä¸Š Dockerfile çš„æ–‡ä»¶åå¹¶ä¸è¦æ±‚å¿…é¡»ä¸º Dockerfileï¼Œè€Œä¸”å¹¶ä¸è¦æ±‚å¿…é¡»ä½äºä¸Šä¸‹æ–‡ç›®å½•ä¸­ï¼Œæ¯”å¦‚**å¯ä»¥ç”¨ -f ../Dockerfile.php å‚æ•°æŒ‡å®šæŸä¸ªæ–‡ä»¶ä½œä¸º Dockerfile**ã€‚ å½“ç„¶ï¼Œä¸€èˆ¬å¤§å®¶ä¹ æƒ¯æ€§çš„ä¼šä½¿ç”¨é»˜è®¤çš„æ–‡ä»¶å Dockerfileï¼Œä»¥åŠä¼šå°†å…¶ç½®äºé•œåƒæ„å»ºä¸Šä¸‹æ–‡ç›®å½•ä¸­ã€‚ å…¶å®ƒ docker build çš„ç”¨æ³•ç›´æ¥ç”¨ Git repo è¿›è¡Œæ„å»ºæˆ–è®¸ä½ å·²ç»æ³¨æ„åˆ°äº†ï¼Œdocker build è¿˜æ”¯æŒä» URL æ„å»ºï¼Œæ¯”å¦‚å¯ä»¥ç›´æ¥ä» Git repo ä¸­æ„å»ºï¼š 1234567891011121314# $env:DOCKER_BUILDKIT=0# export DOCKER_BUILDKIT=0$ docker build -t hello-world https://github.com/docker-library/hello-world.git#master:amd64/hello-worldStep 1/3 : FROM scratch ---&gt;Step 2/3 : COPY hello / ---&gt; ac779757d46eStep 3/3 : CMD [&quot;/hello&quot;] ---&gt; Running in d2a513a760edRemoving intermediate container d2a513a760ed ---&gt; 038ad4142d2bSuccessfully built 038ad4142d2b è¿™è¡Œå‘½ä»¤æŒ‡å®šäº†æ„å»ºæ‰€éœ€çš„ Git repoï¼Œå¹¶ä¸”æŒ‡å®šåˆ†æ”¯ä¸º masterï¼Œæ„å»ºç›®å½•ä¸º /amd64/hello-world/ï¼Œç„¶å Docker å°±ä¼šè‡ªå·±å» git clone è¿™ä¸ªé¡¹ç›®ã€åˆ‡æ¢åˆ°æŒ‡å®šåˆ†æ”¯ã€å¹¶è¿›å…¥åˆ°æŒ‡å®šç›®å½•åå¼€å§‹æ„å»ºã€‚ ç”¨ç»™å®šçš„ tar å‹ç¼©åŒ…æ„å»º1$ docker build http://server/context.tar.gz å¦‚æœæ‰€ç»™å‡ºçš„ URL ä¸æ˜¯ä¸ª Git repoï¼Œè€Œæ˜¯ä¸ª tar å‹ç¼©åŒ…ï¼Œé‚£ä¹ˆ Docker å¼•æ“ä¼šä¸‹è½½è¿™ä¸ªåŒ…ï¼Œå¹¶è‡ªåŠ¨è§£å‹ç¼©ï¼Œä»¥å…¶ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå¼€å§‹æ„å»ºã€‚ ä»æ ‡å‡†è¾“å…¥ä¸­è¯»å– Dockerfile è¿›è¡Œæ„å»º1docker build - &lt; Dockerfile æˆ– 1cat Dockerfile | docker build - å¦‚æœæ ‡å‡†è¾“å…¥ä¼ å…¥çš„æ˜¯æ–‡æœ¬æ–‡ä»¶ï¼Œåˆ™å°†å…¶è§†ä¸º Dockerfileï¼Œå¹¶å¼€å§‹æ„å»ºã€‚è¿™ç§å½¢å¼ç”±äºç›´æ¥ä»æ ‡å‡†è¾“å…¥ä¸­è¯»å– Dockerfile çš„å†…å®¹ï¼Œå®ƒæ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œå› æ­¤ä¸å¯ä»¥åƒå…¶ä»–æ–¹æ³•é‚£æ ·å¯ä»¥å°†æœ¬åœ°æ–‡ä»¶ COPY è¿›é•œåƒä¹‹ç±»çš„äº‹æƒ…ã€‚ ä»æ ‡å‡†è¾“å…¥ä¸­è¯»å–ä¸Šä¸‹æ–‡å‹ç¼©åŒ…è¿›è¡Œæ„å»º1$ docker build - &lt; context.tar.gz å¦‚æœå‘ç°æ ‡å‡†è¾“å…¥çš„æ–‡ä»¶æ ¼å¼æ˜¯ gzipã€bzip2 ä»¥åŠ xz çš„è¯ï¼Œå°†ä¼šä½¿å…¶ä¸ºä¸Šä¸‹æ–‡å‹ç¼©åŒ…ï¼Œç›´æ¥å°†å…¶å±•å¼€ï¼Œå°†é‡Œé¢è§†ä¸ºä¸Šä¸‹æ–‡ï¼Œå¹¶å¼€å§‹æ„å»ºã€‚ 6 Dockerfile æŒ‡ä»¤è¯¦è§£æˆ‘ä»¬å·²ç»ä»‹ç»äº† FROMï¼ŒRUNï¼Œè¿˜æåŠäº† COPY, ADDï¼Œå…¶å® Dockerfile åŠŸèƒ½å¾ˆå¼ºå¤§ï¼Œå®ƒæä¾›äº†åå¤šä¸ªæŒ‡ä»¤ã€‚ä¸‹é¢æˆ‘ä»¬ç»§ç»­è®²è§£å…¶ä»–çš„æŒ‡ä»¤ã€‚ Docker é•œåƒç”±å¤šä¸ªåªè¯»å±‚ç»„æˆï¼Œæ¯ä¸ªå±‚éƒ½å¯¹åº” Dockerfile ä¸­çš„ä¸€ä¸ªæŒ‡ä»¤ã€‚ä»¥ä¸‹è¿™äº› Dockerfile æŒ‡ä»¤å°†ä¼šåˆ›å»ºæ–°çš„å±‚ï¼š RUNï¼šæ¯ä¸ª RUN å‘½ä»¤éƒ½ä¼šåœ¨é•œåƒä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„å±‚ã€‚ç”±äºè¿™è®©é•œåƒå˜å¾—è¾ƒå¤§ï¼Œå› æ­¤å¸¸å¸¸ä¼šçœ‹åˆ°å¤šä¸ª RUN å‘½ä»¤é“¾åœ¨ä¸€èµ·ä»¥å‡å°‘åˆ›å»ºçš„å±‚æ•°ã€‚ COPYï¼šCOPY æŒ‡ä»¤ä¼šå°†æ–‡ä»¶æˆ–ç›®å½•ä» Docker æ„å»ºä¸Šä¸‹æ–‡å¤åˆ¶åˆ°æ–°çš„ä¸€å±‚ä¸Šï¼Œç„¶åå°†å®ƒä»¬æ·»åŠ åˆ° Dockerfile ä¸­æ‰€æŒ‡å®šçš„è·¯å¾„ã€‚ ADDï¼šå°±åƒ COPY ä¸€æ ·, ADD æŒ‡ä»¤ä¼šåœ¨ä¸€ä¸ªæ–°çš„å±‚ä¸Šå¤åˆ¶æ–‡ä»¶ï¼Œå¹¶å¯¹æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯å‹ç¼©çš„è¯ï¼Œä¼šè¿›è¡Œè‡ªåŠ¨è§£å‹ç¼©ï¼‰è¿›è¡Œæå–ã€‚å¦ä¸€æ–¹é¢ï¼Œç”±äº ADD å‘½ä»¤æœ‰äº›é¢å¤–çš„åŠŸèƒ½ï¼ˆæ¯”å¦‚èƒ½ä¸‹è½½è¿œç¨‹çš„ URLsï¼‰ï¼Œé€šå¸¸å»ºè®®åœ¨æ–‡ä»¶å¤åˆ¶æ—¶å°½é‡ä½¿ç”¨ COPYã€‚ WORKDIRï¼šå¦‚æœæŒ‡å®šçš„å·¥ä½œç›®å½•ä¸å­˜åœ¨ï¼Œè¿™ä¸ªå‘½ä»¤å°†ä¼šåˆ›å»ºè¯¥ç›®å½•ï¼Œå¹¶åœ¨æ–°çš„å±‚ä¸Šåˆ›å»ºã€‚ VOLUME: æ­¤å‘½ä»¤ä¹Ÿä¼šåœ¨ Docker é•œåƒä¸­åˆ›å»ºæ–°çš„å±‚ã€‚ USERï¼šæ­¤å‘½ä»¤ç”¨äºè®¾å®šä¸‹ä¸€æ¡ RUN, CMD, ENTRYPOINT æŒ‡ä»¤è¿è¡Œæ—¶çš„ UIDã€‚ LABELï¼šæ­¤å‘½ä»¤æ·»åŠ å…ƒæ•°æ®åˆ°é•œåƒï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„å±‚ã€‚ è™½ç„¶ ENTRYPOINT å’Œ CMD æŒ‡å®šäº†å®¹å™¨çš„é»˜è®¤æ‰§è¡Œå‘½ä»¤ï¼Œä½†å®ƒä»¬ä¸ä¼šåˆ›å»ºæ–°çš„å±‚ï¼Œå› ä¸ºå®ƒä»¬ä¸ä¼šæ”¹å˜é•œåƒçš„æ–‡ä»¶ç³»ç»Ÿã€‚åŒæ ·ï¼ŒENV æŒ‡ä»¤ç”¨æ¥è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œä¹Ÿä¸ä¼šåˆ›å»ºæ–°çš„é•œåƒå±‚ã€‚ è¿™å°±æ˜¯ Dockerfile ä¸­ç”¨æ¥åˆ›å»ºæ–°å±‚çš„ä¸»è¦æŒ‡ä»¤, ä½¿ç”¨åˆç†å¯æœ‰æ•ˆæ”¹è¿›åˆ›å»ºçš„ Docker é•œåƒçš„å¤§å°å’Œæ„å»ºæ—¶é—´ã€‚ 6.1 COPY å¤åˆ¶æ–‡ä»¶æ ¼å¼ï¼š COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;æºè·¯å¾„&gt;... &lt;ç›®æ ‡è·¯å¾„&gt; COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;æºè·¯å¾„1&gt;&quot;,... &quot;&lt;ç›®æ ‡è·¯å¾„&gt;&quot;] å’Œ RUN æŒ‡ä»¤ä¸€æ ·ï¼Œä¹Ÿæœ‰ä¸¤ç§æ ¼å¼ï¼Œä¸€ç§ç±»ä¼¼äºå‘½ä»¤è¡Œï¼Œä¸€ç§ç±»ä¼¼äºå‡½æ•°è°ƒç”¨ã€‚ COPY æŒ‡ä»¤å°†ä»æ„å»ºä¸Šä¸‹æ–‡ç›®å½•ä¸­ &lt;æºè·¯å¾„&gt; çš„æ–‡ä»¶&#x2F;ç›®å½•å¤åˆ¶åˆ°æ–°çš„ä¸€å±‚çš„é•œåƒå†…çš„ &lt;ç›®æ ‡è·¯å¾„&gt; ä½ç½®ã€‚æ¯”å¦‚ï¼š 1COPY package.json /usr/src/app/ &lt;æºè·¯å¾„&gt; å¯ä»¥æ˜¯å¤šä¸ªï¼Œç”šè‡³å¯ä»¥æ˜¯é€šé…ç¬¦ï¼Œå…¶é€šé…ç¬¦è§„åˆ™è¦æ»¡è¶³ Go çš„ filepath.Match è§„åˆ™ï¼Œå¦‚ï¼š 12COPY hom* /mydir/COPY hom?.txt /mydir/ &lt;ç›®æ ‡è·¯å¾„&gt; å¯ä»¥æ˜¯å®¹å™¨å†…çš„ç»å¯¹è·¯å¾„ï¼Œä¹Ÿå¯ä»¥æ˜¯ç›¸å¯¹äºå·¥ä½œç›®å½•çš„ç›¸å¯¹è·¯å¾„ï¼ˆå·¥ä½œç›®å½•å¯ä»¥ç”¨ WORKDIR æŒ‡ä»¤æ¥æŒ‡å®šï¼‰ã€‚ç›®æ ‡è·¯å¾„ä¸éœ€è¦äº‹å…ˆåˆ›å»ºï¼Œå¦‚æœç›®å½•ä¸å­˜åœ¨ä¼šåœ¨å¤åˆ¶æ–‡ä»¶å‰å…ˆè¡Œåˆ›å»ºç¼ºå¤±ç›®å½•ã€‚ æ­¤å¤–ï¼Œè¿˜éœ€è¦æ³¨æ„ä¸€ç‚¹ï¼Œä½¿ç”¨ COPY æŒ‡ä»¤ï¼Œæºæ–‡ä»¶çš„å„ç§å…ƒæ•°æ®éƒ½ä¼šä¿ç•™ã€‚æ¯”å¦‚è¯»ã€å†™ã€æ‰§è¡Œæƒé™ã€æ–‡ä»¶å˜æ›´æ—¶é—´ç­‰ã€‚è¿™ä¸ªç‰¹æ€§å¯¹äºé•œåƒå®šåˆ¶å¾ˆæœ‰ç”¨ã€‚ç‰¹åˆ«æ˜¯æ„å»ºç›¸å…³æ–‡ä»¶éƒ½åœ¨ä½¿ç”¨ Git è¿›è¡Œç®¡ç†çš„æ—¶å€™ã€‚ åœ¨ä½¿ç”¨è¯¥æŒ‡ä»¤çš„æ—¶å€™è¿˜å¯ä»¥åŠ ä¸Š --chown=&lt;user&gt;:&lt;group&gt; é€‰é¡¹æ¥æ”¹å˜æ–‡ä»¶çš„æ‰€å±ç”¨æˆ·åŠæ‰€å±ç»„ã€‚ 1234COPY --chown=55:mygroup files* /mydir/COPY --chown=bin files* /mydir/COPY --chown=1 files* /mydir/COPY --chown=10:11 files* /mydir/ å¦‚æœæºè·¯å¾„ä¸ºæ–‡ä»¶å¤¹ï¼Œå¤åˆ¶çš„æ—¶å€™ä¸æ˜¯ç›´æ¥å¤åˆ¶è¯¥æ–‡ä»¶å¤¹ï¼Œè€Œæ˜¯å°†æ–‡ä»¶å¤¹ä¸­çš„å†…å®¹å¤åˆ¶åˆ°ç›®æ ‡è·¯å¾„ã€‚ 6.2 ADD æ›´é«˜çº§çš„å¤åˆ¶æ–‡ä»¶ADD æŒ‡ä»¤å’Œ COPY çš„æ ¼å¼å’Œæ€§è´¨åŸºæœ¬ä¸€è‡´ã€‚ä½†æ˜¯åœ¨ COPY åŸºç¡€ä¸Šå¢åŠ äº†ä¸€äº›åŠŸèƒ½ã€‚ æ¯”å¦‚ &lt;æºè·¯å¾„&gt; å¯ä»¥æ˜¯ä¸€ä¸ª URLï¼Œè¿™ç§æƒ…å†µä¸‹ï¼ŒDocker å¼•æ“ä¼šè¯•å›¾å»ä¸‹è½½è¿™ä¸ªé“¾æ¥çš„æ–‡ä»¶æ”¾åˆ° &lt;ç›®æ ‡è·¯å¾„&gt; å»ã€‚ä¸‹è½½åçš„æ–‡ä»¶æƒé™è‡ªåŠ¨è®¾ç½®ä¸º 600ï¼Œå¦‚æœè¿™å¹¶ä¸æ˜¯æƒ³è¦çš„æƒé™ï¼Œé‚£ä¹ˆè¿˜éœ€è¦å¢åŠ é¢å¤–çš„ä¸€å±‚ RUN è¿›è¡Œæƒé™è°ƒæ•´ï¼Œå¦å¤–ï¼Œå¦‚æœä¸‹è½½çš„æ˜¯ä¸ªå‹ç¼©åŒ…ï¼Œéœ€è¦è§£å‹ç¼©ï¼Œä¹Ÿä¸€æ ·è¿˜éœ€è¦é¢å¤–çš„ä¸€å±‚ RUN æŒ‡ä»¤è¿›è¡Œè§£å‹ç¼©ã€‚æ‰€ä»¥ä¸å¦‚ç›´æ¥ä½¿ç”¨ RUN æŒ‡ä»¤ï¼Œç„¶åä½¿ç”¨ wget æˆ–è€… curl å·¥å…·ä¸‹è½½ï¼Œå¤„ç†æƒé™ã€è§£å‹ç¼©ã€ç„¶åæ¸…ç†æ— ç”¨æ–‡ä»¶æ›´åˆç†ã€‚å› æ­¤ï¼Œè¿™ä¸ªåŠŸèƒ½å…¶å®å¹¶ä¸å®ç”¨ï¼Œè€Œä¸”ä¸æ¨èä½¿ç”¨ã€‚ å¦‚æœ &lt;æºè·¯å¾„&gt; ä¸ºä¸€ä¸ª tar å‹ç¼©æ–‡ä»¶çš„è¯ï¼Œå‹ç¼©æ ¼å¼ä¸º gzip, bzip2 ä»¥åŠ xz çš„æƒ…å†µä¸‹ï¼ŒADD æŒ‡ä»¤å°†ä¼šè‡ªåŠ¨è§£å‹ç¼©è¿™ä¸ªå‹ç¼©æ–‡ä»¶åˆ° &lt;ç›®æ ‡è·¯å¾„&gt; å»ã€‚ åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¿™ä¸ªè‡ªåŠ¨è§£å‹ç¼©çš„åŠŸèƒ½éå¸¸æœ‰ç”¨ï¼Œæ¯”å¦‚å®˜æ–¹é•œåƒ ubuntu ä¸­ï¼š 123FROM scratchADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /... ä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¦‚æœæˆ‘ä»¬çœŸçš„æ˜¯å¸Œæœ›å¤åˆ¶ä¸ªå‹ç¼©æ–‡ä»¶è¿›å»ï¼Œè€Œä¸è§£å‹ç¼©ï¼Œè¿™æ—¶å°±ä¸å¯ä»¥ä½¿ç”¨ ADD å‘½ä»¤äº†ã€‚ åœ¨ Docker å®˜æ–¹çš„ Dockerfile æœ€ä½³å®è·µæ–‡æ¡£ ä¸­è¦æ±‚ï¼Œå°½å¯èƒ½çš„ä½¿ç”¨ COPYï¼Œå› ä¸º COPY çš„è¯­ä¹‰å¾ˆæ˜ç¡®ï¼Œå°±æ˜¯å¤åˆ¶æ–‡ä»¶è€Œå·²ï¼Œè€Œ ADD åˆ™åŒ…å«äº†æ›´å¤æ‚çš„åŠŸèƒ½ï¼Œå…¶è¡Œä¸ºä¹Ÿä¸ä¸€å®šå¾ˆæ¸…æ™°ã€‚æœ€é€‚åˆä½¿ç”¨ ADD çš„åœºåˆï¼Œå°±æ˜¯æ‰€æåŠçš„éœ€è¦è‡ªåŠ¨è§£å‹ç¼©çš„åœºåˆã€‚ å¦å¤–éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒADD æŒ‡ä»¤ä¼šä»¤é•œåƒæ„å»ºç¼“å­˜å¤±æ•ˆï¼Œä»è€Œå¯èƒ½ä¼šä»¤é•œåƒæ„å»ºå˜å¾—æ¯”è¾ƒç¼“æ…¢ã€‚ å› æ­¤åœ¨ COPY å’Œ ADD æŒ‡ä»¤ä¸­é€‰æ‹©çš„æ—¶å€™ï¼Œå¯ä»¥éµå¾ªè¿™æ ·çš„åŸåˆ™ï¼Œæ‰€æœ‰çš„æ–‡ä»¶å¤åˆ¶å‡ä½¿ç”¨ COPY æŒ‡ä»¤ï¼Œä»…åœ¨éœ€è¦è‡ªåŠ¨è§£å‹ç¼©çš„åœºåˆä½¿ç”¨ ADDã€‚ åœ¨ä½¿ç”¨è¯¥æŒ‡ä»¤çš„æ—¶å€™è¿˜å¯ä»¥åŠ ä¸Š --chown=&lt;user&gt;:&lt;group&gt; é€‰é¡¹æ¥æ”¹å˜æ–‡ä»¶çš„æ‰€å±ç”¨æˆ·åŠæ‰€å±ç»„ã€‚ 1234ADD --chown=55:mygroup files* /mydir/ADD --chown=bin files* /mydir/ADD --chown=1 files* /mydir/ADD --chown=10:11 files* /mydir/ 6.3 CMD å®¹å™¨å¯åŠ¨å‘½ä»¤CMD æŒ‡ä»¤çš„æ ¼å¼å’Œ RUN ç›¸ä¼¼ï¼Œä¹Ÿæ˜¯ä¸¤ç§æ ¼å¼ï¼š shell æ ¼å¼ï¼šCMD &lt;å‘½ä»¤&gt; exec æ ¼å¼ï¼šCMD [&quot;å¯æ‰§è¡Œæ–‡ä»¶&quot;, &quot;å‚æ•°1&quot;, &quot;å‚æ•°2&quot;...] å‚æ•°åˆ—è¡¨æ ¼å¼ï¼šCMD [&quot;å‚æ•°1&quot;, &quot;å‚æ•°2&quot;...]ã€‚åœ¨æŒ‡å®šäº† ENTRYPOINT æŒ‡ä»¤åï¼Œç”¨ CMD æŒ‡å®šå…·ä½“çš„å‚æ•°ã€‚ ä¹‹å‰ä»‹ç»å®¹å™¨çš„æ—¶å€™æ›¾ç»è¯´è¿‡ï¼ŒDocker ä¸æ˜¯è™šæ‹Ÿæœºï¼Œå®¹å™¨å°±æ˜¯è¿›ç¨‹ã€‚æ—¢ç„¶æ˜¯è¿›ç¨‹ï¼Œé‚£ä¹ˆåœ¨å¯åŠ¨å®¹å™¨çš„æ—¶å€™ï¼Œéœ€è¦æŒ‡å®šæ‰€è¿è¡Œçš„ç¨‹åºåŠå‚æ•°ã€‚**CMD æŒ‡ä»¤å°±æ˜¯ç”¨äºæŒ‡å®šé»˜è®¤çš„å®¹å™¨ä¸»è¿›ç¨‹çš„å¯åŠ¨å‘½ä»¤çš„**ã€‚ åœ¨è¿è¡Œæ—¶å¯ä»¥æŒ‡å®šæ–°çš„å‘½ä»¤æ¥æ›¿ä»£é•œåƒè®¾ç½®ä¸­çš„è¿™ä¸ªé»˜è®¤å‘½ä»¤ï¼Œæ¯”å¦‚ï¼Œubuntu é•œåƒé»˜è®¤çš„ CMD æ˜¯ /bin/bashï¼Œå¦‚æœæˆ‘ä»¬ç›´æ¥ docker run -it ubuntu çš„è¯ï¼Œä¼šç›´æ¥è¿›å…¥ bashã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨è¿è¡Œæ—¶æŒ‡å®šè¿è¡Œåˆ«çš„å‘½ä»¤ï¼Œå¦‚ docker run -it ubuntu cat /etc/os-releaseã€‚è¿™å°±æ˜¯ç”¨ cat /etc/os-release å‘½ä»¤æ›¿æ¢äº†é»˜è®¤çš„ /bin/bash å‘½ä»¤äº†ï¼Œè¾“å‡ºäº†ç³»ç»Ÿç‰ˆæœ¬ä¿¡æ¯ã€‚ åœ¨æŒ‡ä»¤æ ¼å¼ä¸Šï¼Œä¸€èˆ¬æ¨èä½¿ç”¨ exec æ ¼å¼ï¼Œè¿™ç±»æ ¼å¼åœ¨è§£ææ—¶ä¼šè¢«è§£æä¸º JSON æ•°ç»„ï¼Œå› æ­¤ä¸€å®šè¦ä½¿ç”¨åŒå¼•å· &quot;ï¼Œè€Œä¸è¦ä½¿ç”¨å•å¼•å·ã€‚ å¦‚æœä½¿ç”¨ shell æ ¼å¼çš„è¯ï¼Œå®é™…çš„å‘½ä»¤ä¼šè¢«åŒ…è£…ä¸º sh -c çš„å‚æ•°çš„å½¢å¼è¿›è¡Œæ‰§è¡Œã€‚æ¯”å¦‚ï¼š 1CMD echo $HOME åœ¨å®é™…æ‰§è¡Œä¸­ï¼Œä¼šå°†å…¶å˜æ›´ä¸ºï¼š 1CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡çš„åŸå› ï¼Œå› ä¸ºè¿™äº›ç¯å¢ƒå˜é‡ä¼šè¢« shell è¿›è¡Œè§£æå¤„ç†ã€‚ æåˆ° CMD å°±ä¸å¾—ä¸æå®¹å™¨ä¸­åº”ç”¨åœ¨å‰å°æ‰§è¡Œå’Œåå°æ‰§è¡Œçš„é—®é¢˜ã€‚è¿™æ˜¯åˆå­¦è€…å¸¸å‡ºç°çš„ä¸€ä¸ªæ··æ·†ã€‚ Docker ä¸æ˜¯è™šæ‹Ÿæœºï¼Œå®¹å™¨ä¸­çš„åº”ç”¨éƒ½åº”è¯¥ä»¥å‰å°æ‰§è¡Œï¼Œè€Œä¸æ˜¯åƒè™šæ‹Ÿæœºã€ç‰©ç†æœºé‡Œé¢é‚£æ ·ï¼Œç”¨ systemd å»å¯åŠ¨åå°æœåŠ¡ï¼Œå®¹å™¨å†…æ²¡æœ‰åå°æœåŠ¡çš„æ¦‚å¿µã€‚ ä¸€äº›åˆå­¦è€…å°† CMD å†™ä¸ºï¼š 1CMD service nginx start ç„¶åå‘ç°å®¹å™¨æ‰§è¡Œåå°±ç«‹å³é€€å‡ºäº†ã€‚ç”šè‡³åœ¨å®¹å™¨å†…å»ä½¿ç”¨ systemctl å‘½ä»¤ç»“æœå´å‘ç°æ ¹æœ¬æ‰§è¡Œä¸äº†ã€‚è¿™å°±æ˜¯å› ä¸ºæ²¡æœ‰ææ˜ç™½å‰å°ã€åå°çš„æ¦‚å¿µï¼Œæ²¡æœ‰åŒºåˆ†å®¹å™¨å’Œè™šæ‹Ÿæœºçš„å·®å¼‚ï¼Œä¾æ—§åœ¨ä»¥ä¼ ç»Ÿè™šæ‹Ÿæœºçš„è§’åº¦å»ç†è§£å®¹å™¨ã€‚ å¯¹äºå®¹å™¨è€Œè¨€ï¼Œå…¶å¯åŠ¨ç¨‹åºå°±æ˜¯å®¹å™¨åº”ç”¨è¿›ç¨‹ï¼Œå®¹å™¨å°±æ˜¯ä¸ºäº†ä¸»è¿›ç¨‹è€Œå­˜åœ¨çš„ï¼Œä¸»è¿›ç¨‹é€€å‡ºï¼Œå®¹å™¨å°±å¤±å»äº†å­˜åœ¨çš„æ„ä¹‰ï¼Œä»è€Œé€€å‡ºï¼Œå…¶å®ƒè¾…åŠ©è¿›ç¨‹ä¸æ˜¯å®ƒéœ€è¦å…³å¿ƒçš„ä¸œè¥¿ã€‚ è€Œä½¿ç”¨ service nginx start å‘½ä»¤ï¼Œåˆ™æ˜¯å¸Œæœ› init ç³»ç»Ÿä»¥åå°å®ˆæŠ¤è¿›ç¨‹çš„å½¢å¼å¯åŠ¨ nginx æœåŠ¡ã€‚è€Œåˆšæ‰è¯´äº† CMD service nginx start ä¼šè¢«ç†è§£ä¸º CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;]ï¼Œå› æ­¤ä¸»è¿›ç¨‹å®é™…ä¸Šæ˜¯ shã€‚é‚£ä¹ˆå½“ service nginx start å‘½ä»¤ç»“æŸåï¼Œsh ä¹Ÿå°±ç»“æŸäº†ï¼Œsh ä½œä¸ºä¸»è¿›ç¨‹é€€å‡ºäº†ï¼Œè‡ªç„¶å°±ä¼šä»¤å®¹å™¨é€€å‡ºã€‚ æ­£ç¡®çš„åšæ³•æ˜¯ç›´æ¥æ‰§è¡Œ nginx å¯æ‰§è¡Œæ–‡ä»¶ï¼Œå¹¶ä¸”è¦æ±‚ä»¥å‰å°å½¢å¼è¿è¡Œã€‚æ¯”å¦‚ï¼š 1CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 6.4 ENTRYPOINT å…¥å£ç‚¹ENTRYPOINT çš„æ ¼å¼å’Œ RUN æŒ‡ä»¤æ ¼å¼ä¸€æ ·ï¼Œåˆ†ä¸º exec æ ¼å¼å’Œ shell æ ¼å¼ã€‚ ENTRYPOINT çš„ç›®çš„å’Œ CMD ä¸€æ ·ï¼Œéƒ½æ˜¯åœ¨æŒ‡å®šå®¹å™¨å¯åŠ¨ç¨‹åºåŠå‚æ•°ã€‚**ENTRYPOINT åœ¨è¿è¡Œæ—¶ä¹Ÿå¯ä»¥æ›¿ä»£ï¼Œä¸è¿‡æ¯” CMD è¦ç•¥æ˜¾ç¹çï¼Œéœ€è¦é€šè¿‡ docker run çš„å‚æ•° --entrypoint æ¥æŒ‡å®š**ã€‚ å½“æŒ‡å®šäº† ENTRYPOINT åï¼ŒCMD çš„å«ä¹‰å°±å‘ç”Ÿäº†æ”¹å˜ï¼Œä¸å†æ˜¯ç›´æ¥çš„è¿è¡Œå…¶å‘½ä»¤ï¼Œè€Œæ˜¯å°† CMD çš„å†…å®¹ä½œä¸ºå‚æ•°ä¼ ç»™ ENTRYPOINT æŒ‡ä»¤ï¼Œæ¢å¥è¯è¯´å®é™…æ‰§è¡Œæ—¶ï¼Œå°†å˜ä¸ºï¼š 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; é‚£ä¹ˆæœ‰äº† CMD åï¼Œä¸ºä»€ä¹ˆè¿˜è¦æœ‰ ENTRYPOINT å‘¢ï¼Ÿè¿™ç§ &lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; æœ‰ä»€ä¹ˆå¥½å¤„ä¹ˆï¼Ÿè®©æˆ‘ä»¬æ¥çœ‹å‡ ä¸ªåœºæ™¯ã€‚ åœºæ™¯ä¸€ï¼šè®©é•œåƒå˜æˆåƒå‘½ä»¤ä¸€æ ·ä½¿ç”¨å‡è®¾æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¾—çŸ¥è‡ªå·±å½“å‰å…¬ç½‘ IP çš„é•œåƒï¼Œé‚£ä¹ˆå¯ä»¥å…ˆç”¨ CMD æ¥å®ç°ï¼š 12345FROM ubuntu:18.04RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://myip.ipip.net&quot; ] å‡å¦‚æˆ‘ä»¬ä½¿ç”¨ docker build -t myip . æ¥æ„å»ºé•œåƒçš„è¯ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦æŸ¥è¯¢å½“å‰å…¬ç½‘ IPï¼Œåªéœ€è¦æ‰§è¡Œï¼š 12$ docker run myipå½“å‰ IPï¼š61.148.226.66 æ¥è‡ªï¼šåŒ—äº¬å¸‚ è”é€š å—¯ï¼Œè¿™ä¹ˆçœ‹èµ·æ¥å¥½åƒå¯ä»¥ç›´æ¥æŠŠé•œåƒå½“åšå‘½ä»¤ä½¿ç”¨äº†ï¼Œä¸è¿‡å‘½ä»¤æ€»æœ‰å‚æ•°ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›åŠ å‚æ•°å‘¢ï¼Ÿæ¯”å¦‚ä»ä¸Šé¢çš„ CMD ä¸­å¯ä»¥çœ‹åˆ°å®è´¨çš„å‘½ä»¤æ˜¯ curlï¼Œé‚£ä¹ˆå¦‚æœæˆ‘ä»¬å¸Œæœ›æ˜¾ç¤º HTTP å¤´ä¿¡æ¯ï¼Œå°±éœ€è¦åŠ ä¸Š -i å‚æ•°ã€‚é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ç›´æ¥åŠ  -i å‚æ•°ç»™ docker run myip ä¹ˆï¼Ÿ 12$ docker run myip -idocker: Error response from daemon: invalid header field value &quot;oci runtime error: container_linux.go:247: starting container process caused \\&quot;exec: \\\\\\&quot;-i\\\\\\&quot;: executable file not found in $PATH\\&quot;\\n&quot;. æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¯æ‰§è¡Œæ–‡ä»¶æ‰¾ä¸åˆ°çš„æŠ¥é”™ï¼Œexecutable file not foundã€‚ä¹‹å‰æˆ‘ä»¬è¯´è¿‡ï¼Œè·Ÿåœ¨é•œåƒååé¢çš„æ˜¯ commandï¼Œè¿è¡Œæ—¶ä¼šæ›¿æ¢ CMD çš„é»˜è®¤å€¼ã€‚å› æ­¤è¿™é‡Œçš„ -i æ›¿æ¢äº†åŸæ¥çš„ CMDï¼Œè€Œä¸æ˜¯æ·»åŠ åœ¨åŸæ¥çš„ curl -s http://myip.ipip.net åé¢ã€‚è€Œ -i æ ¹æœ¬ä¸æ˜¯å‘½ä»¤ï¼Œæ‰€ä»¥è‡ªç„¶æ‰¾ä¸åˆ°ã€‚ é‚£ä¹ˆå¦‚æœæˆ‘ä»¬å¸Œæœ›åŠ å…¥ -i è¿™å‚æ•°ï¼Œæˆ‘ä»¬å°±å¿…é¡»é‡æ–°å®Œæ•´çš„è¾“å…¥è¿™ä¸ªå‘½ä»¤ï¼š 1$ docker run myip curl -s http://myip.ipip.net -i è¿™æ˜¾ç„¶ä¸æ˜¯å¾ˆå¥½çš„è§£å†³æ–¹æ¡ˆï¼Œè€Œä½¿ç”¨ ENTRYPOINT å°±å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç°åœ¨æˆ‘ä»¬é‡æ–°ç”¨ ENTRYPOINT æ¥å®ç°è¿™ä¸ªé•œåƒï¼š 12345FROM ubuntu:18.04RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://myip.ipip.net&quot; ] è¿™æ¬¡æˆ‘ä»¬å†æ¥å°è¯•ç›´æ¥ä½¿ç”¨ docker run myip -iï¼š 123456789101112131415161718$ docker run myipå½“å‰ IPï¼š61.148.226.66 æ¥è‡ªï¼šåŒ—äº¬å¸‚ è”é€š$ docker run myip -iHTTP/1.1 200 OKServer: nginx/1.8.0Date: Tue, 22 Nov 2016 05:12:40 GMTContent-Type: text/html; charset=UTF-8Vary: Accept-EncodingX-Powered-By: PHP/5.6.24-1~dotdeb+7.1X-Cache: MISS from cache-2X-Cache-Lookup: MISS from cache-2:80X-Cache: MISS from proxy-2_6Transfer-Encoding: chunkedVia: 1.1 cache-2:80, 1.1 proxy-2_6:8006Connection: keep-aliveå½“å‰ IPï¼š61.148.226.66 æ¥è‡ªï¼šåŒ—äº¬å¸‚ è”é€š å¯ä»¥çœ‹åˆ°ï¼Œè¿™æ¬¡æˆåŠŸäº†ã€‚è¿™æ˜¯å› ä¸ºå½“å­˜åœ¨ ENTRYPOINT åï¼ŒCMD çš„å†…å®¹å°†ä¼šä½œä¸ºå‚æ•°ä¼ ç»™ ENTRYPOINTï¼Œè€Œè¿™é‡Œ -i å°±æ˜¯æ–°çš„ CMDï¼Œå› æ­¤ä¼šä½œä¸ºå‚æ•°ä¼ ç»™ curlï¼Œä»è€Œè¾¾åˆ°äº†æˆ‘ä»¬é¢„æœŸçš„æ•ˆæœã€‚ åœºæ™¯äºŒï¼šåº”ç”¨è¿è¡Œå‰çš„å‡†å¤‡å·¥ä½œå¯åŠ¨å®¹å™¨å°±æ˜¯å¯åŠ¨ä¸»è¿›ç¨‹ï¼Œä½†æœ‰äº›æ—¶å€™ï¼Œå¯åŠ¨ä¸»è¿›ç¨‹å‰ï¼Œéœ€è¦ä¸€äº›å‡†å¤‡å·¥ä½œã€‚ æ¯”å¦‚ mysql ç±»çš„æ•°æ®åº“ï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ•°æ®åº“é…ç½®ã€åˆå§‹åŒ–çš„å·¥ä½œï¼Œè¿™äº›å·¥ä½œè¦åœ¨æœ€ç»ˆçš„ mysql æœåŠ¡å™¨è¿è¡Œä¹‹å‰è§£å†³ã€‚ æ­¤å¤–ï¼Œå¯èƒ½å¸Œæœ›é¿å…ä½¿ç”¨ root ç”¨æˆ·å»å¯åŠ¨æœåŠ¡ï¼Œä»è€Œæé«˜å®‰å…¨æ€§ï¼Œè€Œåœ¨å¯åŠ¨æœåŠ¡å‰è¿˜éœ€è¦ä»¥ root èº«ä»½æ‰§è¡Œä¸€äº›å¿…è¦çš„å‡†å¤‡å·¥ä½œï¼Œæœ€ååˆ‡æ¢åˆ°æœåŠ¡ç”¨æˆ·èº«ä»½å¯åŠ¨æœåŠ¡ã€‚æˆ–è€…é™¤äº†æœåŠ¡å¤–ï¼Œå…¶å®ƒå‘½ä»¤ä¾æ—§å¯ä»¥ä½¿ç”¨ root èº«ä»½æ‰§è¡Œï¼Œæ–¹ä¾¿è°ƒè¯•ç­‰ã€‚ è¿™äº›å‡†å¤‡å·¥ä½œæ˜¯å’Œå®¹å™¨ CMD æ— å…³çš„ï¼Œæ— è®º CMD ä¸ºä»€ä¹ˆï¼Œéƒ½éœ€è¦äº‹å…ˆè¿›è¡Œä¸€ä¸ªé¢„å¤„ç†çš„å·¥ä½œã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥å†™ä¸€ä¸ªè„šæœ¬ï¼Œç„¶åæ”¾å…¥ ENTRYPOINT ä¸­å»æ‰§è¡Œï¼Œè€Œè¿™ä¸ªè„šæœ¬ä¼šå°†æ¥åˆ°çš„å‚æ•°ï¼ˆä¹Ÿå°±æ˜¯ &lt;CMD&gt;ï¼‰ä½œä¸ºå‘½ä»¤ï¼Œåœ¨è„šæœ¬æœ€åæ‰§è¡Œã€‚æ¯”å¦‚å®˜æ–¹é•œåƒ redis ä¸­å°±æ˜¯è¿™ä¹ˆåšçš„ï¼š 12345678FROM alpine:3.4...RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis...ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]EXPOSE 6379CMD [ &quot;redis-server&quot; ] å¯ä»¥çœ‹åˆ°å…¶ä¸­ä¸ºäº† redis æœåŠ¡åˆ›å»ºäº† redis ç”¨æˆ·ï¼Œå¹¶åœ¨æœ€åæŒ‡å®šäº† ENTRYPOINT ä¸º docker-entrypoint.sh è„šæœ¬ã€‚ 123456789#!/bin/sh...# allow the container to be started with `--user`if [ &quot;$1&quot; = &#x27;redis-server&#x27; -a &quot;$(id -u)&quot; = &#x27;0&#x27; ]; then find . \\! -user redis -exec chown redis &#x27;&#123;&#125;&#x27; + exec gosu redis &quot;$0&quot; &quot;$@&quot;fiexec &quot;$@&quot; è¯¥è„šæœ¬çš„å†…å®¹å°±æ˜¯æ ¹æ® CMD çš„å†…å®¹æ¥åˆ¤æ–­ï¼Œå¦‚æœæ˜¯ redis-server çš„è¯ï¼Œåˆ™åˆ‡æ¢åˆ° redis ç”¨æˆ·èº«ä»½å¯åŠ¨æœåŠ¡å™¨ï¼Œå¦åˆ™ä¾æ—§ä½¿ç”¨ root èº«ä»½æ‰§è¡Œã€‚æ¯”å¦‚ï¼š 12$ docker run -it redis iduid=0(root) gid=0(root) groups=0(root) 6.5 ENV è®¾ç½®ç¯å¢ƒå˜é‡æ ¼å¼æœ‰ä¸¤ç§ï¼š ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... è¿™ä¸ªæŒ‡ä»¤å¾ˆç®€å•ï¼Œå°±æ˜¯è®¾ç½®ç¯å¢ƒå˜é‡è€Œå·²ï¼Œæ— è®ºæ˜¯åé¢çš„å…¶å®ƒæŒ‡ä»¤ï¼Œå¦‚ RUNï¼Œè¿˜æ˜¯è¿è¡Œæ—¶çš„åº”ç”¨ï¼Œéƒ½å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™é‡Œå®šä¹‰çš„ç¯å¢ƒå˜é‡ã€‚ 12ENV VERSION=1.0 DEBUG=on \\ NAME=&quot;Happy Feet&quot; è¿™ä¸ªä¾‹å­ä¸­æ¼”ç¤ºäº†å¦‚ä½•æ¢è¡Œï¼Œä»¥åŠå¯¹å«æœ‰ç©ºæ ¼çš„å€¼ç”¨åŒå¼•å·æ‹¬èµ·æ¥çš„åŠæ³•ï¼Œè¿™å’Œ Shell ä¸‹çš„è¡Œä¸ºæ˜¯ä¸€è‡´çš„ã€‚ å®šä¹‰äº†ç¯å¢ƒå˜é‡ï¼Œé‚£ä¹ˆåœ¨åç»­çš„æŒ‡ä»¤ä¸­ï¼Œå°±å¯ä»¥ä½¿ç”¨è¿™ä¸ªç¯å¢ƒå˜é‡ã€‚æ¯”å¦‚åœ¨å®˜æ–¹ node é•œåƒ Dockerfile ä¸­ï¼Œå°±æœ‰ç±»ä¼¼è¿™æ ·çš„ä»£ç ï¼š 123456789ENV NODE_VERSION 7.2.0RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\ &amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; \\ &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\ &amp;&amp; grep &quot; node-v$NODE_VERSION-linux-x64.tar.xz\\$&quot; SHASUMS256.txt | sha256sum -c - \\ &amp;&amp; tar -xJf &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; -C /usr/local --strip-components=1 \\ &amp;&amp; rm &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; SHASUMS256.txt.asc SHASUMS256.txt \\ &amp;&amp; ln -s /usr/local/bin/node /usr/local/bin/nodejs åœ¨è¿™é‡Œå…ˆå®šä¹‰äº†ç¯å¢ƒå˜é‡ NODE_VERSIONï¼Œå…¶åçš„ RUN è¿™å±‚é‡Œï¼Œå¤šæ¬¡ä½¿ç”¨ $NODE_VERSION æ¥è¿›è¡Œæ“ä½œå®šåˆ¶ã€‚å¯ä»¥çœ‹åˆ°ï¼Œå°†æ¥å‡çº§é•œåƒæ„å»ºç‰ˆæœ¬çš„æ—¶å€™ï¼Œåªéœ€è¦æ›´æ–° 7.2.0 å³å¯ï¼ŒDockerfile æ„å»ºç»´æŠ¤å˜å¾—æ›´è½»æ¾äº†ã€‚ ä¸‹åˆ—æŒ‡ä»¤å¯ä»¥æ”¯æŒç¯å¢ƒå˜é‡å±•å¼€ï¼š ADDã€COPYã€ENVã€EXPOSEã€FROMã€LABELã€USERã€WORKDIRã€VOLUMEã€STOPSIGNALã€ONBUILDã€RUNã€‚ å¯ä»¥ä»è¿™ä¸ªæŒ‡ä»¤åˆ—è¡¨é‡Œæ„Ÿè§‰åˆ°ï¼Œç¯å¢ƒå˜é‡å¯ä»¥ä½¿ç”¨çš„åœ°æ–¹å¾ˆå¤šï¼Œå¾ˆå¼ºå¤§ã€‚é€šè¿‡ç¯å¢ƒå˜é‡ï¼Œæˆ‘ä»¬å¯ä»¥è®©ä¸€ä»½ Dockerfile åˆ¶ä½œæ›´å¤šçš„é•œåƒï¼Œåªéœ€ä½¿ç”¨ä¸åŒçš„ç¯å¢ƒå˜é‡å³å¯ã€‚ 6.6 ARG æ„å»ºå‚æ•°æ ¼å¼ï¼šARG &lt;å‚æ•°å&gt;[=&lt;é»˜è®¤å€¼&gt;] æ„å»ºå‚æ•°å’Œ ENV çš„æ•ˆæœä¸€æ ·ï¼Œéƒ½æ˜¯è®¾ç½®ç¯å¢ƒå˜é‡ã€‚æ‰€ä¸åŒçš„æ˜¯ï¼Œ**ARG æ‰€è®¾ç½®çš„æ„å»ºç¯å¢ƒçš„ç¯å¢ƒå˜é‡ï¼Œåœ¨å°†æ¥å®¹å™¨è¿è¡Œæ—¶æ˜¯ä¸ä¼šå­˜åœ¨è¿™äº›ç¯å¢ƒå˜é‡çš„ã€‚ä½†æ˜¯ä¸è¦å› æ­¤å°±ä½¿ç”¨ ARG ä¿å­˜å¯†ç ä¹‹ç±»çš„ä¿¡æ¯ï¼Œå› ä¸º docker history è¿˜æ˜¯å¯ä»¥çœ‹åˆ°æ‰€æœ‰å€¼çš„**ã€‚ Dockerfile ä¸­çš„ ARG æŒ‡ä»¤æ˜¯å®šä¹‰å‚æ•°åç§°ï¼Œä»¥åŠå®šä¹‰å…¶é»˜è®¤å€¼ã€‚è¯¥é»˜è®¤å€¼å¯ä»¥åœ¨æ„å»ºå‘½ä»¤ docker build ä¸­ç”¨ --build-arg &lt;å‚æ•°å&gt;=&lt;å€¼&gt; æ¥è¦†ç›–ã€‚ çµæ´»çš„ä½¿ç”¨ ARG æŒ‡ä»¤ï¼Œèƒ½å¤Ÿåœ¨ä¸ä¿®æ”¹ Dockerfile çš„æƒ…å†µä¸‹ï¼Œæ„å»ºå‡ºä¸åŒçš„é•œåƒã€‚ ARG æŒ‡ä»¤æœ‰ç”Ÿæ•ˆèŒƒå›´ï¼Œå¦‚æœåœ¨ FROM æŒ‡ä»¤ä¹‹å‰æŒ‡å®šï¼Œé‚£ä¹ˆåªèƒ½ç”¨äº FROM æŒ‡ä»¤ä¸­ã€‚ 12345ARG DOCKER_USERNAME=libraryFROM $&#123;DOCKER_USERNAME&#125;/alpineRUN set -x ; echo $&#123;DOCKER_USERNAME&#125; ä½¿ç”¨ä¸Šè¿° Dockerfile ä¼šå‘ç°æ— æ³•è¾“å‡º $&#123;DOCKER_USERNAME&#125; å˜é‡çš„å€¼ï¼Œè¦æƒ³æ­£å¸¸è¾“å‡ºï¼Œä½ å¿…é¡»åœ¨ FROM ä¹‹åå†æ¬¡æŒ‡å®š ARG 123456789# åªåœ¨ FROM ä¸­ç”Ÿæ•ˆARG DOCKER_USERNAME=libraryFROM $&#123;DOCKER_USERNAME&#125;/alpine# è¦æƒ³åœ¨ FROM ä¹‹åä½¿ç”¨ï¼Œå¿…é¡»å†æ¬¡æŒ‡å®šARG DOCKER_USERNAME=libraryRUN set -x ; echo $&#123;DOCKER_USERNAME&#125; å¯¹äºå¤šé˜¶æ®µæ„å»ºï¼Œå°¤å…¶è¦æ³¨æ„è¿™ä¸ªé—®é¢˜ï¼š 12345678910# è¿™ä¸ªå˜é‡åœ¨æ¯ä¸ª FROM ä¸­éƒ½ç”Ÿæ•ˆARG DOCKER_USERNAME=libraryFROM $&#123;DOCKER_USERNAME&#125;/alpineRUN set -x ; echo 1FROM $&#123;DOCKER_USERNAME&#125;/alpineRUN set -x ; echo 2 å¯¹äºä¸Šè¿° Dockerfile ä¸¤ä¸ª FROM æŒ‡ä»¤éƒ½å¯ä»¥ä½¿ç”¨ $&#123;DOCKER_USERNAME&#125;ï¼Œå¯¹äºåœ¨å„ä¸ªé˜¶æ®µä¸­ä½¿ç”¨çš„å˜é‡éƒ½å¿…é¡»åœ¨æ¯ä¸ªé˜¶æ®µåˆ†åˆ«æŒ‡å®šï¼š 123456789101112131415ARG DOCKER_USERNAME=libraryFROM $&#123;DOCKER_USERNAME&#125;/alpine# åœ¨FROM ä¹‹åä½¿ç”¨å˜é‡ï¼Œå¿…é¡»åœ¨æ¯ä¸ªé˜¶æ®µåˆ†åˆ«æŒ‡å®šARG DOCKER_USERNAME=libraryRUN set -x ; echo $&#123;DOCKER_USERNAME&#125;FROM $&#123;DOCKER_USERNAME&#125;/alpine# åœ¨FROM ä¹‹åä½¿ç”¨å˜é‡ï¼Œå¿…é¡»åœ¨æ¯ä¸ªé˜¶æ®µåˆ†åˆ«æŒ‡å®šARG DOCKER_USERNAME=libraryRUN set -x ; echo $&#123;DOCKER_USERNAME&#125; 6.7 VOLUME å®šä¹‰åŒ¿åå·æ ¼å¼ä¸ºï¼š VOLUME [&quot;&lt;è·¯å¾„1&gt;&quot;, &quot;&lt;è·¯å¾„2&gt;&quot;...] VOLUME &lt;è·¯å¾„&gt; ä¹‹å‰æˆ‘ä»¬è¯´è¿‡ï¼Œå®¹å™¨è¿è¡Œæ—¶åº”è¯¥å°½é‡ä¿æŒå®¹å™¨å­˜å‚¨å±‚ä¸å‘ç”Ÿå†™æ“ä½œï¼Œå¯¹äºæ•°æ®åº“ç±»éœ€è¦ä¿å­˜åŠ¨æ€æ•°æ®çš„åº”ç”¨ï¼Œå…¶æ•°æ®åº“æ–‡ä»¶åº”è¯¥ä¿å­˜äºå·(volume)ä¸­ï¼Œåé¢çš„ç« èŠ‚æˆ‘ä»¬ä¼šè¿›ä¸€æ­¥ä»‹ç» Docker å·çš„æ¦‚å¿µã€‚ä¸ºäº†é˜²æ­¢è¿è¡Œæ—¶ç”¨æˆ·å¿˜è®°å°†åŠ¨æ€æ–‡ä»¶æ‰€ä¿å­˜ç›®å½•æŒ‚è½½ä¸ºå·ï¼Œåœ¨ Dockerfile ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥äº‹å…ˆæŒ‡å®šæŸäº›ç›®å½•æŒ‚è½½ä¸ºåŒ¿åå·ï¼Œè¿™æ ·åœ¨è¿è¡Œæ—¶å¦‚æœç”¨æˆ·ä¸æŒ‡å®šæŒ‚è½½ï¼Œå…¶åº”ç”¨ä¹Ÿå¯ä»¥æ­£å¸¸è¿è¡Œï¼Œä¸ä¼šå‘å®¹å™¨å­˜å‚¨å±‚å†™å…¥å¤§é‡æ•°æ®ã€‚ 1VOLUME /data è¿™é‡Œçš„ /data ç›®å½•å°±ä¼šåœ¨å®¹å™¨è¿è¡Œæ—¶è‡ªåŠ¨æŒ‚è½½ä¸ºåŒ¿åå·ï¼Œä»»ä½•å‘ /data ä¸­å†™å…¥çš„ä¿¡æ¯éƒ½ä¸ä¼šè®°å½•è¿›å®¹å™¨å­˜å‚¨å±‚ï¼Œä»è€Œä¿è¯äº†å®¹å™¨å­˜å‚¨å±‚çš„æ— çŠ¶æ€åŒ–ã€‚å½“ç„¶ï¼Œè¿è¡Œå®¹å™¨æ—¶å¯ä»¥è¦†ç›–è¿™ä¸ªæŒ‚è½½è®¾ç½®ã€‚æ¯”å¦‚ï¼š 1$ docker run -d -v mydata:/data xxxx åœ¨è¿™è¡Œå‘½ä»¤ä¸­ï¼Œå°±ä½¿ç”¨äº† mydata è¿™ä¸ªå‘½åå·æŒ‚è½½åˆ°äº† /data è¿™ä¸ªä½ç½®ï¼Œæ›¿ä»£äº† Dockerfile ä¸­å®šä¹‰çš„åŒ¿åå·çš„æŒ‚è½½é…ç½®ã€‚ å½“ä½ åœ¨ Dockerfile ä¸­ä½¿ç”¨ VOLUME æŒ‡ä»¤æˆ–è€…åœ¨è¿è¡Œå®¹å™¨æ—¶é€šè¿‡ -v æ ‡è®°åˆ›å»ºä¸€ä¸ªåŒ¿åå·æ—¶ï¼ŒDocker ä¼šè‡ªåŠ¨åœ¨å®¿ä¸»æœºä¸Šä¸ºè¯¥å·åˆ†é…ä¸€ä¸ªå­˜å‚¨ä½ç½®ã€‚è¿™ä¸ªä½ç½®æ˜¯ç”± Docker çš„é…ç½®å’Œå®¿ä¸»æœºæ“ä½œç³»ç»Ÿå†³å®šçš„ï¼Œå¹¶ä¸”é€šå¸¸ä¸æ˜¯ç›´æ¥ç”±ç”¨æˆ·æŒ‡å®šçš„ã€‚å¯¹äºå¤§å¤šæ•° Linux å®‰è£…å’Œ Docker çš„é»˜è®¤é…ç½®ï¼ŒåŒ¿åå·çš„å­˜å‚¨ä½ç½®æ˜¯åœ¨å®¿ä¸»æœºçš„ /var/lib/docker/volumes/ ç›®å½•ä¸‹ã€‚ åœ¨è¯¥ç›®å½•ä¸‹ï¼Œæ¯ä¸ªå·éƒ½ä¼šæœ‰ä¸€ä¸ªå”¯ä¸€çš„æ ‡è¯†ç¬¦ä½œä¸ºå…¶ç›®å½•åã€‚åœ¨è¿™äº›å·çš„ç›®å½•å†…éƒ¨ï¼Œä½ ä¼šæ‰¾åˆ°ä¸¤ä¸ªå­ç›®å½•ï¼š_dataï¼Œå…¶ä¸­å­˜å‚¨çš„æ˜¯å·çš„æ•°æ®ï¼Œä»¥åŠ mounts.jsonï¼Œå…¶ä¸­åŒ…å«æœ‰å…³è¯¥å·çš„å…ƒæ•°æ®ã€‚ ä¾‹å¦‚ï¼Œè‹¥ä½ é€šè¿‡ Docker å‘½ä»¤åˆ›å»ºäº†ä¸€ä¸ªåŒ¿åå·ï¼Œä½ å¯èƒ½ä¼šåœ¨ /var/lib/docker/volumes/ ä¸‹æ‰¾åˆ°ä¸€ä¸ªç±»ä¼¼äº /var/lib/docker/volumes/2f4a8c1d591f396c2b47e6b42dfea9184292ab09e78a0b3e7661e8a3ef4b0c82/ çš„ç›®å½•ï¼Œ_data æ–‡ä»¶å¤¹å°±åœ¨è¿™ä¸ªç›®å½•é‡Œã€‚ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸åŒçš„ Docker é…ç½®å’Œä¸åŒçš„å®¿ä¸»æœºæ“ä½œç³»ç»Ÿå¯èƒ½ä¼šæ”¹å˜è¿™ä¸ªé»˜è®¤çš„å­˜å‚¨ä½ç½®ã€‚æ­¤å¤–ï¼Œå‡ºäºå®‰å…¨å’Œç»´æŠ¤çš„ç›®çš„ï¼Œä¸é¼“åŠ±ç›´æ¥æ‰‹åŠ¨æ“ä½œè¿™äº›æ–‡ä»¶ç›®å½•ã€‚å¯¹äºå¤§å¤šæ•°ç”¨ä¾‹ï¼Œå»ºè®®ä½¿ç”¨ Docker å‘½ä»¤æ¥ç®¡ç†å’Œæ“ä½œå·ã€‚ è‹¥éœ€è¦æŸ¥è¯¢å·çš„å…·ä½“å­˜å‚¨ä½ç½®ï¼Œå¯ä»¥ä½¿ç”¨ Docker å·å‘½ä»¤ï¼Œå¦‚ docker volume inspect [VOLUME_NAME]ï¼Œå®ƒä¼šæ˜¾ç¤ºå·çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¶åœ¨å®¿ä¸»æœºä¸Šçš„ç¡®åˆ‡å­˜å‚¨è·¯å¾„ã€‚å¯¹äºåŒ¿åå·ï¼Œè™½ç„¶æ²¡æœ‰å‹å¥½çš„åç§°ï¼Œä½†æ¯ä¸ªéƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„IDï¼Œå¯ä»¥é€šè¿‡åˆ—å‡ºæ‰€æœ‰å·çš„ä¿¡æ¯ docker volume ls æ¥æ‰¾åˆ°ï¼Œç„¶åç”¨è¿™ä¸ª ID è¿›è¡Œæ£€æŸ¥ã€‚ 6.8 EXPOSE æš´éœ²ç«¯å£æ ¼å¼ä¸º EXPOSE &lt;ç«¯å£1&gt; [&lt;ç«¯å£2&gt;...]ã€‚ **EXPOSE æŒ‡ä»¤æ˜¯å£°æ˜å®¹å™¨è¿è¡Œæ—¶æä¾›æœåŠ¡çš„ç«¯å£ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå£°æ˜ï¼Œåœ¨å®¹å™¨è¿è¡Œæ—¶å¹¶ä¸ä¼šå› ä¸ºè¿™ä¸ªå£°æ˜åº”ç”¨å°±ä¼šå¼€å¯è¿™ä¸ªç«¯å£çš„æœåŠ¡**ã€‚åœ¨ Dockerfile ä¸­å†™å…¥è¿™æ ·çš„å£°æ˜æœ‰ä¸¤ä¸ªå¥½å¤„ï¼Œä¸€ä¸ªæ˜¯å¸®åŠ©é•œåƒä½¿ç”¨è€…ç†è§£è¿™ä¸ªé•œåƒæœåŠ¡çš„å®ˆæŠ¤ç«¯å£ï¼Œä»¥æ–¹ä¾¿é…ç½®æ˜ å°„ï¼›å¦ä¸€ä¸ªç”¨å¤„åˆ™æ˜¯åœ¨è¿è¡Œæ—¶ä½¿ç”¨éšæœºç«¯å£æ˜ å°„æ—¶ï¼Œä¹Ÿå°±æ˜¯ docker run -P æ—¶ï¼Œä¼šè‡ªåŠ¨éšæœºæ˜ å°„ EXPOSE çš„ç«¯å£ã€‚ è¦å°† EXPOSE å’Œåœ¨è¿è¡Œæ—¶ä½¿ç”¨ -p &lt;å®¿ä¸»ç«¯å£&gt;:&lt;å®¹å™¨ç«¯å£&gt; åŒºåˆ†å¼€æ¥ã€‚-pï¼Œæ˜¯æ˜ å°„å®¿ä¸»ç«¯å£å’Œå®¹å™¨ç«¯å£ï¼Œæ¢å¥è¯è¯´ï¼Œå°±æ˜¯å°†å®¹å™¨çš„å¯¹åº”ç«¯å£æœåŠ¡å…¬å¼€ç»™å¤–ç•Œè®¿é—®ï¼Œè€Œ EXPOSE ä»…ä»…æ˜¯å£°æ˜å®¹å™¨æ‰“ç®—ä½¿ç”¨ä»€ä¹ˆç«¯å£è€Œå·²ï¼Œå¹¶ä¸ä¼šè‡ªåŠ¨åœ¨å®¿ä¸»è¿›è¡Œç«¯å£æ˜ å°„ã€‚ åœ¨ Docker ä¸­ï¼Œ-p å’Œ -P æ ‡å¿—è¢«ç”¨æ¥å°†å®¹å™¨å†…éƒ¨çš„ç«¯å£æ˜ å°„åˆ°å®¿ä¸»æœºçš„ç«¯å£ä¸Šï¼Œä½†å®ƒä»¬çš„å·¥ä½œæ–¹å¼å­˜åœ¨ä¸€äº›åŒºåˆ«ï¼š -p æ ‡å¿—: ä½¿ç”¨ -p æ ‡å¿—æ—¶ï¼Œä½ éœ€è¦æ˜ç¡®æŒ‡å®šç«¯å£æ˜ å°„å…³ç³»ã€‚è¿™åŒ…æ‹¬å®¿ä¸»æœºçš„ç«¯å£å’Œå®¹å™¨å†…éƒ¨çš„ç«¯å£ï¼Œæ ¼å¼ä¸º -p å®¿ä¸»æœºç«¯å£:å®¹å™¨ç«¯å£ã€‚ ä¾‹å¦‚ï¼Œdocker run -p 8080:80 nginx ä¼šå°†å®¹å™¨å†…éƒ¨çš„ 80 ç«¯å£æ˜ å°„åˆ°å®¿ä¸»æœºçš„ 8080 ç«¯å£ã€‚ ä½ å¯ä»¥ç²¾ç¡®æ§åˆ¶ç«¯å£æ˜ å°„çš„è¿‡ç¨‹ï¼ŒåŒ…æ‹¬é€‰æ‹©ç‰¹å®šçš„å®¿ä¸»æœºç«¯å£ã€‚ -P æ ‡å¿—: ä½¿ç”¨ -P æ ‡å¿—æ—¶ï¼ŒDocker ä¼šè‡ªåŠ¨å°†å®¹å™¨å†…éƒ¨æ‰€æœ‰é€šè¿‡ EXPOSE æŒ‡ä»¤æš´éœ²å‡ºæ¥çš„ç«¯å£æ˜ å°„åˆ°å®¿ä¸»æœºçš„ä¸€ä¸ªéšæœºé«˜ç«¯å£ï¼ˆé€šå¸¸åœ¨ 49153 åˆ° 65535 ä¹‹é—´ï¼‰ã€‚ è¿™æ„å‘³ç€ä½ æ— æ³•æ§åˆ¶ç«¯å£æ˜ å°„åˆ°å®¿ä¸»æœºçš„å“ªä¸ªç«¯å£ä¸Šï¼Œç«¯å£å·æ˜¯ç”± Docker åŠ¨æ€åˆ†é…çš„ã€‚ ä¾‹å¦‚ï¼Œdocker run -P nginx å‡è®¾ä½ çš„ nginx é•œåƒé€šè¿‡ EXPOSE æŒ‡ä»¤æš´éœ²äº† 80 ç«¯å£ï¼ŒDocker å°†è‡ªåŠ¨é€‰æ‹©ä¸€ä¸ªç«¯å£å°†å…¶æ˜ å°„åˆ°å®¿ä¸»æœºã€‚ 6.9 WORKDIR æŒ‡å®šå·¥ä½œç›®å½•æ ¼å¼ä¸º WORKDIR &lt;å·¥ä½œç›®å½•è·¯å¾„&gt;ã€‚ ä½¿ç”¨ WORKDIR æŒ‡ä»¤å¯ä»¥æ¥æŒ‡å®šå·¥ä½œç›®å½•ï¼ˆæˆ–è€…ç§°ä¸ºå½“å‰ç›®å½•ï¼‰ï¼Œä»¥åå„å±‚çš„å½“å‰ç›®å½•å°±è¢«æ”¹ä¸ºæŒ‡å®šçš„ç›®å½•ï¼Œå¦‚è¯¥ç›®å½•ä¸å­˜åœ¨ï¼ŒWORKDIR ä¼šå¸®ä½ å»ºç«‹ç›®å½•ã€‚ ä¹‹å‰æåˆ°ä¸€äº›åˆå­¦è€…å¸¸çŠ¯çš„é”™è¯¯æ˜¯æŠŠ Dockerfile ç­‰åŒäº Shell è„šæœ¬æ¥ä¹¦å†™ï¼Œè¿™ç§é”™è¯¯çš„ç†è§£è¿˜å¯èƒ½ä¼šå¯¼è‡´å‡ºç°ä¸‹é¢è¿™æ ·çš„é”™è¯¯ï¼š 12RUN cd /appRUN echo &quot;hello&quot; &gt; world.txt å¦‚æœå°†è¿™ä¸ª Dockerfile è¿›è¡Œæ„å»ºé•œåƒè¿è¡Œåï¼Œä¼šå‘ç°æ‰¾ä¸åˆ° /app/world.txt æ–‡ä»¶ï¼Œæˆ–è€…å…¶å†…å®¹ä¸æ˜¯ helloã€‚åŸå› å…¶å®å¾ˆç®€å•ï¼Œåœ¨ Shell ä¸­ï¼Œè¿ç»­ä¸¤è¡Œæ˜¯åŒä¸€ä¸ªè¿›ç¨‹æ‰§è¡Œç¯å¢ƒï¼Œå› æ­¤å‰ä¸€ä¸ªå‘½ä»¤ä¿®æ”¹çš„å†…å­˜çŠ¶æ€ï¼Œä¼šç›´æ¥å½±å“åä¸€ä¸ªå‘½ä»¤ï¼›è€Œåœ¨ Dockerfile ä¸­ï¼Œè¿™ä¸¤è¡Œ RUN å‘½ä»¤çš„æ‰§è¡Œç¯å¢ƒæ ¹æœ¬ä¸åŒï¼Œæ˜¯ä¸¤ä¸ªå®Œå…¨ä¸åŒçš„å®¹å™¨ã€‚è¿™å°±æ˜¯å¯¹ Dockerfile æ„å»ºåˆ†å±‚å­˜å‚¨çš„æ¦‚å¿µä¸äº†è§£æ‰€å¯¼è‡´çš„é”™è¯¯ã€‚ ä¹‹å‰è¯´è¿‡æ¯ä¸€ä¸ª RUN éƒ½æ˜¯å¯åŠ¨ä¸€ä¸ªå®¹å™¨ã€æ‰§è¡Œå‘½ä»¤ã€ç„¶åæäº¤å­˜å‚¨å±‚æ–‡ä»¶å˜æ›´ã€‚ç¬¬ä¸€å±‚ RUN cd /app çš„æ‰§è¡Œä»…ä»…æ˜¯å½“å‰è¿›ç¨‹çš„å·¥ä½œç›®å½•å˜æ›´ï¼Œä¸€ä¸ªå†…å­˜ä¸Šçš„å˜åŒ–è€Œå·²ï¼Œå…¶ç»“æœä¸ä¼šé€ æˆä»»ä½•æ–‡ä»¶å˜æ›´ã€‚è€Œåˆ°ç¬¬äºŒå±‚çš„æ—¶å€™ï¼Œå¯åŠ¨çš„æ˜¯ä¸€ä¸ªå…¨æ–°çš„å®¹å™¨ï¼Œè·Ÿç¬¬ä¸€å±‚çš„å®¹å™¨æ›´å®Œå…¨æ²¡å…³ç³»ï¼Œè‡ªç„¶ä¸å¯èƒ½ç»§æ‰¿å‰ä¸€å±‚æ„å»ºè¿‡ç¨‹ä¸­çš„å†…å­˜å˜åŒ–ã€‚ å› æ­¤å¦‚æœéœ€è¦æ”¹å˜ä»¥åå„å±‚çš„å·¥ä½œç›®å½•çš„ä½ç½®ï¼Œé‚£ä¹ˆåº”è¯¥ä½¿ç”¨ WORKDIR æŒ‡ä»¤ã€‚ 123WORKDIR /appRUN echo &quot;hello&quot; &gt; world.txt å¦‚æœä½ çš„ WORKDIR æŒ‡ä»¤ä½¿ç”¨çš„ç›¸å¯¹è·¯å¾„ï¼Œé‚£ä¹ˆæ‰€åˆ‡æ¢çš„è·¯å¾„ä¸ä¹‹å‰çš„ WORKDIR æœ‰å…³ï¼š 12345WORKDIR /aWORKDIR bWORKDIR cRUN pwd RUN pwd çš„å·¥ä½œç›®å½•ä¸º /a/b/cã€‚ 6.10 USER æŒ‡å®šå½“å‰ç”¨æˆ·æ ¼å¼ï¼šUSER &lt;ç”¨æˆ·å&gt;[:&lt;ç”¨æˆ·ç»„&gt;] USER æŒ‡ä»¤å’Œ WORKDIR ç›¸ä¼¼ï¼Œéƒ½æ˜¯æ”¹å˜ç¯å¢ƒçŠ¶æ€å¹¶å½±å“ä»¥åçš„å±‚ã€‚WORKDIR æ˜¯æ”¹å˜å·¥ä½œç›®å½•ï¼ŒUSER åˆ™æ˜¯æ”¹å˜ä¹‹åå±‚çš„æ‰§è¡Œ RUN, CMD ä»¥åŠ ENTRYPOINT è¿™ç±»å‘½ä»¤çš„èº«ä»½ã€‚ æ³¨æ„ï¼ŒUSER åªæ˜¯å¸®åŠ©ä½ åˆ‡æ¢åˆ°æŒ‡å®šç”¨æˆ·è€Œå·²ï¼Œè¿™ä¸ªç”¨æˆ·å¿…é¡»æ˜¯äº‹å…ˆå»ºç«‹å¥½çš„ï¼Œå¦åˆ™æ— æ³•åˆ‡æ¢ã€‚ 123RUN groupadd -r redis &amp;&amp; useradd -r -g redis redisUSER redisRUN [ &quot;redis-server&quot; ] å¦‚æœä»¥ root æ‰§è¡Œçš„è„šæœ¬ï¼Œåœ¨æ‰§è¡ŒæœŸé—´å¸Œæœ›æ”¹å˜èº«ä»½ï¼Œæ¯”å¦‚å¸Œæœ›ä»¥æŸä¸ªå·²ç»å»ºç«‹å¥½çš„ç”¨æˆ·æ¥è¿è¡ŒæŸä¸ªæœåŠ¡è¿›ç¨‹ï¼Œä¸è¦ä½¿ç”¨ su æˆ–è€… sudoï¼Œè¿™äº›éƒ½éœ€è¦æ¯”è¾ƒéº»çƒ¦çš„é…ç½®ï¼Œè€Œä¸”åœ¨ TTY ç¼ºå¤±çš„ç¯å¢ƒä¸‹ç»å¸¸å‡ºé”™ã€‚å»ºè®®ä½¿ç”¨ gosuã€‚ 12345678# å»ºç«‹ redis ç”¨æˆ·ï¼Œå¹¶ä½¿ç”¨ gosu æ¢å¦ä¸€ä¸ªç”¨æˆ·æ‰§è¡Œå‘½ä»¤RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis# ä¸‹è½½ gosuRUN wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/1.12/gosu-amd64&quot; \\ &amp;&amp; chmod +x /usr/local/bin/gosu \\ &amp;&amp; gosu nobody true# è®¾ç½® CMDï¼Œå¹¶ä»¥å¦å¤–çš„ç”¨æˆ·æ‰§è¡ŒCMD [ &quot;exec&quot;, &quot;gosu&quot;, &quot;redis&quot;, &quot;redis-server&quot; ] 7 Dockerfileå¤šé˜¶æ®µæ„å»ºå°†æ‰€æœ‰çš„æ„å»ºè¿‡ç¨‹ç¼–åŒ…å«åœ¨ä¸€ä¸ª Dockerfile ä¸­ï¼ŒåŒ…æ‹¬é¡¹ç›®åŠå…¶ä¾èµ–åº“çš„ç¼–è¯‘ã€æµ‹è¯•ã€æ‰“åŒ…ç­‰æµç¨‹ï¼Œè¿™é‡Œå¯èƒ½ä¼šå¸¦æ¥çš„ä¸€äº›é—®é¢˜ï¼š é•œåƒå±‚æ¬¡å¤šï¼Œé•œåƒä½“ç§¯è¾ƒå¤§ï¼Œéƒ¨ç½²æ—¶é—´å˜é•¿ æºä»£ç å­˜åœ¨æ³„éœ²çš„é£é™© äº‹å…ˆåœ¨ä¸€ä¸ª Dockerfile å°†é¡¹ç›®åŠå…¶ä¾èµ–åº“ç¼–è¯‘æµ‹è¯•æ‰“åŒ…å¥½åï¼Œå†å°†å…¶æ‹·è´åˆ°è¿è¡Œç¯å¢ƒä¸­ï¼Œè¿™ç§æ–¹å¼éœ€è¦æˆ‘ä»¬ç¼–å†™ä¸¤ä¸ª Dockerfile å’Œä¸€äº›ç¼–è¯‘è„šæœ¬æ‰èƒ½å°†å…¶ä¸¤ä¸ªé˜¶æ®µè‡ªåŠ¨æ•´åˆèµ·æ¥ï¼Œè¿™ç§æ–¹å¼è™½ç„¶å¯ä»¥å¾ˆå¥½åœ°è§„é¿ç¬¬ä¸€ç§æ–¹å¼å­˜åœ¨çš„é£é™©ï¼Œä½†æ˜æ˜¾éƒ¨ç½²è¿‡ç¨‹è¾ƒå¤æ‚ã€‚ ä¾‹å¦‚ï¼Œç¼–å†™ Dockerfile.build æ–‡ä»¶ 12345678910FROM golang:alpineRUN apk --no-cache add gitWORKDIR /go/src/github.com/go/helloworldCOPY app.go .RUN go get -d -v github.com/go-sql-driver/mysql \\ &amp;&amp; CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . ç¼–å†™ Dockerfile.copy æ–‡ä»¶ 123456789FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY app .CMD [&quot;./app&quot;] æ–°å»º build.sh 12345678910111213#!/bin/shecho Building go/helloworld:builddocker build -t go/helloworld:build . -f Dockerfile.builddocker create --name extract go/helloworld:builddocker cp extract:/go/src/github.com/go/helloworld/app ./appdocker rm -f extractecho Building go/helloworld:2docker build --no-cache -t go/helloworld:2 . -f Dockerfile.copyrm ./app ç°åœ¨è¿è¡Œè„šæœ¬å³å¯æ„å»ºé•œåƒ 123$ chmod +x build.sh$ ./build.sh å¯¹æ¯”ä¸¤ç§æ–¹å¼ç”Ÿæˆçš„é•œåƒå¤§å° 12345$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEgo/helloworld 2 f7cf3465432c 22 seconds ago 6.47MBgo/helloworld 1 f55d3e16affc 2 minutes ago 295MB ä½¿ç”¨å¤šé˜¶æ®µæ„å»ºä¸ºè§£å†³ä»¥ä¸Šé—®é¢˜ï¼ŒDocker v17.05 å¼€å§‹æ”¯æŒå¤šé˜¶æ®µæ„å»º (multistage builds)ã€‚ä½¿ç”¨å¤šé˜¶æ®µæ„å»ºæˆ‘ä»¬å°±å¯ä»¥å¾ˆå®¹æ˜“è§£å†³å‰é¢æåˆ°çš„é—®é¢˜ï¼Œå¹¶ä¸”åªéœ€è¦ç¼–å†™ä¸€ä¸ª Dockerfileï¼š ä¾‹å¦‚ï¼Œç¼–å†™ Dockerfile æ–‡ä»¶ 123456789101112131415161718192021FROM golang:alpine as builderRUN apk --no-cache add gitWORKDIR /go/src/github.com/go/helloworld/RUN go get -d -v github.com/go-sql-driver/mysqlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latest as prodRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=0 /go/src/github.com/go/helloworld/app .CMD [&quot;./app&quot;] æ„å»ºé•œåƒ 1$ docker build -t go/helloworld:3 . å¯¹æ¯”ä¸‰ä¸ªé•œåƒå¤§å° 123456$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEgo/helloworld 3 d6911ed9c846 7 seconds ago 6.47MBgo/helloworld 2 f7cf3465432c 22 seconds ago 6.47MBgo/helloworld 1 f55d3e16affc 2 minutes ago 295MB å¾ˆæ˜æ˜¾ä½¿ç”¨å¤šé˜¶æ®µæ„å»ºçš„é•œåƒä½“ç§¯å°ï¼ŒåŒæ—¶ä¹Ÿå®Œç¾è§£å†³äº†ä¸Šè¾¹æåˆ°çš„é—®é¢˜ã€‚ åªæ„å»ºæŸä¸€é˜¶æ®µçš„é•œåƒæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ as æ¥ä¸ºæŸä¸€é˜¶æ®µå‘½åï¼Œä¾‹å¦‚ 1FROM golang:alpine as builder ä¾‹å¦‚å½“æˆ‘ä»¬åªæƒ³æ„å»º builder é˜¶æ®µçš„é•œåƒæ—¶ï¼Œå¢åŠ  --target=builder å‚æ•°å³å¯ 1$ docker build --target builder -t username/imagename:tag . æ„å»ºæ—¶ä»å…¶ä»–é•œåƒå¤åˆ¶æ–‡ä»¶ä¸Šé¢ä¾‹å­ä¸­æˆ‘ä»¬ä½¿ç”¨ COPY --from=0 /go/src/github.com/go/helloworld/app . ä»ä¸Šä¸€é˜¶æ®µçš„é•œåƒä¸­å¤åˆ¶æ–‡ä»¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å¤åˆ¶ä»»æ„é•œåƒä¸­çš„æ–‡ä»¶ã€‚ 1$ COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf","tags":[{"name":"docker","slug":"docker","permalink":"https://stu-yue.github.io/tags/docker/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"}],"categories":[{"name":"tools","slug":"tools","permalink":"https://stu-yue.github.io/categories/tools/"},{"name":"docker","slug":"tools/docker","permalink":"https://stu-yue.github.io/categories/tools/docker/"}]},{"title":"Memo | Shell Basis","date":"2023-10-04T07:56:53.000Z","path":"jottings/languages/shell/memo_shell_basis/","text":"0 äº¤äº’å¼ç™»å½• shell å’Œéç™»å½• shelläº¤äº’å¼ç™»å½• shell å’Œéç™»å½• shell æ˜¯ä¸¤ç§åœ¨ Linux ç³»ç»Ÿä¸­ä½¿ç”¨ Shell æ—¶çš„ä¸åŒç¯å¢ƒã€‚å®ƒä»¬æœ‰ä»¥ä¸‹åŒºåˆ«ï¼š äº¤äº’å¼ç™»å½• shellï¼š å½“ç”¨æˆ·é€šè¿‡ç™»å½•ç•Œé¢ï¼ˆä¾‹å¦‚ç»ˆç«¯ç™»å½•ã€SSH è¿œç¨‹ç™»å½•ï¼‰æˆåŠŸç™»å½•åˆ°ç³»ç»Ÿæ—¶ï¼Œç³»ç»Ÿä¼šä¸ºç”¨æˆ·å¯åŠ¨ä¸€ä¸ªäº¤äº’å¼ç™»å½• shellã€‚ äº¤äº’å¼ç™»å½• shell ä¼šè¯»å–ç³»ç»Ÿçš„ç™»å½•é…ç½®æ–‡ä»¶ï¼ˆå¦‚ /etc/profile å’Œ ~/.bash_profileï¼‰æ¥æ‰§è¡Œåˆå§‹åŒ–æ“ä½œï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ã€åŠ è½½åˆ«åå’Œæ‰§è¡Œå…¶ä»–ç™»å½•æ—¶éœ€è¦çš„é…ç½®ã€‚ å®ƒè¿˜ä¼šæ‰§è¡Œ ~/.bashrc æ–‡ä»¶ï¼Œä»¥ä¾¿åŠ è½½ç”¨æˆ·è‡ªå®šä¹‰çš„ Shell é…ç½®ã€‚ ç”¨æˆ·åœ¨äº¤äº’å¼ç™»å½• shell ä¸­æ‰§è¡Œçš„å‘½ä»¤ä¼šè¢«è®°å½•åˆ°å†å²è®°å½•æ–‡ä»¶ï¼ˆå¦‚ ~/.bash_historyï¼‰ä¸­ã€‚ éç™»å½• shellï¼š å½“ç”¨æˆ·å·²ç»ç™»å½•åˆ°ç³»ç»Ÿåï¼Œåœ¨å½“å‰ shell ä¸­æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯æˆ–è¿è¡Œè„šæœ¬æ—¶ï¼Œä¼šå¯åŠ¨ä¸€ä¸ªéç™»å½• shellã€‚ éç™»å½• shell ä¸ä¼šè¯»å–ç™»å½•é…ç½®æ–‡ä»¶ï¼ˆå¦‚ /etc/profile å’Œ ~/.bash_profileï¼‰ï¼Œè€Œæ˜¯è¯»å– ~/.bashrc æ–‡ä»¶è¿›è¡Œåˆå§‹åŒ–ã€‚ å®ƒä¸ä¼šæ‰§è¡Œç™»å½•æ—¶éœ€è¦çš„é…ç½®ï¼Œåªä¼šåŠ è½½ç”¨æˆ·è‡ªå®šä¹‰çš„ Shell é…ç½®ã€‚ ç”¨æˆ·åœ¨éç™»å½• shell ä¸­æ‰§è¡Œçš„å‘½ä»¤ä¸ä¼šè¢«è®°å½•åˆ°å†å²è®°å½•æ–‡ä»¶ä¸­ï¼Œé™¤éç”¨æˆ·åœ¨ ~/.bashrc ä¸­æ˜¾å¼åœ°æŒ‡å®šã€‚ å¤§éƒ¨åˆ†Linuxå‘è¡Œç‰ˆç”¨~/.profileæ›¿æ¢~/.bash_profileï¼Œ~/.profileè¢«æ‰€æœ‰shellè¯»å–ï¼Œ~\\.bash_profileä»…è¢«Bashè¯»å–ï¼› .profileåœ¨ç™»å½•shellå¯åŠ¨æ—¶ï¼Œè¢«è¯»å–å’Œæ‰§è¡Œï¼›.bashrcåœ¨éç™»å½•shellå¯åŠ¨æ—¶æ‰§è¡Œï¼› profileä¸­ä¼šè¯»å–å„è‡ªçº§åˆ«çš„bashrcï¼› Shellå¯åŠ¨æ—¶è¯»å–é…ç½®æ–‡ä»¶çš„é¡ºåºï¼š /etc/profile /etc/profile.d/*.sh /etc/bash.bashrc ~/.profile æˆ– ~/.bash_login æˆ– ~/.bash_profileï¼šä¸ªæ€§åŒ–ç¯å¢ƒå˜é‡è®¾ç½® ~/.bashrc ï¼šåˆ«åã€å‡½æ•°å’Œå…¶ä»–ä¸ªæ€§åŒ–è®¾ç½®ï¼› ç³»ç»Ÿçº§ ç”¨æˆ·çº§ ç™»å½•shell &#x2F;etc&#x2F;profile ~&#x2F;.profile | ~&#x2F;.bash_profile éç™»å½•shell &#x2F;etc&#x2F;bash.bashrc ~&#x2F;.bashrc ç™»å½•å¼ shell å’Œéç™»å½•å¼ shell çš„è¿è¡Œå½¢å¼å¦‚ä¸‹ï¼š ç™»å½•å¼ shellï¼š æ­£å¸¸é€šè¿‡æŸç»ˆç«¯ç™»å½•çš„ shellã€‚ su - usernameã€‚ su -l usernameã€‚ éç™»å½•å¼ shellï¼š su usernameã€‚ å›¾å½¢ç»ˆç«¯ä¸‹æ‰“å¼€çš„å‘½ä»¤çª—å£ã€‚ è‡ªåŠ¨æ‰§è¡Œçš„ shell è„šæœ¬ã€‚ **echo $0**ï¼š-bashç™»å½•shellï¼›bashéç™»å½•ï¼› 1 ç»“åˆLinuxæ–‡ä»¶æè¿°ç¬¦ç†è§£é‡å®šå‘ è¾“å…¥è¾“å‡ºé‡å®šå‘å°±æ˜¯é€šè¿‡ä¿®æ”¹æ–‡ä»¶æŒ‡é’ˆå®ç°çš„ã€‚å‘ç”Ÿé‡å®šå‘æ—¶ï¼Œæ–‡ä»¶æè¿°ç¬¦å¹¶æ²¡æœ‰æ”¹å˜ï¼Œæ”¹å˜çš„æ˜¯æ–‡ä»¶æè¿°ç¬¦å¯¹åº”çš„æ–‡ä»¶æŒ‡é’ˆã€‚ Shellå¯¹æ–‡ä»¶æè¿°ç¬¦çš„æ“ä½œ åˆ†ç±» ç”¨æ³• è¯´æ˜ è¾“å‡º n&gt;filename ä»¥è¾“å‡ºçš„æ–¹å¼æ‰“å¼€æ–‡ä»¶ filenameï¼Œå¹¶ç»‘å®šåˆ°æ–‡ä»¶æè¿°ç¬¦ nã€‚n å¯ä»¥ä¸å†™ï¼Œé»˜è®¤ä¸º 1ï¼Œä¹Ÿå³æ ‡å‡†è¾“å‡ºæ–‡ä»¶ã€‚ è¾“å‡º n&gt;&amp;m ç”¨æ–‡ä»¶æè¿°ç¬¦ m ä¿®æ”¹æ–‡ä»¶æè¿°ç¬¦ nï¼Œæˆ–è€…è¯´ç”¨æ–‡ä»¶æè¿°ç¬¦ m çš„å†…å®¹è¦†ç›–æ–‡ä»¶æè¿°ç¬¦ nï¼Œç»“æœå°±æ˜¯ n å’Œ m éƒ½ä»£è¡¨äº†åŒä¸€ä¸ªæ–‡ä»¶ï¼Œå› ä¸º n å’Œ m çš„æ–‡ä»¶æŒ‡é’ˆéƒ½æŒ‡å‘äº†åŒä¸€ä¸ªæ–‡ä»¶ã€‚å› ä¸ºä½¿ç”¨çš„æ˜¯&gt;ï¼Œæ‰€ä»¥ n å’Œ m åªèƒ½ç”¨ä½œå‘½ä»¤çš„è¾“å‡ºæ–‡ä»¶ã€‚n å¯ä»¥ä¸å†™ï¼Œé»˜è®¤ä¸º 1ã€‚ è¾“å‡º n&gt;&amp;- å…³é—­æ–‡ä»¶æè¿°ç¬¦ n åŠå…¶ä»£è¡¨çš„æ–‡ä»¶ã€‚n å¯ä»¥ä¸å†™ï¼Œé»˜è®¤ä¸º 1ã€‚åœ¨shellä¸­æ‰§è¡Œ&gt;&amp;-å‘½ä»¤ä¼šå…³é—­æ–‡ä»¶æè¿°ç¬¦ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä¼šå…³é—­æ ‡å‡†è¾“å‡ºï¼ˆæ–‡ä»¶æè¿°ç¬¦1ï¼‰å’Œæ ‡å‡†é”™è¯¯è¾“å‡ºï¼ˆæ–‡ä»¶æè¿°ç¬¦2ï¼‰ï¼Œå°†å®ƒä»¬éƒ½é‡å®šå‘åˆ°ç©ºè®¾å¤‡ï¼ˆ&#x2F;dev&#x2F;nullï¼‰ã€‚ è¾“å‡º &amp;&gt;filename è¿™ä¸ªæ“ä½œå¯ä»¥ç”¨äºä¸´æ—¶ç¦ç”¨å‘½ä»¤çš„è¾“å‡ºï¼Œä»¥é˜²æ­¢è¾“å‡ºè¢«æ˜¾ç¤ºæˆ–è®°å½•ã€‚å°†æ­£ç¡®è¾“å‡ºç»“æœå’Œé”™è¯¯ä¿¡æ¯å…¨éƒ¨é‡å®šå‘åˆ° filenameã€‚ è¾“å…¥ n&lt;filename ä»¥è¾“å…¥çš„æ–¹å¼æ‰“å¼€æ–‡ä»¶ filenameï¼Œå¹¶ç»‘å®šåˆ°æ–‡ä»¶æè¿°ç¬¦ nã€‚n å¯ä»¥ä¸å†™ï¼Œé»˜è®¤ä¸º 0ï¼Œä¹Ÿå³æ ‡å‡†è¾“å…¥æ–‡ä»¶ã€‚ è¾“å…¥ n&lt;&amp;m ç±»ä¼¼äº n&gt;&amp;mï¼Œä½†æ˜¯å› ä¸ºä½¿ç”¨çš„æ˜¯&lt;ï¼Œæ‰€ä»¥ n å’Œ m åªèƒ½ç”¨ä½œå‘½ä»¤çš„è¾“å…¥æ–‡ä»¶ã€‚n å¯ä»¥ä¸å†™ï¼Œé»˜è®¤ä¸º 0ã€‚ è¾“å…¥ n&lt;&amp;- å…³é—­æ–‡ä»¶æè¿°ç¬¦ n åŠå…¶ä»£è¡¨çš„æ–‡ä»¶ã€‚n å¯ä»¥ä¸å†™ï¼Œé»˜è®¤ä¸º 0ã€‚ è¾“å…¥å’Œè¾“å‡º n&lt;&gt;filename åŒæ—¶ä»¥è¾“å…¥å’Œè¾“å‡ºçš„æ–¹å¼æ‰“å¼€æ–‡ä»¶ filenameï¼Œå¹¶ç»‘å®šåˆ°æ–‡ä»¶æè¿°ç¬¦ nï¼Œç›¸å½“äº n&gt;filename å’Œ n&lt;filename çš„æ€»å’Œã€‚ã€‚n å¯ä»¥ä¸å†™ï¼Œé»˜è®¤ä¸º 0ã€‚ 1echo &quot;Cè¯­è¨€ä¸­æ–‡ç½‘&quot; 10&gt;log.txt &gt;&amp;10 å…ˆæ‰§è¡Œ10&gt;log.txtï¼Œæ‰“å¼€ log.txtï¼Œå¹¶ç»™å®ƒåˆ†é…æ–‡ä»¶æè¿°ç¬¦ 10ï¼›æ¥ç€æ‰§è¡Œ&gt;&amp;10ï¼Œç”¨æ–‡ä»¶æè¿°ç¬¦ 10 æ¥ä¿®æ”¹æ–‡ä»¶æè¿°ç¬¦ 1ï¼ˆå¯¹äº&gt;ï¼Œçœç•¥ä¸å†™çš„è¯é»˜è®¤ä¸º 1ï¼‰ï¼Œè®© 1 å’Œ 10 éƒ½æŒ‡å‘ log.txt æ–‡ä»¶ï¼Œæœ€ç»ˆçš„ç»“æœæ˜¯å‘ log.txt æ–‡ä»¶ä¸­è¾“å‡ºå†…å®¹ã€‚ è¿™æ¡è¯­å¥å…¶å®ç­‰ä»·äºecho &quot;Cè¯­è¨€ä¸­æ–‡ç½‘&quot; &gt;log.txtï¼Œæˆ‘ä¹‹æ‰€ä»¥å†™å¾—è¿™ä¹ˆç»•ï¼Œæ˜¯ä¸ºäº†è®©å¤§å®¶ç†è§£å„ç§æ“ä½œç¬¦çš„ç”¨æ³•ã€‚ æ–‡ä»¶æè¿°ç¬¦ 10 åªç”¨äº†ä¸€æ¬¡ï¼Œæˆ‘ä»¬åœ¨æœ«å°¾æœ€å¥½å°†å®ƒå…³é—­ï¼Œè¿™æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ã€‚ 1echo &quot;Cè¯­è¨€ä¸­æ–‡ç½‘&quot; 10&gt;log.txt &gt;&amp;10 10&gt;&amp;- 2 ç®¡é“(pipeline, | )pipeline ( | ) æ˜¯ UNIX ç³»ç»Ÿï¼ŒåŸºç¡€ä¸”é‡è¦çš„è§‚å¿µã€‚è¿ç»“ä¸Šä¸ªæŒ‡ä»¤çš„æ ‡å‡†è¾“å‡ºï¼Œåšä¸ºä¸‹ä¸ªæŒ‡ä»¤çš„æ ‡å‡†è¾“å…¥ã€‚ 1who | wc -l å–„ç”¨è¿™ä¸ªè§‚å¿µï¼Œå¯¹ç²¾ç®€ script æœ‰ç›¸å½“çš„å¸®åŠ©ã€‚ 3 åå°å·¥ä½œ( &amp; )å•ä¸€ä¸ª&amp; ç¬¦å·ï¼Œä¸”æ”¾åœ¨å®Œæ•´æŒ‡ä»¤åˆ—çš„æœ€åç«¯ï¼Œå³è¡¨ç¤ºå°†è¯¥æŒ‡ä»¤åˆ—æ”¾å…¥åå°ä¸­å·¥ä½œã€‚ nohupé‡å®šå‘åˆ°æŒ‡å®šæ–‡ä»¶ 1nohup ./run &gt;log 2&gt;&amp;1 &amp; 4 å¿«é€Ÿå…¥é—¨ #!: Shebang lineï¼Œå‘Šè¯‰ç³»ç»Ÿè„šæœ¬ç”¨ä»€ä¹ˆè§£é‡Šå™¨æ‰§è¡Œï¼› .shä½œä¸ºå¯æ‰§è¡Œç¨‹åºæ—¶ï¼ŒåŠ ä¸Šç¬¬ä¸€è¡Œï¼› sh ï¼ˆé»˜è®¤Shellè§£é‡Šå™¨è¿è¡Œï¼‰ã€bashï¼ˆbashè§£é‡Šå™¨æ‰§è¡Œï¼‰ï¼› 5 åŸºæœ¬è¯­æ³•ï¼ˆå˜é‡ï¼‰ å®šä¹‰å˜é‡ï¼šå˜é‡å&#x3D;å˜é‡å€¼ï¼Œç­‰å·ä¸¤ä¾§ä¸èƒ½æœ‰ç©ºæ ¼ï¼Œå˜é‡åä¸€èˆ¬ä¹ æƒ¯ç”¨å¤§å†™ã€‚ åˆ é™¤å˜é‡ï¼šunset å˜é‡å ã€‚ å£°æ˜é™æ€å˜é‡ï¼šreadonly å˜é‡åï¼Œé™æ€å˜é‡ä¸èƒ½unsetã€‚ ä½¿ç”¨å˜é‡ï¼š$å˜é‡å **å‘½ä»¤æ›¿æ¢$()**ï¼šå°†å‘½ä»¤è¿”å›å€¼èµ‹ç»™å˜é‡ï¼›ç­‰ä»·äºåå¼•å·ï¼› ç¯å¢ƒå˜é‡ï¼š export å˜é‡å&#x3D;å˜é‡å€¼ï¼Œå°† Shell å˜é‡è¾“å‡ºä¸ºç¯å¢ƒå˜é‡ï¼› source é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œè®©ä¿®æ”¹åçš„é…ç½®ä¿¡æ¯ç«‹å³ç”Ÿæ•ˆï¼› echo $å˜é‡åï¼Œæ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦ç”Ÿæ•ˆï¼› ä½ç½®å‚æ•°ï¼š $n ï¼š$0 ä»£è¡¨å‘½ä»¤æœ¬èº«ã€$1-$9 ä»£è¡¨ç¬¬1åˆ°9ä¸ªå‚æ•°ï¼Œ10ä»¥ä¸Šå‚æ•°ç”¨èŠ±æ‹¬å·ï¼Œå¦‚ ${10}ã€‚ $* ï¼šå‘½ä»¤è¡Œä¸­æ‰€æœ‰å‚æ•°ï¼Œä¸”æŠŠæ‰€æœ‰å‚æ•°çœ‹æˆä¸€ä¸ªæ•´ä½“ã€‚ $@ ï¼šå‘½ä»¤è¡Œä¸­æ‰€æœ‰å‚æ•°ï¼Œä¸”æŠŠæ¯ä¸ªå‚æ•°åŒºåˆ†å¯¹å¾…ï¼ˆæ¨èï¼‰ã€‚ $# ï¼šæ‰€æœ‰å‚æ•°ä¸ªæ•°ã€‚ $ å’Œ $@ï¼Œåœ¨ä¸è¢«åŒå¼•å·åŒ…å›´æ—¶*ï¼Œè¡Œä¸ºååˆ†ç›¸ä¼¼â€”â€”éƒ½ä¼šå°†è„šæœ¬çš„æ‰€æœ‰å‚æ•°å±•å¼€æˆä¸€ä¸ªç”±ç©ºæ ¼åˆ†éš”çš„åˆ—è¡¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå‚æ•°ä¸­åŒ…å«çš„ç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦å¯èƒ½ä¸ä¼šè¢«æ­£ç¡®å¤„ç†ï¼Œå¹¶å¯èƒ½ä¼šå¼•èµ·è¯è¯­åˆ†å‰²ï¼Œä¾‹å¦‚ï¼š 12345678910// study.sh#!/bin/bashecho $@echo $*// run./study.sh one &quot;two two&quot; three// outputone two two three $ å’Œ $@ï¼Œåœ¨è¢«åŒå¼•å·åŒ…å›´æ—¶*ï¼Œ $@ ä¼šå°†æ¯ä¸ªå‚æ•°ä½œä¸ºç‹¬ç«‹ä¸”è¢«å¼•å·åŒ…å›´çš„å­—ç¬¦ä¸²ï¼Œä¿æŒå…¶ä½œä¸ºå•ç‹¬çš„å…ƒç´ ï¼Œä¼šæ­£ç¡®å¤„ç†åŒ…å«ç©ºæ ¼&#x2F;ç‰¹æ®Šå­—ç¬¦çš„å‚æ•°ï¼› $* ä¼šå°†æ‰€æœ‰å‚æ•°è¿æˆä¸€ä¸ªå•ç‹¬çš„å­—ç¬¦ä¸²ï¼Œå…¶ä¸­çš„å‚æ•°ç”±ç©ºæ ¼åˆ†éš”ï¼Œè¿™ç§æ–¹å¼ä¸èƒ½ä¿è¯åŸæœ‰å‚æ•°çš„å‡†ç¡®ç•Œé™ï¼Œå°¤å…¶æ˜¯å‚æ•°å†…éƒ¨åŒ…å«ç©ºæ ¼æ—¶ã€‚ é¢„å®šä¹‰å˜é‡ $$ï¼šå½“å‰è¿›ç¨‹çš„PIDï¼› **$!**ï¼šåå°è¿è¡Œçš„æœ€åä¸€ä¸ªè¿›ç¨‹çš„PIDï¼› **$?**ï¼šæœ€åä¸€æ¬¡æ‰§è¡Œå‘½ä»¤çš„è¿”å›çŠ¶æ€ï¼Œ0ä¸ºæˆåŠŸï¼› è¿ç®—å¼è®¡ç®— $(())ï¼š$((2+3*2)) $(expr 2 + 3)ï¼š æ¡ä»¶åˆ¤æ–­ [ condition ]ï¼šå‰åéƒ½è¦æœ‰ç©ºæ ¼ï¼Œéç©ºè¿”å›0ï¼Œ0ä¸ºtrueï¼›å¦åˆ™ä¸ºfalseï¼› 12345if [ condition ]; then execelif [ condition ]; then execfi æµ‹è¯•å‚æ•° å«ä¹‰ str å­—ç¬¦ä¸² str éç©º -z str å­—ç¬¦ä¸² str ä¸ºç©º -n str å­—ç¬¦ä¸² str çš„é•¿åº¦éé›¶ str1=str2 str1!=str2 -e file æ–‡ä»¶ file å­˜åœ¨ -f file æ–‡ä»¶ file å­˜åœ¨ä¸”æ˜¯ä¸€ä¸ªæ™®é€šæ–‡ä»¶ -d dir æ–‡ä»¶ dir å­˜åœ¨ä¸”æ˜¯ä¸€ä¸ªç›®å½• -r/w/x file æ–‡ä»¶ file å­˜åœ¨ä¸”å¯è¯»&#x2F;å¯å†™&#x2F;å¯æ‰§è¡Œ -s file æ–‡ä»¶ file å­˜åœ¨ä¸”æ–‡ä»¶å¤§å°ä¸ä¸º0 num1 -eq/ne/lt/le/ge/gt num2 [ ! condition ] [ cond1 -a cond2] [[ cond1 &amp;&amp; cond2]] [ cond1 -o cond2 ] [[ cond1 || cond2 ]] caseåˆ†æ”¯ 1234567891011case $var inc1) echo &quot;c1&quot; ;;c2) echo &quot;c2&quot; ;;*) echo &quot;default&quot; ;;esac forå¾ªç¯ 123456789for var in (...); do echo $vardonefor i in &#123;1..20&#125;; do if [ $((i % 2)) -eq 0 ]; then echo $i; fi; done;# æ¯éš”2ä¸ªæ•°æ‰“å°ä¸€æ¬¡for ((i=0; i&lt;=10; i+=2)); do echo $i; done;for i in $(seq 0 2 10); do echo $i; done; whileå¾ªç¯ 1234i=1while [ $i -le 20 ]; do echo $i; i=$((i + 1));done; è¯»å–æ§åˆ¶å°è¾“å…¥ (read) -pï¼šæŒ‡å®šè¯»å–å€¼æ—¶çš„æç¤ºç¬¦ï¼› 1read -p &quot;è¯·è¾“å…¥ä¸€ä¸ªæ•°num=&quot; NUM; echo &quot;num=$NUM&quot; -tï¼šæŒ‡å®šè¯»å–å€¼æ—¶ç­‰å¾…ç§’æ•°ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šæ—¶é—´å†…è¾“å…¥ï¼Œä¸å†ç­‰å¾…ï¼› 1read -t 5 -p &quot;è¯·5så†…è¾“å…¥ä¸€ä¸ªæ•°num=&quot; NUM; echo &quot;num=$NUM&quot; 6 å‡½æ•° ç³»ç»Ÿå‡½æ•°ï¼š è‡ªå®šä¹‰å‡½æ•°ï¼š 12345678910111213141516171819202122232425262728function_name() &#123; # Your commands here [return value] &#125;# examplecheck_file_exists() &#123; if [ -e &quot;$1&quot; ]; then echo &quot;File exists.&quot; return 0 else echo &quot;File does not exist.&quot; return 1 fi&#125;# è°ƒç”¨å‡½æ•°å¹¶ä¼ é€’æ–‡ä»¶åcheck_file_exists &quot;/path/to/your/file.txt&quot;# è·å–å‡½æ•°è¿”å›å€¼status=$?# æ ¹æ®è¿”å›å€¼åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å­˜åœ¨if [ $status -eq 0 ]; then echo &quot;The check confirmed that the file exists.&quot;else echo &quot;The check confirmed that the file does NOT exist.&quot;fi å¯ä»¥ä½¿ç”¨å±€éƒ¨å˜é‡ï¼ˆå£°æ˜å’Œèµ‹å€¼åº”è¯¥åœ¨ä¸åŒè¡Œï¼‰ï¼Œå°†ä½ç½®å‚æ•°èµ‹äºˆæ›´æœ‰æ„ä¹‰çš„åå­—ï¼š 123456789101112print_details() &#123; local name=$1 local age=$2 local job_title=$3 echo &quot;Name: $name&quot; echo &quot;Age: $age&quot; echo &quot;Job Title: $job_title&quot;&#125;# è°ƒç”¨å‡½æ•°å¹¶ä¼ é€’å‚æ•°print_details &quot;Alice&quot; &quot;30&quot; &quot;Developer&quot;","tags":[{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | Tmux","date":"2023-10-04T07:56:53.000Z","path":"jottings/languages/shell/memo_tmux/","text":"What is tmux? A typical use of the command line is to open a terminal window (session), whose important feature is that window is connected to the process started in it (window closed, session ends, vice versa). Tmux, Terminal multiplexer, is the session and window â€œunbindâ€ tool. It allows: simultaneous access to multiple sessions in a single window. (useful for running multiple terminal simultaneously) a new window to access an existing session; each session having multiple connection window (multiple people sharing sessions in real time) arbitrary vertical and horizontal splitting of windows; Basic conception: session: Basic Usage Start â€”tmux, Quitâ€”exit/Ctrl-d, Prefix Keyâ€”Ctrl+b; A status bar is located at the bottom: 12[name/id] [list of ][0] 0:bash 1:test3* 2:test4- &quot;VM-16-17-ubuntu&quot; 15:28 04-Oct-23 Session Management New a session: tmux new -s &lt;session-name&gt;; 1tmux new -s sessionName -n window Split sessions: tmux detach/Ctrl+b d, after the command is executed, the current Tmux window exits, but the session and the processes inside it still run in the background; View all current tmux sessions: tmux ls 1230: 1 windows (created Tue Sep 19 20:42:24 2023)1: 1 windows (created Tue Oct 3 19:57:48 2023)test2: 1 windows (created Wed Oct 4 14:49:04 2023) (attached) Attach a session: tmux attach -t id/&lt;session-name&gt;; Kill a session: tmux kill-session -t id/&lt;session-name&gt;; Switch a session: tmux switch -t id/&lt;session-name&gt;; Rename a session: tmux rename-session -t id/&lt;session-name&gt; &lt;new-name&gt;; Shortcuts: Ctrl+bd: Split current session; Ctrl+b s list all session; Ctrl+b w list all windows; Ctrl+b $: rename current session; Simple workflow of tmux: new a session: tmux new -s my_session; run program in tmux window; Ctrl+b d splits the session; Attach the last session tmux attach-session -t my_session; Pane OperationTmux can split the window into panes, which can execute different commands. tmux splilt-window splits into vertical layout; tmux split-window -h splits into horizontal layout; tmux select-pane moves the cursor in different panes: 1234567891011# å…‰æ ‡åˆ‡æ¢åˆ°ä¸Šæ–¹çª—æ ¼$ tmux select-pane -U# å…‰æ ‡åˆ‡æ¢åˆ°ä¸‹æ–¹çª—æ ¼$ tmux select-pane -D# å…‰æ ‡åˆ‡æ¢åˆ°å·¦è¾¹çª—æ ¼$ tmux select-pane -L# å…‰æ ‡åˆ‡æ¢åˆ°å³è¾¹çª—æ ¼$ tmux select-pane -R tmux swap-pane exchanges the positions of panes: 12345# å½“å‰çª—æ ¼ä¸Šç§»$ tmux swap-pane -U# å½“å‰çª—æ ¼ä¸‹ç§»$ tmux swap-pane -D Shortcuts in pane operations: 1234567891011121314Ctrl+b % ï¼šåˆ’åˆ†å·¦å³ä¸¤ä¸ªçª—æ ¼ã€‚Ctrl+b &quot; ï¼šåˆ’åˆ†ä¸Šä¸‹ä¸¤ä¸ªçª—æ ¼ã€‚Ctrl+b &lt;arrow key&gt; ï¼šå…‰æ ‡åˆ‡æ¢åˆ°å…¶ä»–çª—æ ¼ã€‚&lt;arrow key&gt;æ˜¯æŒ‡å‘è¦åˆ‡æ¢åˆ°çš„çª—æ ¼çš„æ–¹å‘é”®ï¼Œæ¯”å¦‚åˆ‡æ¢åˆ°ä¸‹æ–¹çª—æ ¼ï¼Œå°±æŒ‰æ–¹å‘é”®â†“ã€‚Ctrl+b ; ï¼šå…‰æ ‡åˆ‡æ¢åˆ°ä¸Šä¸€ä¸ªçª—æ ¼ã€‚Ctrl+b o ï¼šå…‰æ ‡åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªçª—æ ¼ã€‚Ctrl+b &#123; ï¼šå½“å‰çª—æ ¼ä¸ä¸Šä¸€ä¸ªçª—æ ¼äº¤æ¢ä½ç½®ã€‚Ctrl+b &#125; ï¼šå½“å‰çª—æ ¼ä¸ä¸‹ä¸€ä¸ªçª—æ ¼äº¤æ¢ä½ç½®ã€‚Ctrl+b Ctrl+o ï¼šæ‰€æœ‰çª—æ ¼å‘å‰ç§»åŠ¨ä¸€ä¸ªä½ç½®ï¼Œç¬¬ä¸€ä¸ªçª—æ ¼å˜æˆæœ€åä¸€ä¸ªçª—æ ¼ã€‚Ctrl+b Alt+o ï¼šæ‰€æœ‰çª—æ ¼å‘åç§»åŠ¨ä¸€ä¸ªä½ç½®ï¼Œæœ€åä¸€ä¸ªçª—æ ¼å˜æˆç¬¬ä¸€ä¸ªçª—æ ¼ã€‚Ctrl+b x ï¼šå…³é—­å½“å‰çª—æ ¼ã€‚Ctrl+b ! ï¼šå°†å½“å‰çª—æ ¼æ‹†åˆ†ä¸ºä¸€ä¸ªç‹¬ç«‹çª—å£ã€‚Ctrl+b z ï¼šå½“å‰çª—æ ¼å…¨å±æ˜¾ç¤ºï¼Œå†ä½¿ç”¨ä¸€æ¬¡ä¼šå˜å›åŸæ¥å¤§å°ã€‚Ctrl+b Ctrl+&lt;arrow key&gt; ï¼šæŒ‰ç®­å¤´æ–¹å‘è°ƒæ•´çª—æ ¼å¤§å°ã€‚Ctrl+b q ï¼šæ˜¾ç¤ºçª—æ ¼ç¼–å·ã€‚ Close window&#x2F;pane 1exit Window Operation tmux new-window -n &lt;window-name&gt;: new a window; tmux select-window -t &lt;window-number/name&gt;: switch window tmux rename-window Shortcuts in window operation: 123456Ctrl+b cï¼šåˆ›å»ºä¸€ä¸ªæ–°çª—å£ï¼ŒçŠ¶æ€æ ä¼šæ˜¾ç¤ºå¤šä¸ªçª—å£çš„ä¿¡æ¯ã€‚Ctrl+b pï¼šåˆ‡æ¢åˆ°ä¸Šä¸€ä¸ªçª—å£ï¼ˆæŒ‰ç…§çŠ¶æ€æ ä¸Šçš„é¡ºåºï¼‰ã€‚Ctrl+b nï¼šåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªçª—å£ã€‚Ctrl+b &lt;number&gt;ï¼šåˆ‡æ¢åˆ°æŒ‡å®šç¼–å·çš„çª—å£ï¼Œå…¶ä¸­çš„&lt;number&gt;æ˜¯çŠ¶æ€æ ä¸Šçš„çª—å£ç¼–å·ã€‚Ctrl+b wï¼šä»åˆ—è¡¨ä¸­é€‰æ‹©çª—å£ã€‚Ctrl+b ,ï¼šçª—å£é‡å‘½åã€‚ Other Commands1234567891011121314151617181920212223242526272829303132333435363738394041# åˆ—å‡ºæ‰€æœ‰å¿«æ·é”®ï¼ŒåŠå…¶å¯¹åº”çš„ Tmux å‘½ä»¤$ tmux list-keys# åˆ—å‡ºæ‰€æœ‰ Tmux å‘½ä»¤åŠå…¶å‚æ•°$ tmux list-commands# åˆ—å‡ºå½“å‰æ‰€æœ‰ Tmux ä¼šè¯çš„ä¿¡æ¯$ tmux info# å¸¸ç”¨å¿«æ·é”®Ctrl+b s åˆ—å‡ºæ‰€æœ‰sessionsä¿¡æ¯Ctrl+b wCtrl+b o åˆ‡æ¢çª—æ ¼Ctrl+b n åˆ‡æ¢çª—å£Ctrl+b d åˆ†ç¦»sessiontmux new [-t xx [-n xx]]tmux new-windowtmux split-window [-h]tmux lstmux attach -t xxtmux detachexitæ‰“å¼€é¼ æ ‡æ¨¡å¼tmux set mouse on# é‡æ–°åŠ è½½å½“å‰çš„ Tmux é…ç½®$ tmux source-file ~/.tmux.confctrl+b, : //æŒ‰å®Œå‰ç¼€ctrl+Båï¼Œå†æŒ‰åˆ†å·ï¼šè¿›å…¥å‘½ä»¤è¡Œæ¨¡å¼set -g mouse on //å‘½ä»¤è¡Œä¸­è¾“å…¥è¿™å¥å‘½ä»¤ï¼Œå›è½¦å°±è¡Œäº†# é‡å‘½åtmux rename-session -t id &lt;new&gt; -t (target)tmux rename-window -t id &lt;new&gt;tmux resize-pane -U/D/L/R 10# é€‰ä¸­å¤åˆ¶shift + å·¦é”®é€‰ä¸­","tags":[{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | Here Document","date":"2023-10-04T07:56:53.000Z","path":"jottings/languages/shell/memo_here_doc/","text":"teeå‘½ä»¤ ï¼šteeæŒ‡ä»¤ä¼šä»æ ‡å‡†è¾“å…¥è®¾å¤‡è¯»å–æ•°æ®ï¼Œå°†å…¶å†…å®¹è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡ºè®¾å¤‡ï¼ŒåŒæ—¶ä¿å­˜æˆæ–‡ä»¶ã€‚ -aï¼šè¿½åŠ æ–‡ä»¶å†…å®¹ï¼Œè€Œéè¦†ç›–ï¼› -iï¼šå¿½ç•¥ä¸­æ–­ä¿¡å·ï¼› Here Documentï¼ˆä¹Ÿç§°heredocï¼‰æ˜¯ä¸€ç§åœ¨shellä¸­è¾“å…¥ä¸€ä¸ªæˆ–å¤šä¸ªè¡Œçš„æ ‡å‡†è¾“å…¥æ–‡æœ¬çš„æ–¹æ³•ã€‚ä¸€ä¸ªHere Documentå…è®¸ç”¨æˆ·åˆ›å»ºä¸€ä¸ªæœ‰èµ·å§‹æ ‡è®°å’Œç»ˆæ­¢æ ‡è®°çš„æ–‡æœ¬å—ï¼Œè¯¥æ–‡æœ¬å—çš„å†…å®¹ä¼šè¢«å½“ä½œè¾“å…¥ä¼ é€ç»™ä¸€ä¸ªå‘½ä»¤ã€‚ åŸºæœ¬è¯­æ³• 1234command &lt;&lt;DELIMITERtext blocktext blockDELIMITER 12345678910# æ–‡æœ¬å—ä¸­çš„ä»»ä½•ä»¥åˆ¶è¡¨ç¬¦ç¼©è¿›çš„å†…å®¹å°†ä¼šåœ¨ä¼ é€’ç»™å‘½ä»¤ä¹‹å‰å»é™¤è¿™äº›åˆ¶è¡¨ç¬¦ç¼©è¿›command &lt;&lt;-EOF# å¸¦å•/åŒå¼•å·åï¼Œå°†ä¸åœ¨shellä¸­è¿›è¡Œå˜é‡æ›¿æ¢å’Œå‘½ä»¤æ›¿æ¢NAME=&quot;World&quot;CURRENT_DATE=$(date)tee /path/to/greeting.txt &lt;&lt;EOFHello, $NAME!Today is $CURRENT_DATE.EOF","tags":[{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"","date":"2023-09-26T06:40:27.727Z","path":"jottings/tidbits/quantization/","text":"åœ¨çº¿é‡åŒ–ï¼šæŒ‡é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(Quantization-Aware Training)ï¼Œåœ¨ç½‘ç»œæ¨¡å‹è®­ç»ƒé˜¶æ®µé‡‡ç”¨é‡åŒ–æ–¹æ¡ˆè¿›è¡Œé‡åŒ–ï¼› é‡åŒ–æ„ŸçŸ¥è®­ç»ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ç§ä¼ªé‡åŒ–çš„è¿‡ç¨‹ï¼Œå®ƒæ˜¯åœ¨å¯è¯†åˆ«çš„æŸäº›æ“ä½œå†…åµŒå…¥ä¼ªé‡åŒ–èŠ‚ç‚¹ï¼ˆfake quantization opï¼‰ï¼Œå¹¶å‚ä¸æ¨¡å‹è®­ç»ƒçš„å‰å‘æ¨ç†è¿‡ç¨‹æ¨¡æ‹Ÿå¼•å…¥ï¼Œä½†æ¨¡å‹çš„åå‘ä¼ æ’­è¿‡ç¨‹ä¾æ—§ä½¿ç”¨å…¨ç²¾åº¦æµ®ç‚¹æ•°è¿›è¡Œï¼› ä¼ªé‡åŒ–èŠ‚ç‚¹ï¼Œæ˜¯æŒ‡é‡åŒ–æ„ŸçŸ¥è®­ç»ƒä¸­æ’å…¥çš„èŠ‚ç‚¹ï¼Œç”¨ä»¥å¯»æ‰¾ç½‘ç»œæ•°æ®åˆ†å¸ƒï¼Œå¹¶åé¦ˆæŸå¤±ç²¾åº¦ï¼š æ‰¾åˆ°è¾“å…¥ã€æƒé‡ç­‰å¾…é‡åŒ–æ•°æ®çš„åˆ†å¸ƒï¼Œæ‰¾åˆ°å¾…é‡åŒ–æ•°æ®çš„æœ€å¤§å’Œæœ€å°å€¼ï¼› æ¨¡æ‹Ÿä½æ¯”ç‰¹é‡åŒ–å¸¦æ¥çš„ç²¾åº¦æŸå¤±ï¼ŒæŠŠè¯¥æŸå¤±ä½œç”¨åˆ°ç½‘ç»œæ¨¡å‹ä¸­ï¼Œä¼ é€’ç»™æŸå¤±å‡½æ•°ï¼Œè®©ä¼˜åŒ–å™¨åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹è¯¥æŸå¤±å€¼è¿›è¡Œä¼˜åŒ–ï¼Œ å°½å¯èƒ½å‡å°‘ç”±äºä¼ªé‡åŒ–æ“ä½œè€Œå¼•èµ·çš„ç²¾åº¦ä¸‹é™ï¼› å…ˆé¥±å’Œæˆªæ–­å¤„ç†ï¼š$clamp(x,x_{min}, x_{max}) &#x3D; \\min(\\max(x,x_{min}), x_{max})$ï¼› å†Float-&gt;Int-&gt;Floatï¼š ç¦»çº¿é‡åŒ–ï¼šæŒ‡è®­ç»ƒåé‡åŒ–(Post-Training Quantization)ï¼š åŠ¨æ€ç¦»çº¿é‡åŒ–(PTQ, Dynamic)ï¼š åŠ¨æ€ç¦»çº¿é‡åŒ–ä»…å°†æ¨¡å‹ä¸­ç‰¹å®šç®—å­çš„æƒé‡ä»FP32ç±»å‹æ˜ å°„æˆ INT8&#x2F;16 ç±»å‹ï¼Œbiaså’Œæ¿€æ´»å‡½æ•° åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€é‡åŒ–ã€‚ä½†æ˜¯å¯¹äºä¸åŒçš„è¾“å…¥å€¼æ¥è¯´ï¼Œå…¶ç¼©æ”¾å› å­æ˜¯åŠ¨æ€è®¡ç®—çš„ï¼ˆâ€œåŠ¨æ€â€çš„ç”±æ¥ï¼‰ã€‚åŠ¨æ€é‡åŒ–æ˜¯å‡ ç§é‡åŒ–æ–¹æ³•ä¸­æ€§èƒ½æœ€å·®çš„ã€‚åŠ¨æ€é‡åŒ–å¸¸ç”¨äºéå¸¸å¤§çš„æ¨¡å‹ã€‚ é™æ€ç¦»çº¿é‡åŒ–(PTQ, Static)ï¼š é™æ€ç¦»çº¿é‡åŒ–ä½¿ç”¨å°‘é‡æ— æ ‡ç­¾æ ¡å‡†æ•°æ®ï¼Œé‡‡ç”¨ KL æ•£åº¦ç­‰æ–¹æ³•è®¡ç®—é‡åŒ–æ¯”ä¾‹å› å­ã€‚é™æ€é‡åŒ–ï¼ˆStatic quantizationï¼‰ä¸åŠ¨æ€é‡åŒ–çš„åŒºåˆ«åœ¨äºå…¶è¾“å…¥çš„ç¼©æ”¾å› å­è®¡ç®—æ–¹æ³•ä¸åŒï¼Œé™æ€é‡åŒ–çš„æ¨¡å‹åœ¨ä½¿ç”¨å‰æœ‰â€œcalibrateâ€çš„è¿‡ç¨‹ï¼ˆæ ¡å‡†ç¼©æ”¾å› å­ï¼‰ï¼šå‡†å¤‡éƒ¨åˆ†è¾“å…¥ï¼ˆå¯¹äºå›¾åƒåˆ†ç±»æ¨¡å‹å°±æ˜¯å‡†å¤‡ä¸€äº›å›¾ç‰‡ï¼Œå…¶ä»–ä»»åŠ¡ç±»ä¼¼ï¼‰ï¼Œä½¿ç”¨é™æ€é‡åŒ–åçš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­é‡åŒ–æ¨¡å‹çš„ç¼©æ”¾å› å­ä¼šæ ¹æ®è¾“å…¥æ•°æ®çš„åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ã€‚ä¸€æ—¦æ ¡å‡†å®Œæˆåï¼Œæƒé‡å’Œè¾“å…¥çš„ç¼©æ”¾å› å­éƒ½å›ºå®šï¼ˆâ€œé™æ€â€çš„ç”±æ¥ï¼‰ã€‚é™æ€é‡åŒ–çš„æ€§èƒ½ä¸€èˆ¬æ¯”åŠ¨æ€é‡åŒ–å¥½ï¼Œå¸¸ç”¨äºä¸­ç­‰æ¨¡å‹å’Œå¤§æ¨¡å‹ã€‚å› æ­¤å®é™…ä¸­åŸºæœ¬éƒ½æ˜¯åœ¨ç”¨é™æ€é‡åŒ–ã€‚ é™æ€ç¦»çº¿é‡åŒ–çš„ç›®æ ‡æ˜¯æ±‚å–é‡åŒ–æ¯”ä¾‹å› å­ï¼Œä¸»è¦é€šè¿‡å¯¹ç§°é‡åŒ–ã€éå¯¹ç§°é‡åŒ–æ–¹å¼æ¥æ±‚ï¼Œè€Œæ‰¾æœ€å¤§å€¼æˆ–è€…é˜ˆå€¼çš„æ–¹æ³•åˆæœ‰MinMaxã€KLDã€ADMMã€EQç­‰æ–¹æ³•ã€‚ å¯¹ç§°é‡åŒ–ä¸éå¯¹ç§°é‡åŒ–ï¼šå¯¹äºweightæƒé‡çš„é‡åŒ–ä½¿ç”¨å¯¹ç§°é‡åŒ–[-INT_MAX, INT_MAX]ï¼Œå¯¹äºactivateæ¿€æ´»çš„é‡åŒ–ä½¿ç”¨éå¯¹ç§°é‡åŒ–[0, INT_MAX]ï¼›","tags":[],"categories":[{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"}]},{"title":"Memo | Package and Device","date":"2023-09-19T14:56:53.000Z","path":"jottings/languages/shell/memo_package_device/","text":"Package Package System Package Management System Linux Release Version Debian Style (.deb) Debian, Ubuntu Red Hat Style (.rpm) Fedora, CentOS A package file is a compressed collection of files that make up a software package and may contain a large number of programs and the data files that support those programs. Metadata for the packet is included, such as a text description of the package and its contents. Other included are pre-installation and post-installation scripts (which perform configuration tasks before and after installation) Upper Tools and Underlying Tools: Linux Release Version Underlying Tool (install and delete packages) Upper Tool (search for metadata and resolve dependencies) Debian-Style dpkg apt, aptitude Fedora, CentOS rpm yum Search for metadata in the resource repository Style Command Debian apt update; apt search search_string Red Hat yum search search_string (e.g. yum search emacs) Install a package via resource repository Style Command Debian apt update; apt install package_name Red Hat yum install package_name Install a package via raw package files Style Command Debian dpkg â€“install &#x2F; -i package_file Red Hat rpm -i package_file (rpm -i emacs-22.1-7.fc7-i386.rpm) NOTE: Due to this command is executed by rpm, not analyzing dependencies for package_file, so if a dependency is missing, rpm will report error and exit. Uninstall a package Style Command Debian apt remove package_name &#x2F; dpkg -r package_name Red Hat yum erase package_name Upgrade package via resource repository Style Command Debian apt update; apt upgrade Red Hat yum update Upgrade package via package_file Style Command Debian dpkg â€“install package_file Red Hat rpm -U package_file List all package installed Style Command Debian dpkg â€“list &#x2F; -l Red Hat rpm -qa Determine whether a package is installed Style Command Debian dpkg â€“status package_name Red Hat rpm -q package_name Show the info for the installed package Style Command Debian apt show package_name Red Hat yum info package_name apt useful arguments: -y : default set yes in interactive shell; -f: solve the package dependencies; Device","tags":[{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Summa |Networks Tidbits","date":"2023-09-07T10:35:53.000Z","path":"jottings/networks/memo_network_tidbits/","text":"Tunneling: The basic principle is to create a virtual channel between the source and the target, through which the original packets is encapsulated in the packet of another protocol, and then transmitted between the source and the target. At the target end, the receiver unwarps the encapsulated packet, reverts it to the original packet, and gives it to the target application for processing. For example, VPN (Virtual Private Network), SSH Tunneling, GRE (Generic Routing Encapsulation, like IPv6 over IPv4).","tags":[{"name":"networks","slug":"networks","permalink":"https://stu-yue.github.io/tags/networks/"}],"categories":[{"name":"networks","slug":"networks","permalink":"https://stu-yue.github.io/categories/networks/"}]},{"title":"Memo | Olds and Ends","date":"2023-09-06T07:56:53.000Z","path":"jottings/languages/shell/memo_others/","text":"Difference between sh and bash: sh is usually symbolic link for dash; dash is a more lightweight shell, POSIX, designed to replace sh and provide faster startup and executions speeds; bash is an extended version of sh, and most scripts that conform to sh syntax should work fine in bash; In a nutshell, sh is bash, which enables the POSIX standard. POSIX, Portable Operating System Interface of UNIX In accordance with the POSIX specification, â€œWhen a line of code encounters an error, it does not continue to interpret subsequent lines.â€ However, in bash, even if an error occurs, it will continue to execute subsequent lines. To view cpu information: lscpu, or cat /proc/cpuinfo;","tags":[{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | Permission, Progress and Shell Environment","date":"2023-08-31T14:56:53.000Z","path":"jottings/languages/shell/memo_permission_progress_env/","text":"PermissionFirst of all, letâ€™s take a quick look at the permissions-related commands. id: To show the id number of the user. id username: chmod: To change the mode of files. symbolic examples: 123u (user), g (group), o (other), a (all)+, -, =u+x u-x +x[=a+x] o-rw, go=rw u+x,go=rw umask: To set default file permissions (before creating). an example: 1234# umask is 0002Original file mode | --- rw- rw- rw-Mask | 000 000 000 010Result | --- rw- rw- r-- su: To run the shell as another user. su - username, - can enter the home directory. sudo: To execute the command as another user. chown: To change the file owner. chown [owner[:group]] file..., here are some examples: Example Explanation bob change the file owner to bob bob:users change the file owner to bob, group to users :admins change the group to admins, file owner remains the same bob: change the file owner to bob, group to bobâ€™s login group chgrp: To change the group ownership of files. chgrp groupname file... passwd: To change the userâ€™s password. passwd username: set userâ€™s password. User information is stored in /etc/passwd, group information is stored in /etc/group; use the command cat /etc/passwd to have a quick look. 123456789101112131415161718192021cat /etc/passwd | grep ubuntu # username:passwd:uid:gid:comment:home_dir:shell# passwd (x) denotes that password is protected in /etc/passwd# comment store some useful comments (like username)ubuntu:x:1000:1000:ubuntu:/home/ubuntu:/bin/bash sudo cat /etc/shadow | grep ubuntu #username:passwd(encrypted):last_modify_time:min_interval:max_intervalubuntu:$1$oQIzlBrL$MErhwMGkTzqaeWkJNzpUh1:19132:0:99999:7::: cat /etc/group | grep cdrom # groupname:passwd:gid:group_membercdrom:x:24:ubuntu,yue sudo cat /etc/gshadow | grep test # groupname:passwd:group_manager:group_membertest:*:yue:ubuntu Permission Overview: r w x File readable writable executable Directory readable writable to files in the directory enterable to the directory Home directory default permission: user &#x3D;rwx, go&#x3D;r-x ; setuid (s/S &lt;-&gt; x/-, 4000/u+s) : It set valid user ID from the running userâ€™s ID to the file ownerâ€™s ID; setgid (g/G &lt;-&gt; x/-, 2000/g+s): Run not with the permissions of the group to which the user who started it belongs, but with the group that owns the file. In other words, the process gid is the same as the file gid. sticky (t/T &lt;-&gt; x/-, 1000/o+t): It has no effect on files, but when it is used on a directory, all files in the directory can only be deleted or moved by their owner. File Type: Tag Type - a normal file d a directory l a symbolic link (real file property is the file property that the symbolic link points to) c a character device file (process bytes stream, like terminal) b a block device file (process blocks, like hard-disk or CD-ROM) User and GroupBecause the permission is too large, you can even delete system files and crash the system. Therefore, you are not recommended to directly use root account. On Linux systems, sudo is used as the default root identity for standard users. Next, we have some commands for managing users and groups. groupadd: create a new work group, whose info is added to /etc/group, /etc/gshadow and so on. [-g gid] (specify the id of new group), -r (create system working groups) groupdel: delete a group gpasswd [options] groupname: management tool the /etc/group and /etc/gshadow -a/d username (add&#x2F;delete user to group) -A (specify the manager) -r/R (cancel the password for the group, then only group member can newgrp to access the group) -M user1,user2... add users to group groupmod: change the group information -g gid (change group id) -n new_name old_name (change group name) newgrp groupname: Itâ€™s using the same account another group name, to log into the system again. useradd: create a new user. -m/M (automatically &#x2F; not create a user home directory), -g (specify the login group), -G grp1,grp2... (specify the supplementary groups) -d (specify the starting directory for the user to log in to), -r (create a system account) -s (specify the login shell) -n (cancel creating a group with the user name) -p (specify the password, or later run the command passwd to set) useradd -m -g root username, useradd -d /home/test username userdel: -r (recursively delete) Initial Login Group, is a group that a user owns immediately upon login. Itâ€™s usually specified with -g when creating a user. The GID in the user info (/etc/passwd) is login group. A userâ€™s additional group is to assign additional permission to the specified user. (There can be only one login group and multiple supplementary group) usermod: modify the settings of the user account. -d: set login directory of the user account -e: set validity period â€¦ -g: set the login group â€¦ -G: set the supplementary group â€¦ -s: set the shell used after login â€¦ -l new_name old_name: set the new username â€¦ -L/U: lock&#x2F;unlock the account â€¦ -p: set the new password â€¦ ProgressWhen the system starts, the kernel initializes some of its own activities as Init Process (PID 1). In turn, a series of shell scripts called Init Scripts (located in /etc) are run, which can start all system services. Many of these system services are implemented in the form of daemons, which run only in the background without any user interface (inaccessible). Here are some of the command-line tools available: ps: To view the snapshot of process status; common parameter aux (show all processes) 1234567ubuntu@VM-16-17-ubuntu:/etc$ ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND# TTY: ? denotes terminal running locally, Pts/n denotes terminal running remotely# VSZ: virtual memory size# RSS: physical memory size occupied by process# STAT: R(running), S(sleeping), D(uninterruptible sleeping), T(terminal), Z(zombie) &lt;(high priority) N(low priority) Ctrl-C: send a SIGIN Ctrl-D: send a EOF Ctrl-Z: send a SIGSTP, pause ongoing process on the terminal so as to be resumed when necessary. top: To displays a continuously updated list of system process in order of process activity (default, refresh per 3s); jobs: bg: fg: kill: To send signals to programs (kill [-signal] PID...); NO. NAME EXPLANATION 1 HUP Hang up, this signal is used to tell the program that the control terminal has â€œhung up.â€ You can show what this signal does by closing a terminal session. Foreground programs running on the current terminal will receive this signal and terminate. Many daemons also use this signal to re-initialize. 2 INT like Ctrl-c 9 KILL The KILL signal is never sent to the target program. Instead, the kernel immediately terminates the process. When a process is terminated in this way, it has no opportunity to do any â€œcleaningâ€ or saving work. 15 TERM Terminal, this is default signal sent by KILL 18 CONT Continue, after getting a stop signal, program will be resumed by CONT 19 STOP like KILL, STOP is not sent to the target process, so it cannot be ignored å…¶ä»–å¸¸ç”¨ä¿¡å·ï¼š NO. NAME EXPLANATION 3 QUIT 11 SEGV If a program uses memory illegally, this signal will be sent 20 TSTP Ctrl-z will trigger this signal to cause terminal stop, unlike STOP, it can be ignored killall: To send signals to multiple processes that match a particular program or username (killall [-u user] [-signal] name...); shutdown: To shutdown the machine or reboot; Shell Environment printenv: set: To display existing shell variables in the system and set new variable values for shell variables. When user log in to the system, the bash program starts and reads a series of configuration scripts (startup files that define a default environment for all users), then it reads the startup files in the home directory that define the userâ€™s personal shell environment. The exact startup order depends on the type of shell session you want to run. There are two types, one is login shell session (need username and password), the other is non-login shell session (start under the GUI). Login shell startup order: File Usage &#x2F;etc&#x2F;profile global conf script applying to all users ~&#x2F;.bash_profile userâ€™s personal startup file, used to extend or override settings in global conf script ~&#x2F;.bash_login if ~&#x2F;.bash_profile is not found, bash will try to read this script Non-login shell startup order: File Usage &#x2F;etc&#x2F;bash.bashrc global conf script applying to all users ~&#x2F;.bashrc userâ€™s personal startup file, used to extend or override settings in global conf script In addition to reading the startup files above, non-login shell also inherit the environment settings of their parent process, usually a login shell. In general usersâ€™ points, the file ~&#x2F;.bashrc is probably the most important startup file because itâ€™s almost always read. Non-login shells read it by default, and most startup files for login shells are written in such a way that they can read ~&#x2F;.bashrc . The below is a typical .bash_profile file (From CentOS 4): 12345678# .bash_profile# Get the aliaes and functionsif [ -f ~/.bashrc ]; then. ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/binexport PATH export: export environment variables; alias: create alias for command; Refref1","tags":[{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | Parameter Estimation","date":"2023-08-30T05:56:53.000Z","path":"jottings/mathematics/memo_mle_mae_bayes/","text":"Through this note, I hope to deepen my understanding of probability distribution and inference. Preface Probability: to predict results obtained in the next observation when parameters are known; Statistic&#x2F;Likelihood: to estimate parameters about properties when the result of observations are known; Parametric Method: assume that the learned distribution has a specific functional form (like Gaussian distribution or exponential p.d.f), we only estimate the parameters in these functions. Nonparametric Method: use the training samples to estimate the density of any point in the domain. Nonparametric methods also have parameters, we just donâ€™t assume any specific functional form for distribution; Actually, nonparametric methods treat all training samples as parameters; example: kernel density estimation; Under the joint distribution $p_{X,Y}(X,Y)$: When the effect of $Y$ is removed from the joint distribution $p_{X,Y}(X,Y)$, marginal distribution $p_X(X)$ is called marginal likelihood; When $X$ has not yet been observed, marginal distribution $p_Y(Y)$ is called prior distribution; Posterior Distribution: $p(\\theta|\\mathcal{D}) &#x3D; \\frac{p(\\mathcal{D},\\theta)}{p(\\mathcal{D})}$, concentrating Population Info, Sample Info and Prior Info; $p(\\mathcal{D})$ is marginal likelihood; $\\text{Posterior} &#x3D; \\frac{\\text{Likelihood}\\times \\text{Prior}}{\\text{Marginal Likelihood}}$, in terms of $p(Y|X) &#x3D; \\frac{1}{Z}p(X|Y)p(Y)$, $Z&#x3D;p(X)&gt;0$ is a normalized constant such that $p(Y|X)$ is a valid probability distribution. The Views Frequentist: Data are repeatable random sample - there is a frequency; Underlying parameters remain constant during this repeatable process; Parameters are fixed value; statistical inference: Population Info + Sample Info MLE, MAP; Bayesian: Data are observed from the realized sample; Parameters are unknown (random variable) and described probabilistically (prior distribution); statistical inference: Population Info + Sample Info + Prior Info (Main Diff); Bayesian Estimation; Notations Training Data: $\\mathcal{D} &#x3D; { (\\mathbf{x_1}, y_1),\\cdots,(\\mathbf{x}_n, y_n) }$; Model Parameter: $\\theta$; New Data: $x^*$; Maximum Likelihood Estimation Objective is$$\\theta_{MLE}^* &#x3D; \\arg\\max_\\theta p(\\mathcal{D}|\\theta)$$ $p(\\mathcal{D}|\\theta)$ is likelihood, not conditional probability; Usually, we define$$\\mathscr{l}(\\theta) &#x3D; p(\\mathcal{D}|\\theta) \\\\mathscr{ll}(\\theta) &#x3D; \\ln \\mathscr{l}(\\theta)$$So, objective is equivalent to$$\\theta_{MLE}^* &#x3D; \\arg\\max_\\theta \\mathscr{ll}(\\theta)$$That is, we seek those values for the parameters in $\\theta$ which maximize $p(\\mathcal{D}|\\theta)$. The MLE solution is usually obtained by setting$$\\frac{\\partial \\mathscr{ll}(\\theta)}{\\partial\\theta} &#x3D; 0$$ However, the modelâ€¦ Does not incorporate prior belief; Easy to overfit the data; Maximum A Posteri Estimation Objective is$$\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta p(\\theta|\\mathcal{D})$$Since we have Bayes rule:$$p(\\theta | \\mathcal{D}) &#x3D; \\frac{p(\\mathcal{D})p(\\theta)}{p(\\mathcal{D})}$$Our objective is equivalent to$$\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta p(\\mathcal{D}|\\theta)p(\\theta)$$Further, by taking the log$$\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta {\\ln p(\\mathcal{D}|\\theta) + lnp(\\theta) } \\\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta { \\mathscr{ll}(\\theta) + \\ln p(\\theta) }$$Thus, our final goal is to find$$\\theta^*_{MAP} &#x3D; \\arg\\max_\\theta { \\mathscr{ll}(\\theta) + \\ln p(\\theta) }$$The difference between MAP and MLE is the â€œextraâ€ term - $p(\\theta)$. The term is: our prior (belief) also can be seen as penalty (regularization) - to reduce the overfitting. For $p(\\theta|\\mathcal{D})$, in terms of point estimation for $\\theta$, using the maximum value is called Maximum A Posterior Estimation; using the median value is called Posteriror Median Estimation; using the expectation value is called Posterior Expectation Estimation; Bayesian Estimation $p(\\theta|\\mathcal{D})$ (itâ€™s the result of adjustments to prior $p(\\theta)$ by population and sample); Equal Ignorance: If thereâ€™s no information about the prior distribution, assume $\\theta \\sim U(0,1)$ ; Learning: Computing the posterior $p(\\theta|\\mathcal{D})$ ; Prediction: $p(\\hat y | x^*,\\mathcal{D}) &#x3D; \\int_\\theta p(\\hat y | x^*,\\theta)p(\\theta|\\mathcal{D})d\\theta$ ; Both MLE and MAP return only single and specific values for the paramter $\\theta$; Bayesian estimation, by contrast, calculates fully the posterior distribution $p(\\theta|\\mathcal{D})$, and making prediction by considering all possible $\\theta$. Thus, for Bayesian methods: The prediction is optimal Avoid the overfitting Bayesian is powerful, butâ€¦ We need to compute posterior distribution $p(\\theta|\\mathcal{D})$, and$$p(\\theta|\\mathcal{D}) &#x3D; \\frac{p(\\mathcal{D}|\\theta)p(\\theta)}{\\int p(\\mathcal{D},\\theta)d\\theta}$$In practice, evaluating this posterior is usually intractable due to the complex integralsâ€¦ ReferenceMainly Ref Ref2 Ref3","tags":[{"name":"math","slug":"math","permalink":"https://stu-yue.github.io/tags/math/"}],"categories":[{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"}]},{"title":"Summa | Intro of Statistical ML","date":"2023-08-27T07:56:53.000Z","path":"jottings/statistics_ml/summa_intro/","text":"If a system is able to improve its performance by executing a certain process, it is called learning. 1 Basis Hypothesis Space: The set of functions that includes all possible models to be learned. Common Steps: Attain a finite training data set. Determine the set of learning models. Determine the criteria for model selection (learning strategies). Develop algorithms for solving the optimal model (learning algorithm). Select optimal model according to criteria. Use the learned optimal model to predict or analyze new data. Problem Types: Classification&#x2F;Tagging (outputs take a finite number of discrete values), Regression (function fitting, real values) Model Types: Discriminative Model: directly model $p(Y|X)$; Cons: easy to learn, high classification accuracy; Generative Model: model $p(X, Y)$, usually translating to modeling the prior distribution $p(Y)$ and class conditional distribution $p(X|Y)$, due to ($p(X, Y)&#x3D; P(X|Y)p(Y)$); Cons: add the prior distribution [main diff], model the data generation process;","tags":[{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"},{"name":"statistic","slug":"statistic","permalink":"https://stu-yue.github.io/tags/statistic/"}],"categories":[{"name":"statistics_ml","slug":"statistics-ml","permalink":"https://stu-yue.github.io/categories/statistics-ml/"}]},{"title":"Memo | Algebra Basis","date":"2023-08-27T07:56:53.000Z","path":"jottings/mathematics/memo_algebra_basis/","text":"**Positive Definiteness of the Norm: ** According to the usual definition, a norm should satisfy the property of positive definiteness which means that a norm must have a non-negative value for non-zero vectors and only attain zero when the vector is the zero. **Norm and Distance Evaluation: ** Norm Distance $L_0\\ \\text{norm}$ : $ $L_1\\ \\text{norm}$ : $ $L_2\\ \\text{norm}$ : $ $L_p\\ \\text{norm}$ : $ $\\text{Infinite norm}$ : $ Normed Space: Normed space introduces a norm (or length, modulus) concept on the basis of linear space.","tags":[{"name":"algebra","slug":"algebra","permalink":"https://stu-yue.github.io/tags/algebra/"}],"categories":[{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"}]},{"title":"Memo | See the World through Shell","date":"2023-08-27T07:56:53.000Z","path":"jottings/languages/shell/memo_see_the_world_through_shell/","text":"In this post, thereâ€™re other commands we should be familiar with: echo: To display a line text. -e (explain the escape sequences) clear: history: To display the history list content. list history commands: sequence conduct !! repeat the last command executed !number repeat the number line command in the history !string repeat the command starting with this string !?string repeat the command containing this string Expansions in Shell Mathematical Expression: Format: $((expression)), for example, echo $((2 + 2)); Operators: +, -, *, / (integer division), %, ** (exponentiation); Curly Brackets (or Braces): Curly braces can create multiple text characters. Generally speaking, a pattern in curly braces may contain a header and a postscript. The curly brace expression itself may contain a list of strings separated by commas, an integer interval, or a single character interval. Whitespace characters cannot be embedded in this mode. echo Number_&#123;1..5&#125;, echo &#123;Z..A&#125;, echo Front-&#123;A,B,C&#125;; mkdir &#123;2007..2009&#125;-0&#123;1..9&#125; &#123;2007..2009&#125;-&#123;10..12&#125; Furthermore, curly braces can be nested: 12echo a&#123;A&#123;1,2&#125;,B&#123;3,4&#125;&#125;baA1b aA2b aB3b aB4b Parameter Expansion: Command Substitution: Use the output of a command as expansion mode: ls -l $(which cp), echo$(ls), file $(ls /usr/bin* | grep zip); In the old shell, [&#96;&#96;] can replace [$()]: 1ls -l `which cp` Double Quotation: In double quotes, the special characters used by the shell lose their special meaning and are treated as ordinary characters. Mathematical expansion, parameter expansion and command substitution are still performed. (Double quotation can retain whitespace) ls -l &quot;two words.txt&quot;, echo &quot;$USER $((2+2)) $(cal)&quot;; echo &quot;$(cal)&quot; is different with echo $(cal), try it. Single Quotation: Single quotation disables all mode expansions. 123456ubuntu@VM-16-17-ubuntu:~$ echo text ~/*.txt &#123;a,b&#125; $(echo foo) $((2+2)) $USERubuntu@VM-16-17-ubuntu:~$ echo &quot;text ~/*.txt &#123;a,b&#125; $(echo foo) $((2+2)) $USER&quot;ubuntu@VM-16-17-ubuntu:~$ echo &#x27;text ~/*.txt &#123;a,b&#125; $(echo foo) $((2+2)) $USER&#x27;text /home/ubuntu/lazy_dog.txt /home/ubuntu/ls.txt a b foo 4 ubuntutext ~/*.txt &#123;a,b&#125; foo 4 ubuntutext ~/*.txt &#123;a,b&#125; $(echo foo) $((2+2)) $USER **Backslash: ** \\ can escape special characters in shell, but not in single quotes. 12echo &quot;The balance for user $USER is: \\$5.00&quot;mv bad\\&amp;filename good_filename NOTE: 1$&quot;abc&quot;, $&quot;\\n&quot; The above is a special string conversion syntax used to localize strings (with Settings such as the environment variable LANG or LC_MESSAGES). 1$&#x27;abc&#x27;, $&#x27;\\n&#x27;, $&#x27;ab\\tc&#x27; When you use the form $â€™abcâ€™ in the Shell, the Shell extends the string and replaces the special characters with the corresponding escape sequence. Supplement $()ä»…åœ¨Bash Shellä¸­æœ‰æ•ˆï¼Œåå¼•å·å¯åœ¨å¤šç§Shellä¸­ä½¿ç”¨ï¼›å®ƒä¿©ä½œç”¨éƒ½æ˜¯æ‰§è¡Œå‘½ä»¤ $()æ˜¯æ–°ç”¨æ³•ï¼Œ``æ˜¯è€ç”¨æ³•ï¼›$()æ”¯æŒåµŒå¥—â€”â€”å¦‚$(wc -l $(ls | sed -n &#39;1p&#39;)); å•å¼•å·ï¼ˆâ€™ï¼‰æ‰€è§å³æ‰€å¾—ï¼Œç›´æ¥æ˜¾ç¤ºå•å¼•å·é‡Œçš„å†…å®¹ã€‚å³å•å¼•å·é‡Œçš„ä»»ä½•å­—ç¬¦éƒ½ä¼šåŸæ ·è¾“å‡ºï¼Œå•å¼•å·å­—ç¬¦ä¸²ä¸­çš„å˜é‡æ˜¯æ— æ•ˆçš„ï¼› åŒå¼•å·ï¼ˆâ€œï¼‰å…ˆæŠŠå˜é‡è§£æä¹‹åï¼Œå†è¾“å‡ºï¼›åŒå¼•å·æ‹¬èµ·æ¥çš„å­—ç¬¦ä¸­ï¼ˆ$ï¼Œ\\ï¼Œ`)ï¼Œä¸»è¦æ˜¯åŒºåˆ†ç©ºæ ¼ $ ä»£è¡¨å¼•ç”¨å˜é‡çš„å€¼ï¼› \\ æ˜¯è½¬ä¹‰å­—ç¬¦ï¼› ` ä»£è¡¨å¼•ç”¨å‘½ä»¤ï¼› echo -eå¯ä»¥è¯†åˆ«åŒå¼•å·ä¸­çš„è½¬ä¹‰å­—ç¬¦ï¼› åå¼•å·ç”¨äºå‘½ä»¤æ›¿æ¢ï¼Œå³å…ˆæ‰§è¡Œåå¼•å·ä¸­çš„è¯­å¥ï¼Œå†æŠŠç»“æœåŠ å…¥åˆ°åŸå‘½ä»¤ä¸­ï¼› $&#123;a&#125;å’Œ$aä¸€æ ·ï¼Œæ•°ç»„åˆ™éœ€è¦$&#123;array[0]&#125;ï¼› https://blog.csdn.net/qq_39852676/article/details/90228973 Vim1 æ›¿æ¢å­—ç¬¦ä¸²1234567891011:[range]s/&#123;pattern&#125;/&#123;string&#125;/[flags] [count]range: .,$s/foo/bar/ .è¡¨ç¤ºå½“å‰è¡Œ 3,10s/foo/bar/ 3-10è¡Œ %s/foo/bar/ æ•´ä¸ªæ–‡æœ¬ flags: i:å¿½ç•¥å¤§å°å†™ g:å‡ºç°çš„æ‰€æœ‰æ¨¡å¼ c:ç¡®è®¤æ¯æ¬¡æ›¿æ¢ https://cloud.tencent.com/developer/article/2015348","tags":[{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | Redirection","date":"2023-08-25T06:56:53.000Z","path":"jottings/languages/shell/memo_redirection/","text":"Input&#x2F;output redirection is achieved by modifying file pointers. When redirection occurs, file descriptors themselves are not changed, instead, itâ€™s the file pointers associated with the file descriptors that are altered. Manipulation of File Descriptors in Shell In redirection, &amp; is used to indicates the following numbers is file descriptor rather than a filename. Output Redirection: stdiout redirection: command &gt;file: [overwrite], stdout overwrites the file. &gt; file: clear the content. command &gt;&gt;file: [append], stdout appends to the file. stderr redirection: command 2&gt;file: [overwrite], stderr overwrites the file. command 2&gt;&gt;file: [append], stderr appends to the file. Both stdout and stderr: command &gt;file 2&gt;&amp;1: [overwrite], both stdout and stderr overwrite the file. command &gt;&gt;file 2&gt;&amp;1: [append], both stdout and stderr append to the file. command &gt;file1 2&gt;file2: stdout overwrites the file1, stderr overwrites the file2. command &gt;&gt;file1 2&gt;&gt;file2: stdout appends to file1, stderr appends to file2. command &gt;file 2&gt;file: [not recommend] file is opened twice, leading to resource competition. command &gt;&gt;file 2&gt;&gt;file: [not recommend] file is opened twice, leading to resource competition. Input Redirection: command &lt;file: take the contents of the file as the input to command. 1234#!/bin/bashwhile read str; do echo $strdone &lt;readme.txt command &lt;&lt;END: read data from standard input (keyboard) until meeting the delimiter END (defined by the user). command &lt;file1 &gt;file2: input by file1, and output to file2 &amp;&gt;: redirect both stdout and stderr to the same location (usually a file). &gt;&amp;: redirect the output of one file descriptor to another &gt;&amp;-: equal to redirection to /dev/null PipelinePipeline is used to link the stdout of the previous instruction as the stdin of the next instruction. Pipeline is often used to perform complex operations on data. Itâ€™s possible to put several commands together to form a pipeline (usually called filter). For example: 1ls /bin /usr/bin | sort | uniq | less CommandThereâ€™s some useful command in this memo: cat: To link file. cat can accept not one parameter, so it can concatenate the file: cat movie.mpeg.0* &gt; movie.mpeg; sort: To sort the text lines. uniq: To report&#x2F;omit the repetitive lines. grep: To print the matching rows. -i (ignore upper&#x2F;lower), -v (reverse find, print mismatching lines), -n (show the matching lines), -r (recursively find), -l (only print matching filename), -c (only print the number of matching line) wc: To print the LF, word, bytes of the text. -c (bytes), -l (lines), -w (words) head&#x2F;tail: To print first&#x2F;last part of text. -n (lines), -c (bytes) tail -f filename: continue to monitor this file, when the new is added to the file, they appear immediately on the screen. tee: read from stdin, and write to stdout and file. -a (append mode), -i (ignore-interrupts) ls -l | tee -a ls.log : print the content both in the stdout and file. ls /usr/bin | tee ls.log | grep zip","tags":[{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Memo | GIL and Coroutine","date":"2023-08-10T08:01:53.000Z","path":"jottings/languages/python/memo_GIL_and_coroutine/","text":"GIL (Global Interpreter Lock) GIL is not a characteristic of Python itself, but rather a characteristic to CPython, the reference implementation of Python. In CPython, GIL is a mutex lock used to ensure that only on thread is executing at a time within a process. In the absence of the GIL, itâ€™s possible for multiple threads executing the same code simultaneously to cause incorrect reference counting of variables, leading to the garbage collector directly reclaiming the variables involved in the executed code. This can result in errors when other threads attempt to use those reclaimed variables. How to work: Each thread acquires the GIL at the beginning of its execution to prevent other threads from preempting. Similarly, after each thread completes a segment of code (or before system calls that may cause blocking, such as IO operations), it releases the GIL to allow other threads to utilize resources. In CPython, thereâ€™s another mechanism called check_interval, where the interpreter periodically checks the status of the GIL lock for threads. After a certain interval, the interpreter forces the current thread to release the GIL, allowing other threads to have opportunity to execute. Overall, each Python thread is encapsulated in a similar loop structure. Letâ€™s take a look at the following code: 12345678910111213for (;;) &#123; if (--ticker &lt; 0) &#123; ticker = check_interval; /* Give another thread a chance */ PyThread_release_lock(interpreter_lock); /* Other thread may run now */ PyThread_acquire_lock(interpreter_lock); &#125; bytecode = *next_instr++; switch(bytecode) &#123; /* execute the next instruction ... */ &#125;&#125; The above example represents instruction counting, while the current approach is mostly based on time slicing. Hereâ€™s another example that demonstrates GILâ€™s working principle: 123456789101112131415161718# coding=utf-8from threading import Threadfrom multiprocessing import Processdef test(): # endless loop for full CPU utilization while True: pass# multi-thread version:# t1 = Thread(target=test)# multi-process version:t1 = Process(target=test)t1.start()# main thread executionwhile True: pass When the multi-thread code running, we can observe the CPU utilization from htop as shown below: 121 [50%]2 [50%] According to the above, we can know that each thread spends their a half time waiting for GIL. Additionally, the multi-process version as shown below: 121 [100%]2 [100%] The other way to utilize multi-core CPU is Multi-Process or Coroutine GeneratorGenerator contains the yield keyword to produce values. It has the following characteristics: Laziness: Generators are lazy in nature, meaning they produce values on-demand as requested by the caller, rather than generating all the values at once. This lazy evaluation allows for efficient memory usage, especially when dealing with large or infinite sequences. Memory efficiency: Due to their lazy evaluation, generators are memory-efficient. Iterability: Generators are iterable objects, which means they can be looped over using a for loop or consumed by other iterable functions like list() or sum(). They provide a convenient way to iterate over a sequence of values without the need to store the entire sequence in memory. State persistence: Generators maintain their internal state between successive calls. When a generator function is paused at a yield statement, the local variablesâ€™ values are preserved. This allows the generator to resume execution from where it left off, retaining the necessary information to generate the next value. Infinite sequences: Generators can be used to represent infinite sequences since they generate values on-the-fly. Function-like behavior: Generators are defined using the def keyword like regular functions, and they can have parameters, return values, and other function features. However, they differ in their execution behavior, as they can be paused and resumed. When the generator function finishes executing (no more yield statements or returns), the generator object raises a StopIteration exception. yield from is a syntactic sugar that allows delegation of generator execution within a generator function. It provides a concise way to call a sub-generator from a parent generator and directly pass the values yielded by the sub-generator to the parent generator. 123456789101112def sub_generator(): yield &#x27;A&#x27; yield &#x27;B&#x27; yield &#x27;C&#x27; def parent_generator(): yield &#x27;START&#x27; yield from sub_generator() yield &#x27;END&#x27; for item in parent_generator(): print(item) yield and send are used together to allow the generator function to receive values during each iteration and send values back into the generator function for processing. Here is an example of how yield and send are used: 1234567891011121314151617def generator_function(): result = yield # First call, receives a value sent by send() while True: print(&#x27;gen&#x27;, result) result = yield resultgen = generator_function()# Start the generatornext(gen) # or gen.send(None)output = gen.send(&quot;Hello&quot;)print(&#x27;out&#x27;, output)output = gen.send(&quot;World&quot;)print(&#x27;out&#x27;, output)# print result:# gen Hello# out Hello# gen World# out World generator.throw(AnyException) allows generator to throw an Exception, and generator.close() can stop the generator. CoroutineCoroutines are implemented using generator functions and the yield statement. The principle of coroutines is as follows: Coroutine Function Definition: Define a generator function as a coroutine function. This function can use the yield statement to specify suspension points, where it pauses execution and returns a value to the caller. Coroutine Initialization: Create a coroutine object by calling the coroutine function. Coroutine Iteration: Use the next() function or the .send() method of the coroutine object to iterate and execute the coroutine. When the coroutine encounters a yield statement, it pauses execution and returns the result to the caller. Coroutine Resumption: When the caller sends a value to the coroutine (using the .send() method), the coroutine resumes execution from the last paused position and uses the sent value as the result of the yield expression. Coroutine Termination: When the coroutine reaches the end of the function or encounters a StopIteration exception, the coroutine terminates. Further calls to the .send() method on the coroutine object will raise a StopIteration exception. Coroutines allow achieving concurrent execution without the need for multiple threads or processes. Coroutines can switch between different execution paths, enabling efficient asynchronous programming. Coroutines can also delegate to other coroutines using the yield from statement, enabling more complex cooperation and task decomposition. Python provides the asyncio module to support coroutine programming, where the async and await keywords offer a more concise syntax for defining and managing coroutines. With asyncio, it becomes easy to write asynchronous programs and handle tasks like I&#x2F;O operations, network communication, and more. Itâ€™s important to note that coroutines run in a single thread, so their performance may not be as good as multi-threading or multiprocessing when it comes to CPU-bound tasks. However, in I&#x2F;O-bound tasks, coroutines shine because they can effectively utilize the waiting time for I&#x2F;O to execute other tasks. Async&#x2F;Await async def is a keyword combination used in Python to define asynchronous functions. An asynchronous function is a special type of function that can contain await expressions, which suspend the execution of the function and wait for the completion of asynchronous operations. Here is a example: 12345678910111213141516import asyncio# Define an asynchronous functionasync def async_func(): print(&quot;Start&quot;) await asyncio.sleep(1) # Suspend function execution using await, waiting for the completion of an asynchronous operation print(&quot;End&quot;)# Run the asynchronous function in an event loopasync def main(): await async_func()# Create an event loop and run the main functionloop = asyncio.get_event_loop()loop.run_until_complete(main())loop.close() await is a keyword used to suspend the execution of an asynchronous function and wait for the completion of an asynchronous operation. await can only be used within an asynchronous context and is typically used in conjunction with async def. The general usage of await is as follows: Use await within an asynchronous function or coroutine to suspend its execution and wait for the completion of an asynchronous operation. For example: 123async def async_func(): result = await async_operation() # ç­‰å¾… async_operation() å¼‚æ­¥æ“ä½œçš„å®Œæˆ # ç»§ç»­å¼‚æ­¥æ“ä½œï¼Œä½¿ç”¨å¼‚æ­¥æ“ä½œçš„ç»“æœ result Note that await can only be used within asynchronous functions or coroutines. It is not valid to use await in synchronous code. Typically, await is followed by an awaitable object, such as an asynchronous function, coroutine, asynchronous iterator, etc. These awaitable objects must implement specific protocols, which include methods like __await__() or __aiter__(). The await expression invokes these methods to obtain an iterator or a context manager from the awaitable object and waits for its completion. Here are some common awaitable objects: Asynchronous functions or coroutines: Use await to wait for the execution of an asynchronous function or coroutine to complete. Asynchronous generators: Use await to iterate over asynchronous generators and wait for each generated value. Asynchronous iterators: Use await to iterate over asynchronous iterators and wait for each iteration value. Asynchronous context managers: Use await to enter and exit the context of an asynchronous context manager. For example: 123456async def async_func(): async with async_context_manager() as cm: await cm.do_something() # Wait for the completion of the asynchronous context manager async for item in async_iterator(): await process_item(item) # Wait for the completion of each item generated by the asynchronous iterator","tags":[{"name":"python","slug":"python","permalink":"https://stu-yue.github.io/tags/python/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"python","slug":"languages/python","permalink":"https://stu-yue.github.io/categories/languages/python/"}]},{"title":"Memo | Optimization Algorithm in Machine Learning","date":"2023-08-05T14:56:53.000Z","path":"jottings/mathematics/memo_optimization_alg/","text":"Reproduced in The Summary of Optimization Algorithm in ML For machine learning algorithms with diverse forms and characteristics, we have various optimization algorithms suitable for optimizing their objective functions. Apart from a few problems that can be solved using Brute Force Search to obtain the optimal solution, we can categorize the optimization algorithms used in machine learning into two types: Analytical Solutions: These algorithms aim to find the optimal solution to the objective function by solving mathematical equations or performing algebraic manipulations. They often involve setting derivatives or gradients to zero and solving the resulting equations. Analytical solutions are typically used for linear regression, logistic regression, and certain types of optimization problems with closed-form solutions. Numerical Optimization: These algorithms iteratively search for the optimal solution by evaluating the objective function at different points in the search space. They do not rely on explicit mathematical equations or derivatives. Numerical optimization methods include gradient-based algorithms like gradient descent and its variants, Newtonâ€™s method, stochastic gradient descent, and quasi-Newton methods. Global Optimization Methods: Heuristic Algorithm, Simulated Annealing, Particle Swarm Optimization, etc. Local Optimization Methods: Gradient Based: First Order Derivative: (Jacobian) Gradient Descent: $\\theta &#x3D; \\theta - \\eta \\cdot\\nabla J(\\theta)$ whereas Standard Gradient Descent will only converge to the minimum of the basin as mentioned above. SGD: $\\theta &#x3D; \\theta - \\eta \\cdot \\nabla J(\\theta;x_i;y_i)$; frequent updates, parameters updates have high variance and causes the Loss function to fluctuate to different intensities; helps us discover new and possibly better local minima; it ultimately complicates the convergence to the exact minimum and will keep overshooting due to the frequent fluctuations; Mini-Batch GD: ultimately lead us to a much better and stable convergence; make use of highly optimized matrix optimizations common to state-of-the-art deep learning libraries that make computing the gradient w.r.t. a mini-batch very efficient. Challenges in GD: Choosing a proper learning rate can be difficult; Additionally, the same learning rate applies to all parameter updates. If our data is sparse and our features have very different frequencies, we might not want to update all of them to the same extent, but perform a larger update for rarely occurring features. avoiding getting trapped in their numerous sub-optimal local minima; Actually, Difficulty arises in fact not from local minima but from *saddle points*, i.e. points where one dimension slopes up and another slopes down. These saddle points are usually surrounded by a plateau of the same error, which makes it notoriously hard for SGD to escape, as the gradient is close to zero in all dimensions. Momentum: $V(t) &#x3D; \\gamma\\cdot V(t-1)+\\eta \\cdot\\nabla J(\\theta)$, then $\\theta &#x3D; \\theta - V(t)$; leads to faster and stable convergence; reduced oscillations Problem: What actually happens is that as we reach the minima i.e the lowest point on the curve ,the momentum is pretty high and it doesnâ€™t knows to *slow* down at that point due to the high momentum which could cause it to miss the minima entirely and continue movie up. Nesterov accelerated gradient (NAG): $V(t) &#x3D; \\gamma\\cdot V(t-1)+\\eta\\cdot\\nabla J(\\theta - \\gamma\\cdot V(t-1))$, then $\\theta &#x3D; \\theta - V(t)$ï¼› In the method he suggested we first make a big jump based on out previous momentum then calculate the Gradient and then make an correction which results in an parameter update. Now this anticipatory update prevents us to go too fast and not miss the minima and makes it more responsive to changes. We know that we will use our momentum term Î³V(tâˆ’1) to move the parameters Î¸. Computing Î¸âˆ’Î³V(tâˆ’1) thus gives us an approximation of the next position of the parameters which gives us a rough idea where our parameters are going to be. We can now effectively look ahead by calculating the gradient not w.r.t. to our current parameters Î¸ but w.r.t. the approximate future position of our parameters AdaGrad: $\\theta_{t+1,i} &#x3D; \\theta_{t,i}-\\frac{\\eta}{\\sqrt{G_{t,i}+\\epsilon}}\\cdot g_{t,i}$, $G_{t,i} &#x3D; G_{t,i}+\\nabla_{\\theta_{t,i}}J(\\theta)$; allows the learning Rate $-\\eta$ to adapt based on the parameters. So it makes big updates for infrequent parameters and small updates for frequent parameters. For this reason, it is well-suited for dealing with sparse data. At the beginning, AdaGrad has an incentive effect on convergence, and then slowly becomes penalty convergence, and the updating speed is getting slower and slower Problem: its learning rate $-\\eta$ is always Decreasing and decaying. Due to: the accumulation of each squared Gradients in the denominator , since every added term is positive. This in turn causes the learning rate to shrink and eventually become so small, that the model just stops learning entirely and stops acquiring new additional knowledge. This problem of Decaying learning Rate is Rectified in another algorithm called AdaDelta. AdaDelta: $g(t)$ is gradient of mini-batch; RMSprop: $E[g^2]t &#x3D; \\gamma E[g^2]{t-1}+(1-\\gamma)g^2_t$, $\\Delta\\theta_t &#x3D; -\\frac{\\eta}{\\sqrt{E[g^2]_t+\\epsilon}}\\odot g_t &#x3D; -\\frac{\\eta}{RMS[g]_t}g_t$, $\\theta_{t+1} &#x3D; \\theta_t + \\Delta\\theta_t$ The authors note that the units in this update (as well as in SGD, Momentum, or Adagrad) do not match, i.e. the update should have the same hypothetical units as the parameter. To realize this, they first define another exponentially decaying average, this time not of squared gradients but of squared parameter updates; Thus, they use $RMS[\\Delta\\theta]_{t-1}$ instead of hyperparameter $\\eta$ ; $RMS[\\Delta\\theta]t &#x3D; \\sqrt{E[\\Delta\\theta^2]{t-1}+\\epsilon}$ $E[\\Delta\\theta^2]t &#x3D; \\gamma E[\\Delta\\theta^2]{t-1}+(1-\\gamma)\\Delta\\theta^2_t$ Instead of accumulating all previous squared gradients, *AdaDelta* limits the window of accumulated past gradients to some fixed size w. Another thing with AdaDelta is that we donâ€™t even need to set a default learning rate. What improvements we have done so farâ€”â€” We are calculating different learning Rates for each parameter. We are also calculating momentum. Preventing Vanishing(decaying) learning Rates. Since we are calculating individual learning rates for each parameter , why not calculate individual *momentum* changes for each parameter and store them separately. This is where a new modified technique and improvement comes into play called as *Adam.* Adam: Adaptive Moment Estimation (Adam) is another method that computes adaptive learning rates for each parameter. In addition to storing an exponentially decaying average of past squared gradients like AdaDelta ,Adam *also keeps an exponentially decaying average of past gradients M(t), similar to momentum*: $m_t &#x3D; \\beta_1m_{t-1}+(1-\\beta_1)g_t, \\quad v_t &#x3D; \\beta_2v_{t-1}+(1-\\beta_2)g^2_t$ $m_t &#x3D; (1-\\beta_1)\\sum_{i&#x3D;1}^{t}\\beta^{t-i}_{1}g_i$, sum all weights of $g_i$ is $(1-\\beta_1)\\sum_{i&#x3D;1}^{t}\\beta_1^{t-i} &#x3D; 1-\\beta^t_1$ To rectify the bias to 1, divide $(1-\\beta_1^t)$ respectively, $\\hat m_t &#x3D; \\frac{m_t}{1-\\beta_1^t}, \\quad \\hat v_t &#x3D; \\frac{v_t}{1-\\beta_2^t}$, $\\theta_{t+1} &#x3D; \\theta_t - \\frac{\\eta}{\\sqrt{\\hat v_t}+\\epsilon}\\hat m_t$ æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡$m_t$ï¼ŒæŒ‰å…ƒç´ å¹³æ–¹çš„æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡$v_t$ Second Order Derivative: (Hessian) Newton Method: Divide and Conquer: Coordinate Descent: SMO Algorithm: Staged Optimization: Dynamic Programming: The following picture illustrates the organization of this memorandum: Reference Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient Descent","tags":[{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"},{"name":"optimization","slug":"optimization","permalink":"https://stu-yue.github.io/tags/optimization/"}],"categories":[{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"}]},{"title":"Memo | Exploring Linux Files and Directories","date":"2023-08-05T02:56:53.000Z","path":"jottings/languages/shell/memo_exploring_os/","text":"Letâ€™s start by learning some commands that are helpful for researching Linux systems. type: To explain how to interpret a command name. which: To show which executable program will be executed. man: To show command manual. apropos: To display a list of appropriate commands. info: To display the command info. alias: To create an alias for the command unalias: To cancel a alias for the command. ls: To list the files and directories in the current directory. -a, -d, -h, -r/--reverse, -l, -S[sort by size], -t[sort by modification time] file: To determine the file type. file filename is OK. less: To browse the content of a file, specifically, less is an improved version of more. less filename is OK. Commands Behavior Page UP or b Backward one window Page Down or space Forward one window UP Arrow Backward one line Down Arrow Forward one line [N]G Go to last line in file (or N lines) [N]g Go to first line in file (or N lines) &#x2F;characters Search forward for matching line n Repeat previous search h Display help. cpï¼š Options Implication -a, â€“archive Copy files and directories, along with their attributes, including ownership and permissions -i, â€“interactive Prompt the user for confirmation before overwriting an existing file (default disable) -r, â€“recursive -u, â€“update Update the content not already present in the original -v, â€“verbose Display detailed command operation information mv: Options Implication -i, â€“interactive Prompt the user for confirmation before overwriting an existing file (default disable) -u, â€“update Update the content not already present in the original -v, â€“verbose Display detailed command operation information rm: Options Implication -f, â€“force Directly delete the file even if its attributes are read-only, without requiring individual confirmation -i, â€“interactive Prompt the user for confirmation before overwriting an existing file (default disable) -r, â€“recursive -v, â€“verbose Display detailed command operation information ln: ln file hard_link creates a hard link, and ln -s item soft_link creates a soft link. Hard Links: A hard link is a direct reference to the same physical location of a file on the storage device. It creates an additional entry in the file system that points to the same inode (data structure representing a file) as the original file. Changes made to either the original file or the hard link are reflected in both, as they refer to the same underlying data. Hard links cannot reference directories or files on different file systems or partitions. Soft Links: A symbolic link is a special file that contains a path pointing to another file or directory. It acts as a pointer or shortcut to the target file or directory. Symbolic links are independent files and have their own inodes. Modifying the original file or symbolic link does not affect each other, as they are separate entities. Symbolic links can reference directories or files on different file systems or partitions. Soft links can be created to a non-existent filename (of course, if you use vi on this soft link file, Linux will automatically create a new file named â€œfilenameâ€). Hard links cannot be created in such cases since the file must already exist, and the inode must exist as well. Using ls -li can view the inodes of the files. drwxrwxr-x 2 â€˜s 2 is the number of hard links to a file. Besides, the usual number of inodes for a directory is 2 (include parent directory and itself .) tar: To create archive files (usually with the .tar extension) and archive files. create archive file: tar -cvf archive.tar file1 file2 directory/ -c (create archive file), -v (view details), -f (specify archive file) extract archive file: tar -xvf archive.tar -x (extract the content of archive files) compress archive file: tar -czvf archive.tar.gz directory/ -z (use gzip to compress) decompress archive file: tar -xzvf archive.tar.gz, tar -xjvf archive.tar.bz2 list the content of archive files: tar -tvf archive.tar tar -tf test.tar: view package structure tar -C dest_dir/ -x[z]vf test.tar[.gz] specified_dir_or_file...[path in -tf shows]: unzip the specified file&#x2F;directory in the package; unzip archive.zip -d dest_dir split and cat: split the tar.gz into small files, split: split -6/-b 3M -d -a 2 cud_test.tar.gz[dst_filename] cud_test.tar.gz_[out_filename] 12345cud_test.tar.gz_00cud_test.tar.gz_01cud_test.tar.gz_02cud_test.tar.gz_03cud_test.tar.gz_04 -&lt;line_N&gt; : split into a file every N lines -b &lt;bytes&gt; : split into a file every N bytes -d : specify the generated split file suffix in numeric form -a x : set the length of the sequence (suffix digits) cat cud_test.tar.gz_* &gt; cud_test.tar.gz : to concatenate split files; Before starting using commands, letâ€™s introduce wildcards that provide special characters to help you quickly specify a group of filenames. Wildcard Implication * match any sequence of characters, including zero characters. ? match any single character (excluding zero character) [character] match any single character within the specified character set [!character] match any single character without the specified character set [[:class:]] match any single character within the specified character class The following table lists the most commonly used character classes. Character Class Implication [:alnum:] match any single letter or digit [:alpha:] match any single letter [:digit:] match any single digit [:lower:] match any single lower letter [:upper:] match any single upper letter There are some examples constructed with wildcard: *, g*, b*.txt, Data???, [abc]*, BACKUP.[0-9][0-9][0-9], [[:upper:]], [![:digit:]]*, *[[:lower:]123] Service and Systemctl systemctl is a system service manager that actually combines the service and chkconfig commands together. 123456789systemctl is-enabled httpd.servicesystemctl status httpd.servicesystemctl list-unit-files --type=servicesystemctl restart httpd.servicesystemctl stop httpd.servicesystemctl reload httpd.servicesystemctl restart httpd.servicesystemctl enable httpd # bootstrapsystemctl disable httpd # not bootstrap service 12345service ssh startservice ssh stopservice ssh restartservice ssh statusservice --status-all","tags":[{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"}],"categories":[{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"}]},{"title":"Design Mode","date":"2023-07-22T12:00:53.000Z","path":"jottings/interview/memo_design_mode/","text":"ç¬”è®°å‚è€ƒä¸»è¦è‡ª https://refactoringguru.cn/design-patterns/catalog 0 UMLç±»å›¾å…³ç³» ä¾èµ–å…³ç³»ï¼šä¸€ç§ä½¿ç”¨å…³ç³»ï¼Œä¸€ä¸ªç±»çš„å®ç°éœ€è¦å¦ä¸€ä¸ªç±»çš„ååŠ© ä»£ç è¡¨ç°ï¼šå±€éƒ¨å˜é‡ã€æ–¹æ³•çš„å‚æ•°æˆ–é™æ€æ–¹æ³•çš„è°ƒç”¨ï¼› ç®­å¤´æ–¹å‘ï¼šå¸¦è™šçº¿ç®­å¤´ï¼Œç®­å¤´ä»ä½¿ç”¨ç±»æŒ‡å‘è¢«ä½¿ç”¨ç±»ï¼› 123456classDiagram Programmer ..&gt; Computer class Programmer &#123; -name: String +coding(Computer c) &#125; å…³è”å…³ç³»ï¼šä¸€ç§å¼•ç”¨å…³ç³»ï¼Œä½¿ä¸€ä¸ªç±»çŸ¥é“å¦ä¸€ä¸ªç±»çš„å±æ€§å’Œæ–¹æ³•ï¼›å¦‚è€å¸ˆä¸å­¦ç”Ÿï¼› ä»£ç è¡¨ç°ï¼šæˆå‘˜å˜é‡ï¼› ç®­å¤´æ–¹å‘ï¼šå•å‘å…³è”ï¼ˆç®­å¤´å®çº¿æŒ‡å‘è¢«æ‹¥æœ‰è€…ï¼‰ï¼ŒåŒå‘å…³è”ï¼ˆå¯åŒç®­å¤´&#x2F;ä¹Ÿå¯éƒ½æ²¡æœ‰ï¼‰ 12345678910classDiagram Teacher--Student Student--&gt;Course class Teacher &#123; -students: List&amp;ltStudent&amp;gt &#125; class Student &#123; -teacher: Teacher -courses: List&amp;ltCourse&amp;gt &#125; èšåˆå…³ç³»ï¼šå…³è”å…³ç³»çš„ä¸€ç§ï¼Œæ•´ä½“ä¸ä¸éƒ¨åˆ†çš„å…³ç³»ï¼Œä¸”éƒ¨åˆ†å¯ä»¥ç¦»å¼€æ•´ä½“è€Œå•ç‹¬å­˜åœ¨ã€‚ ä»£ç è¡¨ç°ï¼šæˆå‘˜å˜é‡ ç®­å¤´æ–¹å‘ï¼šå¸¦ç©ºå¿ƒè±å½¢çš„å®å¿ƒçº¿ï¼Œè±å½¢æŒ‡å‘æ•´ä½“ 12345classDiagram School o-- Teacher class School &#123; -teacher: List&amp;ltTeacher&amp;gt &#125; ç»„åˆå…³ç³»ï¼šè”å…³ç³»çš„ä¸€ç§ï¼Œæ•´ä½“ä¸ä¸éƒ¨åˆ†çš„å…³ç³»ï¼Œä¸”éƒ¨åˆ†ä¸å¯ä»¥ç¦»å¼€æ•´ä½“è€Œå•ç‹¬å­˜åœ¨ã€‚ ä»£ç è¡¨ç°ï¼šæˆå‘˜å˜é‡ ç®­å¤´æ–¹å‘ï¼šå¸¦å®å¿ƒè±å½¢çš„å®çº¿ï¼Œè±å½¢æŒ‡å‘æ•´ä½“ 12345classDiagram Body *-- Brain class Body &#123; -brain: Brain &#125; å®ç°å…³ç³»ï¼šæ¥å£å’Œå®ç°ç±»ï¼Œå¸¦ä¸‰è§’ç®­å¤´çš„å®çº¿æŒ‡å‘æ¥å£ï¼› æ³›åŒ–å…³ç³»ï¼šçˆ¶å­ç±»ä¹‹é—´çš„ç»§æ‰¿å…³ç³»ï¼Œå¸¦ä¸‰è§’ç®­å¤´çš„è™šçº¿æŒ‡å‘çˆ¶ç±»ï¼› 12345classDiagram University &lt;|.. Tsinghua University &lt;|.. Peking Animal&lt;|--Bird Animal&lt;|--Lion 1 å•ä¾‹æ¨¡å¼ æ ¸å¿ƒæ€æƒ³ï¼šä¿è¯ä¸€ä¸ªç±»åªæœ‰ä¸€ä¸ªå®ä¾‹ï¼Œå¹¶æä¾›ä¸€ä¸ªå…¨å±€è®¿é—®ç‚¹æ¥è®¿é—®è¿™ä¸ªå®ä¾‹ã€‚ ä¼˜ç‚¹ï¼š å…¨å±€æ§åˆ¶ï¼šå¯ä»¥ä¸¥æ ¼çš„æ§åˆ¶å®¢æˆ·æ€æ ·è®¿é—®&#x2F;ä½•æ—¶è®¿é—®ï¼Œå³å¯¹å”¯ä¸€å®ä¾‹çš„å—æ§è®¿é—®ã€‚ èŠ‚çœèµ„æºï¼šå•ä¾‹é¿å…å¤šæ¬¡åˆ›å»ºäº†ç›¸åŒçš„å¯¹è±¡ï¼ŒèŠ‚çœäº†ç³»ç»Ÿèµ„æºï¼Œä¸”å¤šä¸ªæ¨¡å—å¯ä»¥é€šè¿‡å•ä¾‹å®ä¾‹å…±äº«æ•°æ®ã€‚ æ‡’åŠ è½½ï¼šåœ¨éœ€è¦æ—¶æ‰å®ä¾‹åŒ–ï¼Œå¯ä»¥æé«˜ç¨‹åºçš„æ€§èƒ½ã€‚ åŸºæœ¬ç»„æˆï¼šç§æœ‰çš„æ„é€ å‡½æ•°ã€é™æ€å®ä¾‹å˜é‡ï¼Œå…¬æœ‰çš„é™æ€æ–¹æ³•ï¼› 123456classDiagram class Singleton&#123; -instance: Singleton - Singleton() + GetInstance() &#125; å®ç°ï¼š é¥¿æ±‰æ¨¡å¼ï¼šåœ¨ç±»åŠ è½½æ—¶å°±å·²ç»å®Œæˆäº†åˆ›å»ºï¼Œå¯èƒ½é€ æˆèµ„æºæµªè´¹ï¼Œä½†ä¸€èˆ¬ä¸å­˜åœ¨å¤šä¸ªçº¿ç¨‹åŒæ—¶å°è¯•åˆå§‹åŒ–å®ä¾‹çš„é—®é¢˜ã€‚ 123456789101112// hppclass Singleton &#123; public: static Singleton&amp; getInstance() &#123; return s_instance; &#125; Singleton(const Singleton&amp;) = delete; Singleton&amp; operator=(const Singleton&amp;) = delete; private: Singleton() = default; static Singleton s_instance;&#125;// cppSingleton Singleton::s_instance; æ‡’æ±‰æ¨¡å¼ï¼šé¦–æ¬¡è°ƒç”¨æ‰è¢«åˆ›å»ºï¼Œé¿å…èµ„æºæµªè´¹ï¼ˆå¦‚æœInstanceç±»å¾ˆå¤§ï¼‰ 12345678910111213141516171819202122// Double-Checked LockingClass Singleton &#123; public: static Singleton* getInstance() &#123; if (!p_instance) &#123; // å‡å°‘å¯¹åŒæ­¥é”çš„ç«äº‰ï¼Œæé«˜æ•ˆç‡ lock_guard&lt;mutex&gt; lck(mtx); if (!p_instance) &#123; p_instance = new Singleton(); &#125; &#125; return p_instance; &#125; Singleton(const Singleton&amp;) = delete; Singleton&amp; operator=(const Singleton&amp;) = delete; private: Singleton() = default; static Singleton* p_singleton; static mutex mtx;&#125;;// cppSingleton* Singleton::p_singleton = nullptr;mutex Singleton::mtx; C++11æ ‡å‡†è§„å®šäº†å±€éƒ¨é™æ€å˜é‡çš„åˆå§‹åŒ–å¿…é¡»æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œå› æ­¤å¯åˆ©ç”¨å±€éƒ¨é™æ€å˜é‡æ¥å®ç°å•ä¾‹ã€‚ å½“å¤šä¸ªçº¿ç¨‹åŒæ—¶åˆ°è¾¾å±€éƒ¨é™æ€å˜é‡çš„åˆå§‹åŒ–è¯­å¥æ—¶ï¼Œä¿è¯åªæœ‰ä¸€ä¸ªçº¿ç¨‹å°†æ‰§è¡Œåˆå§‹åŒ–ä»£ç ï¼Œè€Œå…¶ä»–çº¿ç¨‹å°†ç­‰å¾…è¿™ä¸ªåˆå§‹åŒ–å®Œæˆã€‚ 123456789101112// Meyer&#x27;s Singletonclass Singleton &#123; public: static Singleton&amp; getInstance() &#123; static Singleton s_instance; return s_instance; &#125; Singleton(const Singleton&amp;) = delete; Singleton&amp; operator=(const Singleton&amp;) = delete; private: Singleton() = default;&#125;; 2 å·¥å‚æ¨¡å¼2.1 ç®€å•å·¥å‚æ¨¡å¼ æ ¸å¿ƒæ€æƒ³ï¼šå°†å„ç§äº§å“å¯¹è±¡çš„åˆ›å»ºè¿‡ç¨‹å°è£…åœ¨ä¸€ä¸ªå·¥å‚ç±»ä¸­ã€‚ åŸºæœ¬ç»„æˆï¼šå·¥å‚ã€æŠ½è±¡äº§å“ï¼ˆæ¥å£ï¼‰ã€å…·ä½“äº§å“ï¼› ç¼ºç‚¹ï¼šå¯¹ä¿®æ”¹ä¸å°é—­ï¼Œæ–°å¢äº§å“éœ€è¦ä¿®æ”¹å·¥å‚ï¼Œè¿åäº†OCPåŸåˆ™ï¼› 2.2 å·¥å‚æ¨¡å¼ æ ¸å¿ƒæ€æƒ³ï¼šå¼•å…¥æŠ½è±¡å·¥å‚å’Œå…·ä½“å·¥å‚çš„æ¦‚å¿µï¼Œæ¯ä¸ªå…·ä½“å·¥å‚è´Ÿè´£åˆ›å»ºå¯¹åº”çš„å…·ä½“äº§å“ï¼Œæ–°å¢äº§å“ç§©åªéœ€æ·»åŠ æ–°çš„å·¥å‚ç±»è€Œæ— éœ€ä¿®æ”¹åŸæ¥çš„ä»£ç ï¼› åŸºæœ¬ç»„æˆï¼šæŠ½è±¡å·¥å‚ï¼ˆæ¥å£ï¼‰ã€å…·ä½“å·¥å‚ã€æŠ½è±¡äº§å“ï¼ˆæ¥å£ï¼‰ã€å…·ä½“äº§å“ï¼› ä¼˜ç‚¹ï¼šæ–°å¢äº§å“æ›´çµæ´»ã€æ”¯æŒæ‰©å±•ï¼Œç¬¦åˆå¼€é—­åŸåˆ™ï¼› åº”ç”¨åœºæ™¯ï¼š Spring æ¡†æ¶ä¸­çš„ Bean å·¥å‚ï¼šé€šè¿‡é…ç½®æ–‡ä»¶æˆ–æ³¨è§£ï¼ŒSpring å¯ä»¥æ ¹æ®é…ç½®ä¿¡æ¯åŠ¨æ€åœ°åˆ›å»ºå’Œç®¡ç†å¯¹è±¡ã€‚ JDBC ä¸­çš„ Connection å·¥å‚ï¼šåœ¨ Java æ•°æ®åº“è¿æ¥ä¸­ï¼Œ DriverManager ä½¿ç”¨å·¥å‚æ–¹æ³•æ¨¡å¼æ¥åˆ›å»ºæ•°æ®åº“è¿æ¥ã€‚ä¸åŒçš„æ•°æ®åº“é©±åŠ¨ï¼ˆå¦‚ MySQLã€PostgreSQL ç­‰ï¼‰éƒ½æœ‰å¯¹åº”çš„å·¥å‚æ¥åˆ›å»ºè¿æ¥ã€‚ 2.3 æŠ½è±¡å·¥å‚æ¨¡å¼ æ ¸å¿ƒæ€æƒ³ï¼š ç®€å•å·¥å‚ï¼Œä¸€ä¸ªå·¥å‚åˆ›å»ºæ‰€æœ‰å…·ä½“äº§å“ï¼› å·¥å‚æ–¹æ³•ï¼Œä¸€ä¸ªå·¥å‚åˆ›å»ºä¸€ä¸ªå…·ä½“äº§å“ï¼› æŠ½è±¡å·¥å‚ï¼Œä¸€ä¸ªå·¥å‚åˆ›å»ºä¸€ç±»å…·ä½“äº§å“ï¼› åŸºæœ¬ç»„æˆï¼š 123456789101112131415161718// Simple Factoryfactory.create(&#x27;A&#x27;); // product Afactory.create(&#x27;B&#x27;); // product B// Factory Method// factory_ab &lt;|-- factory_a// factory_ab &lt;|-- factory_bfactory_a.create(); // product Afactory_b.create(); // product B// Abstract Factory// factory &lt;|-- factory_1/2// product_a &lt;|-- product_a_1/2// product_b &lt;|-- product_b_1/2factory_1.create_a(); // product A1factory_1.create_b(); // product B1factory_2.create_a(); // product A2factory_2.create_b(); // product B2 3 å»ºé€ è€…æ¨¡å¼ æ ¸å¿ƒæ€æƒ³ï¼šå°†å¯¹è±¡çš„æ„å»ºè¿‡ç¨‹åˆ†ä¸ºå¤šä¸ªæ­¥éª¤ï¼Œå¹¶ä¸ºæ¯ä¸ªæ­¥éª¤å®šä¹‰ä¸€ä¸ªæŠ½è±¡çš„æ¥å£ã€‚å…·ä½“çš„æ„å»ºè¿‡ç¨‹ç”±å®ç°äº†è¿™äº›æ¥å£çš„å…·ä½“å»ºé€ è€…ç±»æ¥å®Œæˆã€‚ è€ŒæŒ‡å¯¼è€…ç±»è´Ÿè´£æŒ‰ç…§ä¸€å®šçš„é¡ºåºæ¥æ‰§è¡Œæ„å»ºæ­¥éª¤ï¼Œæœ€ç»ˆç”Ÿæˆäº§å“ã€‚ åŸºæœ¬ç»„æˆï¼š 1234567891011121314151617181920212223classDiagram AbstractBuilder&lt;|--Builder1 AbstractBuilder&lt;|--Builder2 AbstractProduct&lt;|--Product1 AbstractProduct&lt;|--Product2 Director o--AbstractBuilder Builder1 ..&gt; Product1 Builder2 ..&gt; Product2 class AbstractBuilder&#123; - product: AbstractProduct +BuildPartA() +BuildPartB() +GetProuct() &#125; class Director&#123; -builder: AbstractBuilder +construct() &#125; class AbstractProduct &#123; -partA -partB &#125; 12345678910111213141516// Directorclass Director &#123; public: explicit Director(Builder* builder): builder_(builder) &#123;&#125; void construct() &#123; builder_-&gt;BuildPartA(); builder_-&gt;BuildPartB(); &#125; private: Builder* builder_;&#125;// ClientBuilder* builder = new ConcreteBuilder();Director* director = new Director(builder);director-&gt;construct();Product product = builder-&gt;GetProduct(); ä¼˜ç‚¹ï¼š å°è£…æ€§å¥½ï¼Œæ„å»ºå’Œè¡¨ç¤ºåˆ†ç¦»ï¼› æ‰©å±•æ€§å¥½ï¼Œå„ä¸ªå…·ä½“çš„å»ºé€ è€…ç›¸äº’ç‹¬ç«‹ï¼Œåˆ©äºç³»ç»Ÿè§£è€¦ï¼› æ§åˆ¶é£é™©ç»†èŠ‚ï¼Œå®¢æˆ·ç«¯æ— éœ€çŸ¥é“ç»†èŠ‚ï¼Œå»ºé€ è€…ç»†åŒ–åˆ›å»ºè¿‡ç¨‹ï¼› ç¼ºç‚¹ï¼š äº§å“çš„ç»„æˆéƒ¨åˆ†å¿…é¡»ç›¸åŒï¼Œé™åˆ¶äº†å…¶ä½¿ç”¨èŒƒå›´ï¼› äº§å“å†…éƒ¨å‘ç”Ÿå˜åŒ–ï¼Œå»ºé€ è€…éœ€åŒæ­¥ä¿®æ”¹ï¼ŒåæœŸç»´æŠ¤æˆæœ¬è¾ƒå¤§ï¼› 4 åŸå‹æ¨¡å¼ğŸ’¬ 4.1 æ„å›¾åŸºäºç°æœ‰çš„å¯¹è±¡åˆ›å»ºæ–°çš„å¯¹è±¡ï¼Œå°†åŸå‹å¯¹è±¡çš„æˆå‘˜å˜é‡å¤åˆ¶åˆ°æ–°ç”Ÿæˆçš„å¯¹è±¡ä¸­ï¼Œè€Œä¸éœ€ä½¿ä»£ç ä¾èµ–å®ƒä»¬æ‰€å±çš„ç±»ã€‚ ğŸ™ 4.2 é—®é¢˜ ç›´æ¥å¤åˆ¶å¯¹è±¡ï¼ˆâ€œä»å¤–éƒ¨â€ å¤åˆ¶å¯¹è±¡å¹¶éæ€»æ˜¯å¯è¡Œï¼‰ï¼Œå¿…é¡»çŸ¥é“å¯¹è±¡æ‰€å±çš„ç±»æ‰èƒ½åˆ›å»ºå¤åˆ¶å“ï¼Œ æ‰€ä»¥ä»£ç å¿…é¡»ä¾èµ–è¯¥ç±»ï¼› æ­¤å¤–ï¼Œæœ‰æ—¶åªçŸ¥é“å¯¹è±¡æ‰€å®ç°çš„æ¥å£ï¼Œ è€Œä¸çŸ¥é“å…¶æ‰€å±çš„å…·ä½“ç±»ï¼Œæ¯”å¦‚å‘æ–¹æ³•çš„æŸä¸ªå‚æ•°ä¼ å…¥å®ç°äº†æŸä¸ªæ¥å£çš„ä»»ä½•å¯¹è±¡ï¼› ğŸ˜Š 4.3 è§£å†³æ–¹æ¡ˆåŸå‹æ¨¡å¼å°†å…‹éš†è¿‡ç¨‹å§”æ´¾ç»™è¢«å…‹éš†çš„å®é™…å¯¹è±¡ã€‚ æ¨¡å¼ä¸ºæ‰€æœ‰æ”¯æŒå…‹éš†çš„å¯¹è±¡å£°æ˜äº†ä¸€ä¸ªé€šç”¨æ¥å£ï¼Œ è¯¥æ¥å£è®©ä½ èƒ½å¤Ÿå…‹éš†å¯¹è±¡ï¼Œ åŒæ—¶åˆæ— éœ€å°†ä»£ç å’Œå¯¹è±¡æ‰€å±ç±»è€¦åˆã€‚ æ‰€æœ‰çš„ç±»å¯¹ cloneæ–¹æ³•çš„å®ç°éƒ½éå¸¸ç›¸ä¼¼ã€‚ è¯¥æ–¹æ³•ä¼šåˆ›å»ºä¸€ä¸ªå½“å‰ç±»çš„å¯¹è±¡ï¼Œ ç„¶åå°†åŸå§‹å¯¹è±¡æ‰€æœ‰çš„æˆå‘˜å˜é‡å€¼å¤åˆ¶åˆ°æ–°å»ºçš„ç±»ä¸­ã€‚ æ”¯æŒå…‹éš†çš„å¯¹è±¡å³ä¸ºåŸå‹ã€‚ å½“ä½ çš„å¯¹è±¡æœ‰å‡ åä¸ªæˆå‘˜å˜é‡å’Œå‡ ç™¾ç§ç±»å‹æ—¶ï¼Œ å¯¹å…¶é¢„ç”ŸæˆåŸå‹å¯ä»¥ä»£æ›¿å­ç±»çš„æ„é€ ï¼ˆé¿å…å­ç±»å®ä¾‹åŒ–çš„å¤æ‚ï¼Œæ— éœ€å…³å¿ƒè¯¥å®ä¾‹æ˜¯å¦‚ä½•é€šè¿‡å­ç±»åŒ–æ„é€ å‡ºæ¥çš„ï¼‰ã€‚ å…¶è¿ä½œæ–¹å¼å¦‚ä¸‹ï¼š åˆ›å»ºä¸€ç³»åˆ—ä¸åŒç±»å‹çš„å¯¹è±¡å¹¶ä¸åŒçš„æ–¹å¼å¯¹å…¶è¿›è¡Œé…ç½®ã€‚ å¦‚æœæ‰€éœ€å¯¹è±¡ä¸é¢„å…ˆé…ç½®çš„å¯¹è±¡ç›¸åŒï¼Œ é‚£ä¹ˆä½ åªéœ€å…‹éš†åŸå‹å³å¯ï¼Œ æ— éœ€æ–°å»ºä¸€ä¸ªå¯¹è±¡ã€‚ ğŸš€ 4.4 åŸå‹æ¨¡å¼ç»“æ„åŸºæœ¬å®ç° åŸå‹ ï¼ˆPrototypeï¼‰ æ¥å£å°†å¯¹å…‹éš†æ–¹æ³•è¿›è¡Œå£°æ˜ã€‚ åœ¨ç»å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œ å…¶ä¸­åªä¼šæœ‰ä¸€ä¸ªåä¸º cloneå…‹éš†çš„æ–¹æ³•ã€‚ å…·ä½“åŸå‹ ï¼ˆConcrete Prototypeï¼‰ ç±»å°†å®ç°å…‹éš†æ–¹æ³•ã€‚ é™¤äº†å°†åŸå§‹å¯¹è±¡çš„æ•°æ®å¤åˆ¶åˆ°å…‹éš†ä½“ä¸­ä¹‹å¤–ï¼Œ è¯¥æ–¹æ³•æœ‰æ—¶è¿˜éœ€å¤„ç†å…‹éš†è¿‡ç¨‹ä¸­çš„æç«¯æƒ…å†µï¼Œ ä¾‹å¦‚å…‹éš†å…³è”å¯¹è±¡å’Œæ¢³ç†é€’å½’ä¾èµ–ç­‰ç­‰ã€‚ å…‹éš†æ–¹æ³•é€šå¸¸åªæœ‰ä¸€è¡Œä»£ç ï¼š ä½¿ç”¨ newè¿ç®—ç¬¦è°ƒç”¨åŸå‹ç‰ˆæœ¬çš„æ„é€ å‡½æ•°ã€‚ å®¢æˆ·ç«¯ ï¼ˆClientï¼‰ å¯ä»¥å¤åˆ¶å®ç°äº†åŸå‹æ¥å£çš„ä»»ä½•å¯¹è±¡ã€‚ åŸå‹æ³¨å†Œè¡¨å®ç° åŸå‹æ³¨å†Œè¡¨ ï¼ˆPrototype Registryï¼‰ æä¾›äº†ä¸€ç§è®¿é—®å¸¸ç”¨åŸå‹çš„ç®€å•æ–¹æ³•ï¼Œ å…¶ä¸­å­˜å‚¨äº†ä¸€ç³»åˆ—å¯ä¾›éšæ—¶å¤åˆ¶çš„é¢„ç”Ÿæˆå¯¹è±¡ã€‚ ğŸ’¡ 4.5 é€‚ç”¨åœºæ™¯ å¦‚æœä½ éœ€è¦å¤åˆ¶ä¸€äº›å¯¹è±¡ï¼Œ åŒæ—¶åˆå¸Œæœ›ä»£ç ç‹¬ç«‹äºè¿™äº›å¯¹è±¡æ‰€å±çš„å…·ä½“ç±»ï¼› åŠ¨æ€ç”Ÿæˆå¯¹è±¡ï¼šåŸå‹æ¨¡å¼å…è®¸åœ¨è¿è¡Œæ—¶åŠ¨æ€ç”Ÿæˆå¯¹è±¡çš„å‰¯æœ¬ã€‚ ä¾‹å¦‚ï¼Œåœ¨æŸäº›éœ€è¦æ ¹æ®å¤–éƒ¨è¾“å…¥æˆ–è€…é…ç½®æ–‡ä»¶æ¥åˆ›å»ºå¯¹è±¡çš„åº”ç”¨ä¸­ï¼Œä½¿ç”¨é¢„ç”ŸæˆåŸå‹å¯ä»¥ç®€åŒ–å¯¹è±¡çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œå› ä¸ºä½ å¯ä»¥åœ¨è¿è¡Œæ—¶é€‰æ‹©åˆé€‚çš„åŸå‹è¿›è¡Œå¤åˆ¶ï¼Œè€Œä¸æ˜¯é ç¡¬ç¼–ç çš„æ–¹å¼æ¥å†³å®šä½¿ç”¨å“ªä¸ªå­ç±»ã€‚ å¯¹è±¡çŠ¶æ€çš„å¤ç”¨ï¼šå¯¹äºä¸€äº›åˆå§‹åŒ–èµ„æºæ¶ˆè€—è¾ƒå¤§çš„å¯¹è±¡ï¼Œå¦‚é‚£äº›éœ€è¦ä»æ•°æ®åº“åŠ è½½æ•°æ®çš„å¯¹è±¡ï¼Œæ–°åˆ›å»ºçš„å¯¹è±¡å¯ä»¥è‡ªåŠ¨ç»§æ‰¿å…¶åŸå‹å¯¹è±¡çš„çŠ¶æ€ï¼› ğŸ² 4.6 ä¼˜ç¼ºç‚¹âœ” å¯ä»¥å…‹éš†å¯¹è±¡ï¼Œæ— éœ€ä¸å®ƒä»¬æ‰€å±çš„ç±»ç›¸è€¦åˆï¼›åŠ¨æ€ç”Ÿæˆå¯¹è±¡å‰¯æœ¬ï¼› âœ” å¯ä»¥å…‹éš†é¢„ç”ŸæˆåŸå‹ï¼Œé¿å…åå¤è¿è¡Œåˆå§‹åŒ–ä»£ç ï¼›å¯¹è±¡çŠ¶æ€çš„å¤ç”¨ï¼› âŒ å…‹éš†åŒ…å«å¾ªç¯å¼•ç”¨çš„å¤æ‚å¯¹è±¡å¯èƒ½ä¼šéå¸¸éº»çƒ¦ã€‚ ğŸ“œ 4.7 ç¤ºä¾‹ä»£ç 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697using std::string;enum Type &#123; PROTOTYPE_1 = 0, PROTOTYPE_2&#125;;class Prototype &#123; protected: string prototype_name_; float prototype_field_; public: Prototype() &#123;&#125; Prototype(string prototype_name) : prototype_name_(prototype_name) &#123; &#125; virtual ~Prototype() &#123;&#125; virtual Prototype *Clone() const = 0; virtual void Method(float prototype_field) &#123; this-&gt;prototype_field_ = prototype_field; std::cout &lt;&lt; &quot;Call Method from &quot; &lt;&lt; prototype_name_ &lt;&lt; &quot; with field : &quot; &lt;&lt; prototype_field &lt;&lt; std::endl; &#125;&#125;;class ConcretePrototype1 : public Prototype &#123; private: float concrete_prototype_field1_; public: ConcretePrototype1(string prototype_name, float concrete_prototype_field) : Prototype(prototype_name), concrete_prototype_field1_(concrete_prototype_field) &#123; &#125; Prototype *Clone() const override &#123; return new ConcretePrototype1(*this); &#125;&#125;;class ConcretePrototype2 : public Prototype &#123; private: float concrete_prototype_field2_; public: ConcretePrototype2(string prototype_name, float concrete_prototype_field) : Prototype(prototype_name), concrete_prototype_field2_(concrete_prototype_field) &#123; &#125; Prototype *Clone() const override &#123; return new ConcretePrototype2(*this); &#125;&#125;;class PrototypeFactory &#123; private: std::unordered_map&lt;Type, Prototype *, std::hash&lt;int&gt;&gt; prototypes_; public: PrototypeFactory() &#123; prototypes_[Type::PROTOTYPE_1] = new ConcretePrototype1(&quot;PROTOTYPE_1 &quot;, 50.f); prototypes_[Type::PROTOTYPE_2] = new ConcretePrototype2(&quot;PROTOTYPE_2 &quot;, 60.f); &#125; ~PrototypeFactory() &#123; delete prototypes_[Type::PROTOTYPE_1]; delete prototypes_[Type::PROTOTYPE_2]; &#125; Prototype *CreatePrototype(Type type) &#123; return prototypes_[type]-&gt;Clone(); &#125;&#125;;void Client(PrototypeFactory &amp;prototype_factory) &#123; std::cout &lt;&lt; &quot;Let&#x27;s create a Prototype 1\\n&quot;; Prototype *prototype = prototype_factory.CreatePrototype(Type::PROTOTYPE_1); prototype-&gt;Method(90); delete prototype; std::cout &lt;&lt; &quot;\\n&quot;; std::cout &lt;&lt; &quot;Let&#x27;s create a Prototype 2 \\n&quot;; prototype = prototype_factory.CreatePrototype(Type::PROTOTYPE_2); prototype-&gt;Method(10); delete prototype;&#125;int main() &#123; PrototypeFactory *prototype_factory = new PrototypeFactory(); Client(*prototype_factory); delete prototype_factory; return 0;&#125; è®¾è®¡åŸåˆ™ OCP (Open&#x2F;Closed Principle): è½¯ä»¶å®ä½“ï¼ˆç±»&#x2F;æ¨¡å—&#x2F;å‡½æ•°ç­‰ï¼‰åº”è¯¥æ˜¯å¯æ‰©å±•çš„ï¼Œä½†æ˜¯ä¸å¯ä¿®æ”¹çš„ã€‚ RAII (Resource Acquisition Is Initialization): ç¡®ä¿æ‰€æœ‰èµ„æºï¼ˆå¦‚æŒ‡é’ˆã€æ–‡ä»¶å¥æŸ„ã€ç½‘ç»œè¿æ¥ç­‰ï¼‰éƒ½å°è£…åœ¨ç±»å¯¹è±¡é‡Œï¼Œè®©å¯¹è±¡çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†èµ„æºã€‚ èµ„æºçš„è·å–ï¼ˆAllocationï¼‰åº”åœ¨å¯¹è±¡æ„é€ æ—¶å®Œæˆ èµ„æºçš„é‡Šæ”¾ï¼ˆDeallocationï¼‰è‡ªåŠ¨åœ¨å¯¹è±¡çš„ææ„æ—¶æ‰§è¡Œ å¼‚å¸¸å®‰å…¨ï¼šRAIIä¿è¯æ— è®ºå¯¹è±¡æ˜¯å› ä¸ºä½œç”¨åŸŸç»“æŸè¿˜æ˜¯å› ä¸ºå¼‚å¸¸è€Œç¦»å¼€ä½œç”¨åŸŸï¼Œèµ„æºçš„é‡Šæ”¾å°†æ€»æ˜¯è‡ªåŠ¨å‘ç”Ÿã€‚ å½“C++ç¨‹åºä¸­æŠ›å‡ºä¸€ä¸ªå¼‚å¸¸æ—¶ï¼Œç¨‹åºæ§åˆ¶æµä¼šä»æŠ›å‡ºå¼‚å¸¸çš„ç‚¹è·³è½¬åˆ°èƒ½å¤Ÿå¤„ç†è¯¥å¼‚å¸¸çš„æ•æ‰ç‚¹ï¼ˆcatch blockï¼‰ã€‚åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­ï¼Œç¨‹åºä¼šå±•å¼€å †æ ˆï¼Œé€€å‡ºå½“å‰ä½œç”¨åŸŸåŠå…¶çˆ¶ä½œç”¨åŸŸï¼Œç›´åˆ°æ‰¾åˆ°åˆé€‚çš„å¼‚å¸¸å¤„ç†ä»£ç ã€‚åœ¨å±•å¼€å †æ ˆçš„è¿‡ç¨‹ä¸­ï¼Œå±€éƒ¨å¯¹è±¡ä¼šè¢«é”€æ¯ï¼Œå…¶ææ„å‡½æ•°æŒ‰ç…§åˆ›å»ºçš„é€†åºè¢«è°ƒç”¨ã€‚å› æ­¤ï¼ŒRAIIç±»çš„ææ„å‡½æ•°å°†è´Ÿè´£é‡Šæ”¾å…¶ç®¡ç†çš„èµ„æºï¼Œå³ä½¿æ˜¯åœ¨å¼‚å¸¸å‘ç”Ÿæ—¶ã€‚ ä¼˜ç‚¹ï¼š ä»£ç æ›´åŠ ç®€æ´æ˜äº†ã€æ˜“äºç»´æŠ¤ï¼› è‡ªåŠ¨èµ„æºç®¡ç†ã€å‡å°‘äº†èµ„æºæ³„éœ²çš„é£é™©ï¼› æé«˜äº†ä»£ç çš„å¼‚å¸¸å®‰å…¨æ€§ï¼›","tags":[{"name":"interview","slug":"interview","permalink":"https://stu-yue.github.io/tags/interview/"}],"categories":[{"name":"interview","slug":"interview","permalink":"https://stu-yue.github.io/categories/interview/"}]},{"title":"Hot Points","date":"2023-07-22T12:00:53.000Z","path":"jottings/tidbits/hot_points/","text":"Generate random numbers by reading thermal noise on CPU pins. Hot Plug, refers to the operation of inserting&#x2F;removing a device while it is running. In contrast, Cold Plug means do above operation while the device is powered off. Software versionâ€™s explanation: Version Description Snapshot Development version Alpha Internal beta Beta Public beta Pre (M) Similar to Alpha, sometimes subdivided into M_(Milestone) version RC(Release Candidate) During Beta stage, new features will continue to be added, but once the RC version is reached, there will mainly be on debugging and issue resolution. GA(General Availability) Some software may be labeled as â€œstableâ€ or â€œproductionâ€. Release&#x2F;Stable Current The latest version, but no necessarily a stable one. Eval There may be a monthly or fixed time limit for usage. Declarative Programming expresses the logic of a computation without describing its control flow. Many languages that apply this style attempt to minimize or eliminate side effects by describing what the program must accomplish in terms of the problem domain (what to do), rather than specifying all the details of how the program should achieve the result (how to do). Imperative Programming uses statements that change a programâ€™s state. Imperative Programming focuses on describing how a program operates step by step, rather than on high-level descriptions of its expected results. KVM: Kernel-based Virtual Machine, is a virtualization infrastructure used in the Linux kernel to turn the Linux kernel into a hypervisor; Hypervisor: creates and runs virtual machines, sometimes called a virtual machine monitor (VMM), like a meta-OS; IT resource pooled, OS and hardware decoupled, allocated according to needs; A computer on which a hypervisor runs one or more virtual machines is called a host machine, and each virtual machine is called a guest machine; (Type 1) Native or bare mental hypervisor: runs directly on the hostâ€™s hardware to manage guest operating systems. It takes the place of a host operating system and VM resources are scheduled directly to the hardware by the hypervisor. This type of hypervisor is most common in an enterprise data center or other server-based environments. KVM, Microsoft Hyper-V, and VMware vSphere are examples of a type 1 hypervisor. KVM was merged into the Linux kernel in 2007, so if youâ€™re using a modern version of Linux, you already have access to KVM. (Type 2) Hosted hypervisor: run on a conventional operating system as a software layer or application. It works by abstracting guest operating systems from the host operating system. VM resources are scheduled against a host operating system, which is then executed against the hardware. A type 2 hypervisor is better for individual users who want to run multiple operating systems on a personal computer. VMware Workstation and Oracle VirtualBox are examples of a type 2 hypervisor. (Emulator) The difference with the Hypervisor is that the Hypervisor runs the same VM and host CPU architecture, while the Emulator can be used to run systems or programs on other hardware platforms (arm, mips, x86). When used as a machine emulator, QEMU can run OSes and programs made for one machine (e.g. an ARM board) on a different machine (e.g. your x86 PC). By using dynamic translation, it achieves very good performance; QEMU can use other hypervisors like Xen or KVM to use CPU extensions (HVM) for virtualization. When used as a virtualizer, QEMU achieves near native performances by executing the guest code directly on the host CPU. When QEMU is used in conjunction with KVM, KVM provides hardware virtualization support, while QEMU is responsible for virtual machine simulation and management. In this configuration, KVM functions as a Hypervisor to directly interact with hardware and provide high-performance virtualization support, while QEMU runs on the upper layer of KVM and is responsible for VM simulation and management, including device simulation, VM creation, start, and stop. So while QEMU is not a traditional Hypervisor on its own, when used in conjunction with KVM, QEMU can work with KVM to provide a complete virtualization solution and act as part of a Hypervisor","tags":[{"name":"points","slug":"points","permalink":"https://stu-yue.github.io/tags/points/"}],"categories":[{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"}]},{"title":"TBR_compiler","date":"2023-07-22T12:00:53.000Z","path":"jottings/tidbits/tbr_compiler/","text":"ã€Šç¼–è¯‘åŸç†ã€‹è¯¾ä»¶æ¬è¿ â€”â€”&gt; æºåœ°å€ 1.1 ç¼–è¯‘å™¨ä½œç”¨ ç¼–è¯‘å™¨ï¼ˆCompilerï¼‰ è¯»å…¥ä»¥æŸç§è¯­è¨€ï¼ˆæºè¯­è¨€ï¼‰ç¼–å†™çš„ç¨‹åºï¼› è¾“å‡ºç­‰ä»·çš„ç”¨å¦ä¸€ç§è¯­è¨€ï¼ˆç›®æ ‡è¯­è¨€ï¼‰ç¼–å†™çš„ç¨‹åºï¼› é€šå¸¸ç›®æ ‡ç¨‹åºæ˜¯å¯æ‰§è¡Œçš„ï¼› è§£é‡Šå™¨ï¼ˆInterpreterï¼‰ ä¸ç”Ÿæˆç›®æ ‡ç¨‹åºï¼Œç›´æ¥æ ¹æ®æºç¨‹åºçš„è¯­ä¹‰æ‰§è¡Œæºç¨‹åºä¸­æŒ‡å®šçš„æ“ä½œï¼› Javaè¯­è¨€çš„å¤„ç†ç»“åˆäº†ç¼–è¯‘(.classå­—èŠ‚ç )å’Œè§£é‡Šï¼ŒPythonä¼šå°†ç¼–è¯‘çš„å­—èŠ‚ç (pyc)å­˜æ”¾äº_pycache_(å¯è·¨å¹³å°éƒ¨ç½²ï¼Œä¸€å®šç¨‹åº¦é˜²æºç æ³„éœ²ï¼Œimportçš„pyä¸å˜pycå°±ä¸å˜[æ£€æŸ¥pyå’Œpycçš„ä¿®æ”¹æ—¶é—´æ˜¯å¦ä¸€è‡´]) 1.2 ç¼–è¯‘å™¨çš„ç»“æ„ ç¼–è¯‘å™¨å¯ä»¥åˆ†ä¸ºåˆ†æéƒ¨åˆ†å’Œç»¼åˆéƒ¨åˆ† åˆ†æï¼ˆanalysisï¼‰éƒ¨åˆ† &#x2F; å‰ç«¯ï¼ˆfront endï¼‰ æŠŠæºç¨‹åºåˆ†è§£æˆç»„æˆè¦ç´ ï¼Œä»¥åŠç›¸åº”çš„è¯­æ³•ç»“æ„ï¼› ä½¿ç”¨è¿™ä¸ªç»“æ„åˆ›å»ºæºç¨‹åºçš„ä¸­é—´è¡¨ç¤ºï¼› åŒæ—¶æ”¶é›†å’Œæºç¨‹åºç›¸å…³çš„ä¿¡æ¯ï¼Œå­˜æ”¾åˆ°ç¬¦å·è¡¨ï¼› ç»¼åˆï¼ˆsynthesisï¼‰éƒ¨åˆ† &#x2F; åç«¯ï¼ˆback endï¼‰ æ ¹æ®ä¸­é—´è¡¨ç¤ºå’Œç¬¦å·è¡¨ä¿¡æ¯æ„é€ ç›®æ ‡ç¨‹åºï¼› å‰ç«¯éƒ¨åˆ†æ˜¯æœºå™¨æ— å…³çš„ï¼Œåç«¯éƒ¨åˆ†æ˜¯æœºå™¨ç›¸å…³çš„ï¼› ç¼–è¯‘å™¨åˆ†æˆæ‰§è¡Œé¡ºåºçš„ä¸€ç»„æ­¥éª¤ï¼š 1.3 è¯æ³•åˆ†æ è¯æ³•åˆ†æ&#x2F;æ‰«æï¼ˆlexical analysis&#x2F;scanningï¼‰ è¯»å…¥æºç¨‹åºçš„å­—ç¬¦æµï¼Œè¾“å‡ºä¸ºæœ‰æ„ä¹‰çš„è¯ç´ ï¼ˆlexemeï¼‰ &lt;token-name, attribute-value&gt; token-nameï¼šç”±è¯­æ³•åˆ†ææ­¥éª¤ä½¿ç”¨ï¼› attribute-valueï¼šæŒ‡å‘ç›¸åº”çš„ç¬¦å·è¡¨æ¡ç›®ï¼Œç”±è¯­ä¹‰åˆ†æ&#x2F;ä»£ç ç”Ÿæˆæ­¥éª¤ä½¿ç”¨ï¼› ä¾‹å­ position &#x3D; initial + rate * 60 &lt;id, 1&gt; &lt;&#x3D;, &gt; &lt;id, 2&gt;, &lt;+, &gt; &lt;id, 3&gt; &lt;*, &gt; &lt;number, 4&gt; 1.4 è¯­æ³•åˆ†æ è¯­æ³•åˆ†æ&#x2F;è§£æï¼ˆsyntax analysis&#x2F;parsingï¼‰ æ ¹æ®å„ä¸ªè¯æ³•å•å…ƒçš„ç¬¬ä¸€ä¸ªåˆ†é‡æ¥åˆ›å»ºæ ‘å‹çš„ä¸­é—´è¡¨ç¤ºå½¢å¼ï¼Œé€šå¸¸æ˜¯è¯­æ³•æ ‘ï¼ˆsyntax treeï¼‰ ä¸­é—´è¡¨ç¤ºå½¢å¼æŒ‡å‡ºäº†è¯æ³•å•å…ƒæµçš„è¯­æ³•ç»“æ„ï¼› 1.5 è¯­ä¹‰åˆ†æ è¯­ä¹‰åˆ†æï¼ˆsemantic analysisï¼‰ ä½¿ç”¨è¯­æ³•æ ‘å’Œç¬¦å·è¡¨ä¸­çš„ä¿¡æ¯ï¼Œæ£€æŸ¥æºç¨‹åºæ˜¯å¦æ»¡è¶³è¯­è¨€å®šä¹‰çš„è¯­ä¹‰çº¦æŸï¼› åŒæ—¶æ”¶é›†ç±»å‹ä¿¡æ¯ï¼Œç”¨äºä»£ç ç”Ÿæˆã€ç±»å‹æ£€æŸ¥ã€ç±»å‹è½¬æ¢ï¼› 1.6 ä¸­é—´ä»£ç ç”Ÿæˆ æ ¹æ®è¯­ä¹‰åˆ†æè¾“å‡ºï¼Œç”Ÿæˆç±»æœºå™¨è¯­è¨€çš„ä¸­é—´è¡¨ç¤ºï¼› ä¸‰åœ°å€ä»£ç ï¼ˆthree-address codeï¼‰ æ¯ä¸ªæŒ‡ä»¤æœ€å¤šåŒ…å«ä¸‰ä¸ªè¿ç®—åˆ†é‡ï¼›å¾ˆå®¹æ˜“ç”Ÿæˆæœºå™¨è¯­è¨€æŒ‡ä»¤ï¼› 1.7 ä¸­é—´ä»£ç ä¼˜åŒ– é€šè¿‡å¯¹ä¸­é—´ä»£ç åˆ†æï¼Œæ”¹è¿›ä¸­é—´ä»£ç çš„è´¨é‡ï¼›ï¼ˆæ›´å¿«ã€æ›´çŸ­ã€èƒ½è€—æ›´ä½ï¼‰ 1.8 ä»£ç ç”Ÿæˆ æŠŠä¸­é—´è¡¨ç¤ºå½¢å¼æ˜ å°„æˆç›®æ ‡è¯­è¨€ï¼›ï¼ˆå¯„å­˜å™¨åˆ†é…ã€æŒ‡ä»¤é€‰æ‹©ï¼‰ 1.9 å…¶ä»– ç¬¦å·è¡¨ç®¡ç†ï¼šè®°å½•æºç¨‹åºä¸­ä½¿ç”¨çš„å˜é‡çš„åå­—ï¼Œæ”¶é›†å„ç§å±æ€§ï¼› ç¼–è¯‘å™¨æ„é€ å·¥å…·ï¼šæ‰«æå™¨ï¼ˆLexï¼‰ã€è¯­æ³•åˆ†æå™¨ï¼ˆYaccï¼‰ã€è¯­æ³•åˆ¶å¯¼çš„ç¿»è¯‘å¼•æ“ï¼› ç¨‹åºè®¾è®¡è¯­è¨€çš„æ–°å‘å±•å‘ç¼–è¯‘å™¨è®¾è®¡è€…æå‡ºæ–°çš„è¦æ±‚ è®¾è®¡ç›¸åº”çš„ç®—æ³•å’Œè¡¨ç¤ºæ–¹æ³•æ¥ç¿»è¯‘å’Œæ”¯æŒæ–°çš„è¯­è¨€ç‰¹å¾ï¼Œå¦‚å¤šæ€ã€åŠ¨æ€ç»‘å®šã€ç±»ã€ç±»å± (æ¨¡æ¿) ã€â€¦ ç¼–è¯‘å™¨è®¾è®¡è€…è¿˜éœ€è¦æ›´å¥½åœ°åˆ©ç”¨æ–°ç¡¬ä»¶çš„èƒ½åŠ› RISCæŠ€æœ¯ã€å¤šæ ¸æŠ€æœ¯ã€å¤§è§„æ¨¡å¹¶è¡ŒæŠ€æœ¯ 1.10 ç¨‹åºè®¾è®¡è¯­è¨€çš„åŸºç¡€æ¦‚å¿µ é™æ€&#x2F;åŠ¨æ€ï¼š é™æ€ï¼šæ”¯æŒç¼–è¯‘å™¨é™æ€å†³å®šæŸä¸ªé—®é¢˜ï¼› åŠ¨æ€ï¼šåªå…è®¸åœ¨ç¨‹åºè¿è¡Œæ—¶åˆ»ä½œå‡ºå†³å®šï¼› ä½œç”¨åŸŸï¼š xçš„ä½œç”¨åŸŸæŒ‡ç¨‹åºæ–‡æœ¬çš„ä¸€ä¸ªåŒºåŸŸï¼Œå…¶ä¸­å¯¹xçš„ä½¿ç”¨éƒ½æŒ‡å‘è¿™ä¸ªå£°æ˜ï¼› é™æ€ä½œç”¨åŸŸï¼ˆstatic scopeï¼‰: é€šè¿‡é™æ€é˜…è¯»ç¨‹åºå¯å†³å®šï¼› åŠ¨æ€ä½œç”¨åŸŸï¼ˆdynamic scopeï¼‰: è¿è¡Œæ—¶ç¡®å®šxçš„æŒ‡å‘ï¼› ç¯å¢ƒä¸çŠ¶æ€ï¼š ç¯å¢ƒï¼ˆenvironmentï¼‰: æ˜¯ä»åå­—åˆ°å­˜å‚¨ä½ç½®çš„æ˜ å°„ï¼› çŠ¶æ€ï¼ˆstateï¼‰: ä»å­˜å‚¨ä½ç½®åˆ°å®ƒä»¬å€¼çš„æ˜ å°„ï¼›","tags":[{"name":"points","slug":"points","permalink":"https://stu-yue.github.io/tags/points/"}],"categories":[{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"}]},{"title":"TBR_Net_Info","date":"2023-07-22T12:00:53.000Z","path":"jottings/tidbits/tbr_net_info/","text":"1 IPTV å’Œ OTTIPTVï¼ˆInternet Protocol Televisionï¼‰æ˜¯ä¸€ç§é€šè¿‡Internet Protocolï¼ˆIPï¼‰åœ¨ä¸“ç”¨ç½‘ç»œä¸Šä¼ è¾“è§†é¢‘å’ŒéŸ³é¢‘å†…å®¹çš„æŠ€æœ¯ã€‚å®ƒä½¿ç”¨LANï¼ˆå±€åŸŸç½‘ï¼‰æˆ–WANï¼ˆå¹¿åŸŸç½‘ï¼‰ç­‰å°é—­ç½‘ç»œç”Ÿæ€ç³»ç»Ÿè¿›è¡Œæ“ä½œã€‚IPTVéœ€è¦ä¸“é—¨çš„è®¾å¤‡ï¼ˆå¦‚æœºé¡¶ç›’ï¼‰å’Œå®½å¸¦è¿æ¥ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è¿™äº›è®¾å¤‡è®¿é—®ä¼ ç»Ÿçš„ç”µè§†é¢‘é“ï¼Œå¦‚CBSã€CNNã€FOXã€HBOç­‰ã€‚IPTVçš„ä¼˜åŠ¿åœ¨äºæä¾›é«˜è´¨é‡çš„å›¾åƒå’Œå£°éŸ³ï¼Œå› ä¸ºå®ƒä½¿ç”¨ä¸“ç”¨ç½‘ç»œè¿›è¡Œä¼ è¾“ï¼Œä¸ä¼šå ç”¨ç”¨æˆ·çš„äº’è”ç½‘å¸¦å®½[2]ã€‚ OTTï¼ˆOver-The-Topï¼‰æ˜¯ä¸€ç§é€šè¿‡å…¬å…±äº’è”ç½‘ä¼ è¾“è§†é¢‘å†…å®¹çš„æŠ€æœ¯ã€‚OTTæœåŠ¡åŸºäºè§†é¢‘ç‚¹æ’­ï¼ˆVODï¼‰çš„åˆ†å‘ï¼Œç”¨æˆ·åªéœ€è®¢é˜…æœåŠ¡ï¼Œå°±å¯ä»¥é€šè¿‡è¿æ¥åˆ°äº’è”ç½‘çš„è®¾å¤‡æ’­æ”¾å†…å®¹ã€‚OTTæœåŠ¡çš„ä¼˜åŠ¿åœ¨äºæˆæœ¬è¾ƒä½ã€å®‰è£…ç®€ä¾¿ï¼Œå¹¶ä¸”æä¾›å„ç§å„æ ·çš„èŠ‚ç›®é€‰æ‹©ã€‚ç„¶è€Œï¼ŒOTTçš„è§†é¢‘è´¨é‡å–å†³äºç”¨æˆ·çš„äº’è”ç½‘è¿æ¥é€Ÿåº¦ï¼Œå¯èƒ½ä¼šå‡ºç°ç¼“å†²å¯¼è‡´å†…å®¹ä¸­æ–­çš„æƒ…å†µ[2]ã€‚ ä»¥ä¸‹æ˜¯IPTVå’ŒOTTä¹‹é—´çš„ä¸»è¦åŒºåˆ«ï¼š å†…å®¹ä¼ é€’å’Œç½‘ç»œç»“æ„ï¼š IPTVä½¿ç”¨å°é—­ç½‘ç»œï¼ˆLANã€WANï¼‰ï¼Œæä¾›å¹³ç¨³çš„å†…å®¹ä¼ é€’ï¼Œä¸ä¾èµ–äºäº’è”ç½‘å¸¦å®½ã€‚ OTTä½¿ç”¨å…¬å…±äº’è”ç½‘è¿æ¥ï¼Œä»»ä½•äººéƒ½å¯ä»¥è®¿é—®ï¼Œä½†æœåŠ¡è´¨é‡å–å†³äºç”¨æˆ·çš„äº’è”ç½‘é€Ÿåº¦ã€‚ è®¾å¤‡éœ€æ±‚ï¼š OTTä¸éœ€è¦é¢å¤–çš„ç¡¬ä»¶è®¾å¤‡ï¼Œåªéœ€ä½¿ç”¨ä¸“ç”¨åº”ç”¨ç¨‹åºå³å¯ã€‚ IPTVéœ€è¦ä¸“é—¨çš„æœºé¡¶ç›’å’Œè·¯ç”±å™¨ã€‚ è§†é¢‘è´¨é‡ï¼š OTTçš„è§†é¢‘è´¨é‡å–å†³äºäº’è”ç½‘é€Ÿåº¦ã€‚ IPTVæä¾›æ›´æµç•…ã€æ›´å¥½çš„ç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰æ›´é«˜çš„è§†é¢‘è´¨é‡å’ŒéŸ³é¢‘æ•ˆæœã€‚ ä»·æ ¼ï¼š OTTæœåŠ¡é€šå¸¸æ˜¯å…è´¹çš„ï¼Œä½†å¯èƒ½éœ€è¦ä»˜è´¹è®¢é˜…ä»¥å»é™¤å¹¿å‘Šã€‚ IPTVçš„ä»·æ ¼è¾ƒé«˜ï¼Œå¹³å‡æ¯æœˆè´¹ç”¨åœ¨15ç¾å…ƒè‡³30ç¾å…ƒä¹‹é—´ã€‚ å†…å®¹ç±»å‹ï¼š OTTæä¾›å…è´¹æˆ–ä»˜è´¹çš„å†…å®¹ï¼Œä¹Ÿå¯ä»¥æ˜¯æ··åˆå†…å®¹ã€‚ IPTVæä¾›ç‹¬å®¶çš„ä»˜è´¹å†…å®¹ï¼Œå¦‚è®¢é˜…è§†é¢‘ç‚¹æ’­ï¼ˆSVODï¼‰ã€‚ OTT+ç›´æ’­ï¼Ÿ 2 è¿è¥å•†ã€ISPã€ICPã€éª¨å¹²ç½‘ ç”µä¿¡è¿è¥å•†ï¼šæŒ‡æä¾›åŸºç¡€çš„ç”µä¿¡ä¸šåŠ¡ï¼ŒåŒ…æ‹¬å›ºç½‘ï¼ˆæœ‰çº¿ï¼‰ï¼Œç§»åŠ¨ç½‘ç»œï¼ˆæ— çº¿ï¼‰çš„è¿è¥å•†ï¼ˆç”µä¿¡&#x2F;è”é€š&#x2F;ç§»åŠ¨æ˜¯ä¸€çº§&#x2F;åŸºç¡€è¿è¥å•†ï¼‰ã€‚ ISPï¼šå¤šæŒ‡äº’è”ç½‘æ¥å…¥æœåŠ¡æä¾›å•†ï¼Œé•¿åŸå®½å¸¦ç­‰äºŒçº§è¿è¥å•†ï¼ˆé€šè¿‡è´­ä¹°ç”µä¿¡è¿è¥å•†çš„å¸¦å®½æ¥æä¾›äº’è”ç½‘æ¥å…¥æœåŠ¡ï¼‰ ICPï¼šå†…å®¹æä¾›å•†æŒ‡æä¾›äº’è”ç½‘ä¸Šå„ç§å†…å®¹çš„æœåŠ¡æä¾›å•†ï¼Œä¾‹å¦‚è§†é¢‘ã€éŸ³ä¹ã€æ–°é—»ã€ç¤¾äº¤åª’ä½“ç­‰ã€‚åœ¨ä¸­å›½ï¼Œä¸€äº›çŸ¥åçš„å†…å®¹æä¾›å•†åŒ…æ‹¬çˆ±å¥‡å¼‚ã€ä¼˜é…·ç­‰ã€‚ å†…å®¹æä¾›å•†é€šå¸¸å°†å…¶å†…å®¹æ‰˜ç®¡åœ¨ç”µä¿¡è¿è¥å•†çš„æœºæˆ¿å†…ï¼Œç”¨æˆ·é€šè¿‡è´­ä¹°ISPçš„æœåŠ¡æ¥è®¿é—®è¿™äº›å†…å®¹ã€‚ å±€åŸŸç½‘ï¼šå‡ å°è®¡ç®—æœºäº’è”ï¼ˆè®¡ç®—æœºç»„ï¼‰ï¼ˆå…‰çº¤ã€å¾ˆç»†çš„å…‰ç¼†ã€‘&#x2F;wifiï¼‰ï¼› å››ç§æŠ€æœ¯ç±»å‹&#x2F;æ ‡å‡†ï¼šä»¥å¤ªç½‘ã€ä»¤ç‰Œç¯ã€ä»¤ç‰Œæ€»çº¿ã€å…‰çº¤åˆ†å¸ƒå¼æ•°æ®æ¥å£(FDDI)ï¼› åŸåŸŸç½‘ï¼šåŸå¸‚èŒƒå›´å†…çš„è®¡ç®—æœºé€šä¿¡ç½‘ï¼ˆå¤§å‹LANï¼‰ï¼ˆå…‰ç¼†ï¼‰ï¼› å•ç‹¬åˆ—å‡ºï¼Œç”±äºæœ‰ä¸€ä¸ªç‹¬æœ‰æ ‡å‡†ï¼šåˆ†å¸ƒå¼é˜Ÿåˆ—åŒæ€»çº¿DQDBï¼ˆDistributed Queue Dual Busï¼‰ éª¨å¹²ç½‘ï¼šé€šå¸¸æ˜¯ä¸€ä¸ªå›½å®¶æˆ–åœ°åŒºèŒƒå›´å†…çš„ç½‘ç»œï¼Œç”¨äºè¿æ¥ä¸åŒåŸå¸‚æˆ–åœ°åŒºçš„ç½‘ç»œï¼› å¹¿åŸŸç½‘ï¼šè·¨è¶Šå¤šä¸ªåŸå¸‚ã€å›½å®¶æˆ–æ´²é™…ï¼Œè¿æ¥ä¸åŒçš„å±€åŸŸç½‘å’ŒåŸåŸŸç½‘ï¼ˆå¯åŒ…å«å¤šä¸ªéª¨å¹²ç½‘ï¼‰ ä¸­å›½ä¸»è¦çš„éª¨å¹²ç½‘ï¼š ä¸­å›½ç”µä¿¡ CHINANETï¼šä¸­å›½å…¬ç”¨è®¡ç®—æœºäº’è”ç½‘ï¼ŒåŸé‚®ç”µéƒ¨ ä¸­å›½ç§»åŠ¨ CMNETï¼šä¸­å›½ç§»åŠ¨äº’è”ç½‘ ä¸­å›½è”é€š UNINETï¼šä¸­å›½è”é€šè®¡ç®—æœºäº’è”ç½‘ï¼Œè¿˜æœ‰å­å…¬å¸ç½‘é€šçš„ä¸­å›½ç½‘é€šå…¬ç”¨äº’è”ç½‘ï¼ˆCNCNETï¼‰ ä¸­ç§‘é™¢ CSTNETï¼šä¸­å›½ç§‘æŠ€ç½‘ ä¿¡æ¯äº§ä¸šéƒ¨ CHINAGBNï¼šä¸­å›½é‡‘æ¡¥ä¿¡æ¯ç½‘ æ•™è‚²éƒ¨ CERNETï¼šä¸­å›½æ•™è‚²å’Œç§‘ç ”è®¡ç®—æœºç½‘ï¼Œå›½å®¶å…¬ç”¨ç»æµä¿¡æ¯é€šä¿¡ç½‘ 12345ç§»åŠ¨ é“é€š ç”µä¿¡ è”é€š(CDMA) å«é€š è”é€š(GSM) ç½‘é€š | | | | / \\ | | \\ / \\ | / \\ \\ / \\ / \\ | / | \\ / ç§»åŠ¨ ç”µä¿¡ èˆªå¤©ç§‘æŠ€ è”é€š SDNæ˜¯å…¸å‹çš„ç½‘ç»œæŠ€æœ¯ï¼ŒNFVæ˜¯å…¸å‹çš„è®¡ç®—æŠ€æœ¯ï¼›SDNä¸»è¦åº”ç”¨äºæ‰¿è½½ç½‘ï¼ŒNFVä¸»è¦åº”ç”¨äºæ ¸å¿ƒç½‘å’Œæ¥å…¥ç½‘ï¼›SDNæ˜¯è½¬å‘ä¸æ§åˆ¶çš„è§£è€¦ï¼ŒNFVæ˜¯è½¯ä»¶ä¸ç¡¬ä»¶çš„è§£è€¦ã€‚ NFVï¼Œå…¨ç§°Network Function Virtualizationï¼Œç½‘ç»œåŠŸèƒ½è™šæ‹ŸåŒ–ã€‚æ‰€è°“çš„ç½‘ç»œåŠŸèƒ½ï¼Œæ˜¯æŒ‡ç½‘ç»œè®¾å¤‡çš„åŠŸèƒ½ï¼›è€Œè™šæ‹ŸåŒ–ï¼Œæ˜¯äº‘è®¡ç®—çš„æ ¸å¿ƒæŠ€æœ¯ã€‚ ä»å‰çš„ç§»åŠ¨é€šä¿¡ç½‘ç»œï¼Œå°¤å…¶æ˜¯æ ¸å¿ƒç½‘ï¼Œæ˜¯ç”±å¾ˆå¤šä¸“ç”¨ç¡¬ä»¶è®¾å¤‡ç»„æˆçš„ï¼Œåœ¨ä¸“ç”¨è®¾å¤‡è¿è¡Œå¯¹åº”çš„è½¯ä»¶æœåŠ¡ï¼Œä¿è¯åŠŸèƒ½å®ç°ã€‚ä½†æ˜¯åœ¨5Gæ ¸å¿ƒç½‘ä¸­ï¼Œå·²ç»æ²¡æœ‰ä»»ä½•ä¸“ç”¨ç¡¬ä»¶ï¼Œå®Œå…¨é‡‡ç”¨X86é€šç”¨æœåŠ¡å™¨ï¼Œè½¯ä»¶æœåŠ¡è¿è¡Œåœ¨è™šæ‹Ÿæœºå’Œå®¹å™¨ä¸Šã€‚ è¿™å°±æ˜¯é‡‡ç”¨äº†NFVæŠ€æœ¯ï¼Œå°†é€šä¿¡è®¾å¤‡ç½‘å…ƒäº‘åŒ–ï¼Œå®ç°è½¯ä»¶å’Œç¡¬ä»¶çš„è§£è€¦ï¼Œè¿è¡Œå•†ä¸éœ€è¦å†è´­ä¹°ä¸“ç”¨ç¡¬ä»¶è®¾å¤‡ï¼Œå‡å°‘äº†ç¡¬ä»¶èµ„é‡‘çš„æŠ•å…¥ã€‚ å¦å¤–ï¼ŒNFVè¿˜å…·å¤‡è‡ªåŠ¨éƒ¨ç½²ã€å¼¹æ€§ä¼¸ç¼©ã€æ•…éšœéš”ç¦»å’Œè‡ªæ„ˆæ€§é«˜ç­‰ä¼˜ç‚¹ï¼Œå¯ä»¥å¤§å¹…æå‡ç½‘ç»œè¿ç»´æ•ˆç‡ã€é™ä½æ•…éšœé£é™©å’Œèƒ½è€—ã€‚ SDNï¼Œå…¨ç§°æ˜¯Software Defined Networkingï¼Œè½¯ä»¶å®šä¹‰ç½‘ç»œã€‚ å®ƒçš„æ ¸å¿ƒæ€æƒ³å°±æ˜¯å°†æ§åˆ¶å¹³é¢ä¸è½¬å‘å¹³é¢è§£è€¦ï¼Œå¼•å…¥ç½‘ç»œå¯ç¼–ç¨‹èƒ½åŠ›ï¼Œæ¥æå‡ç³»ç»Ÿçµæ´»æ€§ã€‚ æ§åˆ¶åŠŸèƒ½å…¨éƒ¨é›†ä¸­åˆ°æ§åˆ¶å™¨ä¸­ï¼Œè·¯ç”±å™¨äº¤æ¢æœºåªè´Ÿè´£æŒ‰ç…§Flowtableè½¬å‘å³å¯ã€‚æ‰¿è½½ç½‘å¼•å…¥äº†SDNæŠ€æœ¯ï¼Œè·¯ç”±å™¨åªè½¬å‘ï¼ŒSDNæ§åˆ¶å™¨å»ºç«‹åœ¨äº‘å¹³å°ä¸Šï¼Œå‘ä¸Šå±‚ç”¨æˆ·æä¾›æ¥å£æœåŠ¡ã€‚ ç±»å‹ SDN NFV ç›®çš„ è½¬å‘å’Œæ§åˆ¶åˆ†ç¦»ï¼Œæ§åˆ¶é¢é›†ä¸­ï¼Œç½‘ç»œå¯ç¼–ç¨‹ å°†ç½‘ç»œåŠŸèƒ½ä»åŸæ¥çš„ä¸“ç”¨æœåŠ¡å™¨è½¬ç§»åˆ°é€šç”¨è®¾å¤‡ é’ˆå¯¹åœºæ™¯ æ•°æ®ä¸­å¿ƒã€å›­åŒºç½‘ã€è¿è¥å•†ç½‘ç»œ è¿è¥å•†ç½‘ç»œ é’ˆå¯¹è®¾å¤‡ å•†ç”¨äº¤æ¢æœºç­‰æ•°é€šè®¾å¤‡ ä¸“ç”¨æœåŠ¡å™¨ ISOå±‚çº§ 2-3å±‚ 4-7å±‚ æ¥å…¥ç½‘ï¼ˆæ¥å…¥å±‚ï¼‰ï¼šæ— çº¿æ¥å…¥ã€æœ‰çº¿æ¥å…¥ ä¼ è¾“ç½‘ï¼ˆéª¨å¹²ç½‘ï¼‰ï¼šä¸»è¦ä¸ºOTNï¼ˆå…‰ä¼ è¾“ç½‘ç»œï¼‰","tags":[{"name":"points","slug":"points","permalink":"https://stu-yue.github.io/tags/points/"}],"categories":[{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"}]},{"title":"Summa | The Majority of Memory Categories","date":"2023-07-20T08:41:53.000Z","path":"jottings/architecture/summa_memory_categories/","text":"Reproduced in 8 types of memory every embedded engineer should know about! The majority of memory can be categorized as shown in the following picture: The real difference between primary and secondary memories is the speed&#x2F;volatility(without power) tradeoffs. Primary MemoryPrimary memory is very fast, but it cannot hold data without power. The popular name for Primary Memory is RAM, which has 2 most important types namely SRAM and DRAM. Bistable Circuit usually consists of two complementary transistors or other switching devices, one used to hold the circuit in one stable state and the other to switch the circuit to another stable state. The switch between these two states is triggered by the input signal. Bistable Circuit can store data. Latches and registers are bistable devices. SRAM is the use of bistable flip-flop to save information, as long as the power is not lost, the information is not lost. DRAM uses capacitors to store charge to store information, so data stored in the DRAM must be constantly refreshed every few milliseconds or else it will end up being erased. The action is taken care of by a special device named DRAM controllers. SRAM DRAM Construction Principle It uses a cross-coupled flip flop configuration of transistors It uses a capacitor transistor circuit to hold data Cost Relatively more expensive, it needs more transistors per bit of data it can store Relatively less expensive, as fewer transistors per bit of storage are needed Speed Faster Slower (capacitor charge and discharge time) Volatility As long as power is ON, it can store data since it uses no capacitors Data needs to be continuously refreshed (usually in the order of 4 times a second) since the capacitors leak power. Power consumption Less More Density Less dense (6 transistors, more area needed) Highly dense (1 pass transistor and 1 capacitor, easy to integrate) Addition components needed None DRAM controllers are needed to make it work like an SRAM. This controller offloads the data refreshing duties of a microprocessor and hence a DRAM coupled with a DRAM controller behaves more like an SRAM from the processorâ€™s perspective. Application areas Cache memory (Ls2) Main memory (memory chips) NVRAM or Non Volatile Random Access Memory, is a special type of RAM that can store data permanently. Itâ€™s basically an SRAM with a power supply Secondary MemoryROM MASK ROM: The main characteristic of this device is the fact that the data is written onto the device as it gets manufactured and it is impossible to change them. This is done by designing the chip in such a manner so that it already contains the necessary data. In order to mass production, the manufacturer makes a ROM or EPROM with original data as a sample in advance, and then mass-produces the same ROM as the sample. This kind of ROM sample for mass production is the MASK ROM, and the data burned in the MASK ROM can never be modified. PROM stands for Programmable Read-Only Memory. These are programmable chips for user needs, the main characteristic being it can only be programmed one time. That is it cannot be erased or reprogrammed. They are also known as One Time Programmable devices or OTPs for short. EPROM stands for Erasable Programmable Read-Only Memory. These chips usually have a small glass window on top and if you expose them to direct sunlight(UV, ultraviolet) that will erase the chipâ€™s data. They can then be programmed again with fresh data. Cons: Inconvenient, instability, can not be exposed to the light source otherwise easy to lead to data loss EEPROM stands for Electrically Erasable Programmable Read-Only Memory. These chips can be erased and reprogrammed using electricity as opposed to exposing them to UV rays as EPROMs. EEPROM can be erased and reprogrammed on a computer or dedicated device, generally plugging and playing. FLASH MEMORY The basic storage unit of flash memory is the transistor-based storage unit, and each storage unit can store 1 bit of data. Storage units are usually organized into a block, and each block contains thousands of storage units. Each storage unit has a floating gate to store electric charges. The state of a storage unit can be determined as â€œ1â€ or â€œ0â€ based on the amount of electric charges stored in the floating gate. The state of a storage unit is changed by injecting or extracting electrons into&#x2F;from the floating gate to modify the amount of electric charges stored in it. Flash memory uses Hot carrier injection(HCI) mechanism to write data. In simple terms, a certain storage unit is grounded at the source, a positive voltage is applied to its control gate, and a positive voltage is applied to the drain to generate a strong electric field between the source and drain. This will give electrons enough energy (hot carriers) to be attracted by the voltage at the control gate and injected into the floating gate. Afterwards, as the insulating material on the top and bottom of the floating gate is not conductive, these electrons are trapped in the floating gate and cannot escape. (Every time electrons enter and exit the surrounding silicon dioxide on the floating gate, it will cause aging[1]) To save cost, flash memory adopts page programming mode. Each page contains a certain number of storage units, and all units in a page are written at the same time. Cons: Flash memory has the issue of wear-out (write&#x2F;erase endurance limits), which is usually mitigated by disabling bad blocks, and then reducing usable capacity. USB flash disk, namely â€œU diskâ€, is a new generation of storage devices based on USB interface and flash memory chip as storage medium. It is basically composed of five parts: USB port, main control chip, flash memory chip, PCB backboard, outer package. USB flash drives, SD cards, and SSDs are a type of storage device that uses flash memory chips as the storage medium. They are primarily composed of a controller (main control) and flash memory chips, and have no mechanical structure, consisting purely of electronic circuitry. They are resistant to physical shocks and impacts. The controller manages data storage and other functions. Even after power loss, data remains stored in the memory cells. USB flash drives generally have a cache on them to prevent the loss of data copies from being quickly plugged in&#x2F;out. OTHER Hard Disk Drive: The disk reads data according to the polarity of the magnetic particle and writes data according to the polarity of the magnetic head. Compact Disk: CD-ROM can only be read and not written to because after being burned once, each unit has a fixed different reflectivity (the reading probe emits laser and the reflected laser is read as â€œ1â€, or non-reflected laser is read as â€œ0â€). Floppy Disk: A type of magnetic disk, less capacity, slower speed.","tags":[{"name":"memory","slug":"memory","permalink":"https://stu-yue.github.io/tags/memory/"}],"categories":[{"name":"architecture","slug":"architecture","permalink":"https://stu-yue.github.io/categories/architecture/"}]},{"title":"Welcome to Yue's Jotter","date":"2023-07-13T08:23:57.000Z","path":"jottings/intro/","text":"","tags":[],"categories":[]},{"title":"Summa | Firmware and Drivers","date":"2023-07-13T06:21:53.000Z","path":"jottings/architecture/summa_firmware_and_drivers/","text":"Reproduced in Firmware vs Device Drivers: Explained with Examples! Firmware vs. Device Drivers Firmware Device Drivers Firmware is a class of software that is written for specific custom hardware. Device drivers are software that is needed to make a given hardware accessory Firmware lives and runs directly on the hardware. Device drivers live on hard-disk and run on the CPU. Firmware is independent of an operating system, i.e., you can run any operating system on top of a given motherboardâ€™s firmware. Device drivers are highly dependent on the operating system on which they are used. For example, for the same hardware device, you need different device drivers for using that on Windows vs Linux. Firmware cannot be updated through an operating system, we need to go into the BIOS&#x2F;UEFI to update the device drivers. Drivers can be updated from within the operating system. Firmware engineers do not need any knowledge of operating systems. But they need core knowledge on processors and the latest RAMs, PCIe standards, and so on to write firmware that complies with the latest standards Device driver engineers need knowledge about the specific device that they are using, the communication standard the device uses to talk to the computer (like Bluetooth, USB, etc), and the operating system the device driver is written for. Firmware is written by motherboard manufacturers Drivers are written by engineers in companies that produce hardware accessories that connect to your computer Examples include the BIOS&#x2F;UEFI interface that comes with the computerâ€™s motherboard Examples include special software you install to handle the extra buttons on your mouse, software that comes with any non-standard hardware like special game controllers, also the software that helps us use all the standard hardware like USB storage devices, keyboards, mice, headphones, etc. Layers of software on a typical computer are shown in the following figure: Firmwareâ€‹ Firmware is a computer program that is written to work directly on specific custom hardware and it lives in non-volatile memory such as a flash chip and it is executed directly from it. The job of the firmware is to make the hardware accessible to the operating system. Firmware can be thought of as the glasses through which the operating system can see the actual hardware! â€‹ Originally Firmware is written on Masked ROMs, which is a special type of memory that can be programmed&#x2F;written-data-to only once. The products were then shipped with these unchangeable programs called firmware and they run for ages till the device goes out of use. â€‹ The first replacement of Masked ROMs came in the form of EPROM which can be erased by exposure to UV light and then reprogrammed as required. Then came EEPROMs which used electricity to change the contents. Nowadays the Masked ROMs have been replaced with Flash memory, which is cheaper and serves the purpose. Device DriversDevice drivers are programs that can control a given hardware and provide a software interface to it. Other programs like Operating Systems can interact with the hardware through this software interface without needing to know the actual underlying implementation of the software interface. The relation graph between firmware and drivers is also shown below: â€‹ Generally speaking, drivers and firmware together form the module that operates hardware. But why not make the firmware perfect so that it doesnâ€™t require driver support? â€‹ The answer to the above question is, there are different operating systems which have completely different ways of operating hardware. So, on the one hand, hardware manufactures need to write firmware to make their hardware easier to use with software, but on the other hand, they cannot make the firmware too rigid in order to be compatible with various operating systems. They must leave enough room for software to freely operate â€”â€” and thatâ€™s where drivers come in.","tags":[{"name":"firmware","slug":"firmware","permalink":"https://stu-yue.github.io/tags/firmware/"},{"name":"driver","slug":"driver","permalink":"https://stu-yue.github.io/tags/driver/"}],"categories":[{"name":"architecture","slug":"architecture","permalink":"https://stu-yue.github.io/categories/architecture/"}]}],"categories":[{"name":"interview","slug":"interview","permalink":"https://stu-yue.github.io/categories/interview/"},{"name":"Hot100","slug":"interview/Hot100","permalink":"https://stu-yue.github.io/categories/interview/Hot100/"},{"name":"mathematics","slug":"mathematics","permalink":"https://stu-yue.github.io/categories/mathematics/"},{"name":"statistics_ml","slug":"statistics-ml","permalink":"https://stu-yue.github.io/categories/statistics-ml/"},{"name":"architecture","slug":"architecture","permalink":"https://stu-yue.github.io/categories/architecture/"},{"name":"tools","slug":"tools","permalink":"https://stu-yue.github.io/categories/tools/"},{"name":"docker","slug":"tools/docker","permalink":"https://stu-yue.github.io/categories/tools/docker/"},{"name":"languages","slug":"languages","permalink":"https://stu-yue.github.io/categories/languages/"},{"name":"shell","slug":"languages/shell","permalink":"https://stu-yue.github.io/categories/languages/shell/"},{"name":"tidbits","slug":"tidbits","permalink":"https://stu-yue.github.io/categories/tidbits/"},{"name":"networks","slug":"networks","permalink":"https://stu-yue.github.io/categories/networks/"},{"name":"python","slug":"languages/python","permalink":"https://stu-yue.github.io/categories/languages/python/"}],"tags":[{"name":"math","slug":"math","permalink":"https://stu-yue.github.io/tags/math/"},{"name":"ml","slug":"ml","permalink":"https://stu-yue.github.io/tags/ml/"},{"name":"instruction set arch","slug":"instruction-set-arch","permalink":"https://stu-yue.github.io/tags/instruction-set-arch/"},{"name":"docker","slug":"docker","permalink":"https://stu-yue.github.io/tags/docker/"},{"name":"linux","slug":"linux","permalink":"https://stu-yue.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://stu-yue.github.io/tags/shell/"},{"name":"networks","slug":"networks","permalink":"https://stu-yue.github.io/tags/networks/"},{"name":"statistic","slug":"statistic","permalink":"https://stu-yue.github.io/tags/statistic/"},{"name":"algebra","slug":"algebra","permalink":"https://stu-yue.github.io/tags/algebra/"},{"name":"python","slug":"python","permalink":"https://stu-yue.github.io/tags/python/"},{"name":"optimization","slug":"optimization","permalink":"https://stu-yue.github.io/tags/optimization/"},{"name":"interview","slug":"interview","permalink":"https://stu-yue.github.io/tags/interview/"},{"name":"points","slug":"points","permalink":"https://stu-yue.github.io/tags/points/"},{"name":"memory","slug":"memory","permalink":"https://stu-yue.github.io/tags/memory/"},{"name":"firmware","slug":"firmware","permalink":"https://stu-yue.github.io/tags/firmware/"},{"name":"driver","slug":"driver","permalink":"https://stu-yue.github.io/tags/driver/"}]}